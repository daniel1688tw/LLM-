{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc75c21b",
   "metadata": {},
   "source": [
    "## 簡介 ##\n",
    "此代碼用來讓LLM根據表格資料與使用者的提問要求，透過pipline與tree stucture，生成報導或分析資料\n",
    "\n",
    "此篇研究只需提供\n",
    "\"main.txt\"為使用者的大綱與簡短想法\n",
    "\"data_description.txt\"為要分析的table columns所代表的意義\n",
    "就可產生完整報導\n",
    "(可使用在產生任何報導上不限於羽球)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d0e02",
   "metadata": {},
   "source": [
    "# STEP 1\n",
    "\n",
    "刪減不必要的columns\n",
    "\n",
    "結果保留['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88a047de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"Gemini_API\")\n",
    "if not api_key:\n",
    "    print(\"❌ Gemini_API 環境變數未設定\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ca3c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#正式\n",
    "import dspy\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional, ClassVar\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "class GeminiOpenAI(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        # 使用 Google 的 OpenAI 兼容端點\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "        )\n",
    "        super().__init__(model=model_name)\n",
    "     \n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "         \n",
    "        # Convert messages to OpenAI format\n",
    "        if isinstance(messages, list):\n",
    "            formatted_messages = []\n",
    "            for msg in messages:\n",
    "                if isinstance(msg, dict) and 'content' in msg:\n",
    "                    role = msg.get('role', 'user')\n",
    "                    formatted_messages.append({\n",
    "                        'role': role,\n",
    "                        'content': msg['content']\n",
    "                    })\n",
    "                else:\n",
    "                    formatted_messages.append({\n",
    "                        'role': 'user',\n",
    "                        'content': str(msg)\n",
    "                    })\n",
    "        else:\n",
    "            formatted_messages = [{'role': 'user', 'content': str(messages)}]\n",
    "         \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=formatted_messages,\n",
    "                **kwargs\n",
    "            )\n",
    "            \n",
    "            if not response.choices or not response.choices[0].message.content:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            \n",
    "            return [{\n",
    "                'text': response.choices[0].message.content,\n",
    "                'logprobs': None\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{\n",
    "                'text': \"⚠️ Gemini API 回應失敗,可能已達限額或出現錯誤。\",\n",
    "                'logprobs': None\n",
    "            }]\n",
    "     \n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[{'role': 'user', 'content': prompt}],\n",
    "                **kwargs\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "def setup_gemini_api(api_key, model_name=\"gemini-2.0-flash\"):\n",
    "    lm = GeminiOpenAI(api_key=api_key, model_name=model_name)\n",
    "    dspy.settings.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "\n",
    "def parse_list_from_response(response_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse a Python list from various response formats including markdown code blocks\n",
    "    \"\"\"\n",
    "    if not response_text or response_text.strip() == \"\":\n",
    "        print(\"⚠️ 回應為空\")\n",
    "        return []\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = response_text.strip()\n",
    "    \n",
    "    # Remove markdown code blocks\n",
    "    text = re.sub(r'```(?:python|json)?\\s*', '', text)\n",
    "    text = re.sub(r'```\\s*', '', text)\n",
    "    \n",
    "    # Remove any additional backticks\n",
    "    text = text.strip('`').strip()\n",
    "    \n",
    "    # Try to find a list pattern in the text\n",
    "    list_match = re.search(r'\\[.*?\\]', text, re.DOTALL)\n",
    "    \n",
    "    if list_match:\n",
    "        list_text = list_match.group(0)\n",
    "    else:\n",
    "        print(f\"⚠️ 無法在回應中找到列表格式\")\n",
    "        print(f\"完整回應: {text[:200]}...\")\n",
    "        return []\n",
    "    \n",
    "    # Clean up the list text\n",
    "    list_text = list_text.strip()\n",
    "    \n",
    "    # Try multiple parsing strategies\n",
    "    try:\n",
    "        # Strategy 1: Parse as-is\n",
    "        return json.loads(list_text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Strategy 2: Convert single quotes to double quotes\n",
    "        list_text_double = list_text.replace(\"'\", '\"')\n",
    "        return json.loads(list_text_double)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # Strategy 3: Manual parsing for simple cases\n",
    "        # Remove brackets and split by comma\n",
    "        content = list_text.strip('[]').strip()\n",
    "        if not content:\n",
    "            return []\n",
    "        \n",
    "        # Split by comma and clean each item\n",
    "        items = []\n",
    "        for item in content.split(','):\n",
    "            item = item.strip().strip('\"').strip(\"'\").strip()\n",
    "            if item:\n",
    "                items.append(item)\n",
    "        \n",
    "        if items:\n",
    "            print(f\"✓ 使用手動解析成功\")\n",
    "            return items\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 手動解析失敗: {e}\")\n",
    "    \n",
    "    print(f\"❌ 所有解析方法都失敗了\")\n",
    "    print(f\"原始文本: {list_text[:200]}\")\n",
    "    return []\n",
    "\n",
    "\n",
    "def extract_news_relevant_fields(description_path: str, main_path: str, model_name=\"gemini-2.0-flash\"):\n",
    "    \"\"\"\n",
    "    從描述文件和大綱文件中提取相關欄位\n",
    "    \n",
    "    Args:\n",
    "        description_path: 資料欄位描述文件路徑\n",
    "        main_path: 大綱文件路徑\n",
    "        model_name: 使用的模型名稱\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: 篩選出的欄位列表\n",
    "    \"\"\"\n",
    "     \n",
    "    lm = setup_gemini_api(api_key, model_name)\n",
    "    main_content = read_text_file(main_path)\n",
    "    description = read_text_file(description_path)\n",
    "    \n",
    "    prompt = f\"\"\"Using the following outline and list of data column descriptions, select only the columns that are useful for the outline.\n",
    "\n",
    "## outline\n",
    "{main_content}\n",
    "\n",
    "## Data Column Descriptions:\n",
    "{description}\n",
    "\n",
    "---\n",
    "\n",
    "Please return only a Python list of column names, like this:\n",
    "['player_name', 'match_score', 'duration', ...]\n",
    "\n",
    "Do not include explanations or any other text. Return only the list.\"\"\"\n",
    "     \n",
    "    result = lm.basic_request(prompt)\n",
    "    \n",
    "    print(f\"🔍 原始回應:\\n{result}\\n\")\n",
    "    \n",
    "    selected_fields = parse_list_from_response(result)\n",
    "    \n",
    "    if selected_fields:\n",
    "        print(\"✅ 篩選出的欄位:\", selected_fields)\n",
    "    else:\n",
    "        print(\"❌ 未能成功解析欄位列表\")\n",
    "    \n",
    "    return selected_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "692ab381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 原始回應:\n",
      "```python\n",
      "['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']\n",
      "```\n",
      "\n",
      "✅ 篩選出的欄位: ['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']\n",
      "最終欄位清單: ['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']\n"
     ]
    }
   ],
   "source": [
    "# 直接調用函式\n",
    "fields = extract_news_relevant_fields(\"data_description.txt\", \"main.txt\")\n",
    "print(\"最終欄位清單:\", fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c560a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"set1.csv\")\n",
    "filtered_df = df[fields]\n",
    "filtered_df.to_csv(\"filtered_set1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc7c70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已將欄位描述寫入 filtered_data_description.txt\n"
     ]
    }
   ],
   "source": [
    "def extract_descriptions_for_fields(fields: List[str], desc_path: str, output_path: str):\n",
    "    description_text = read_text_file(desc_path)\n",
    "\n",
    "    field_desc = {}\n",
    "    for line in description_text.splitlines():\n",
    "        for field in fields:\n",
    "            if line.lower().startswith(field.lower() + \":\"):\n",
    "                field_desc[field] = line.strip()\n",
    "\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for field in fields:\n",
    "                f.write(field_desc.get(field, f\"{field}: [Description not found]\") + \"\\n\")\n",
    "        print(f\"✅ 已將欄位描述寫入 {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 寫入失敗: {e}\")\n",
    "\n",
    "\n",
    "extract_descriptions_for_fields(fields, 'data_description.txt', \"filtered_data_description.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c668469",
   "metadata": {},
   "source": [
    "# STEP 2\n",
    "\n",
    "藉由人為輸入問題與方向提示，給LLM做完整分析問題與方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e639240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chain_of_thought_response(main_path: str, desc_path: str, output_path: str, model_name=\"gemini-2.0-flash\"):\n",
    "    \"\"\"\n",
    "    生成 Chain-of-Thought 分析回應\n",
    "    \n",
    "    Args:\n",
    "        main_path: 大綱文件路徑\n",
    "        desc_path: 資料欄位描述文件路徑\n",
    "        output_path: 輸出文件路徑\n",
    "        model_name: 使用的模型名稱\n",
    "    \n",
    "    Returns:\n",
    "        str: 生成的回應內容,如果失敗則返回 None\n",
    "    \"\"\"\n",
    "\n",
    "    lm = setup_gemini_api(api_key, model_name)\n",
    "\n",
    "    main_content = read_text_file(main_path)\n",
    "    description = read_text_file(desc_path)\n",
    "\n",
    "    chain_prompt = f\"\"\"\n",
    "You are a planning assistant.\n",
    "Analyze the following outline and column descriptions.\n",
    "\n",
    "## Outline & Ideas:\n",
    "{main_content}\n",
    "\n",
    "## Data Column Descriptions:\n",
    "{description}\n",
    "\n",
    "---\n",
    "\n",
    "Step-by-step:\n",
    "1. Reflect on the structure and meaning of the content.\n",
    "2. Formulate relevant and meaningful questions or planning strategies.\n",
    "3. Be explicit and detailed, use Chain-of-Thought reasoning.\n",
    "4. Output all thoughts and questions in English only.\n",
    "\"\"\"\n",
    "\n",
    "    result = lm.basic_request(chain_prompt)\n",
    "\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result)\n",
    "        print(f\"✅ Response saved to: {output_path}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to write output: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cbf0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Response saved to: analyze_response.txt\n"
     ]
    }
   ],
   "source": [
    "response = generate_chain_of_thought_response(\n",
    "    main_path=\"main.txt\",\n",
    "    desc_path=\"filtered_data_description.txt\",\n",
    "    output_path=\"analyze_response.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1496f5f",
   "metadata": {},
   "source": [
    "# STEP 3\n",
    "\n",
    "請LLM根據\"analyze_response.txt\"思考可以使用的operation並將結果存於 \"operations_info.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6399f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 操作清單與描述已儲存至 operations_info.json\n",
      "\n",
      "✅ 操作名稱陣列:\n",
      "['write', 'select_row', 'select_column', 'groupby', 'aggregate', 'sort', 'filter', 'calculate', 'merge', 'join', 'pivot_table', 'rolling_window', 'shift', 'value_counts', 'corr']\n"
     ]
    }
   ],
   "source": [
    "def analyze_operations(analyze_path: str, output_json: str) -> List[str]:\n",
    "    lm = setup_gemini_api(api_key)\n",
    "    analysis = read_text_file(analyze_path)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a news journalist want to analyze data not forecaster.\n",
    "Based on the following text analysis, identify multiple useful table operations\n",
    "and describe the direct meaning of each operation.\n",
    "\n",
    "## Text Analysis:\n",
    "{analysis}\n",
    "\n",
    "---\n",
    "\n",
    "Please output a numbered list in this format:\n",
    "1. write: If the table is clear or small enough, generates text based on the tables using the LLM.\n",
    "2. select_row: Description\n",
    "3. select_column: Description\n",
    "4. operation_name: Description\n",
    "5. operation_name: Description\n",
    "...\n",
    "\n",
    "IMPORTANT: operation must contain select_row, select_column, and write in the first three operation.\n",
    "\n",
    "Give important operations and at most 15 operations.\n",
    "operation_name should be different and each operation can not be similar.\n",
    "operation can be apply on many columns is better.\n",
    "Description just give the original definition of the operation name and give some useful functions name in pandas.\n",
    "Only include operations and their descriptions. Be concise and clear.\n",
    "\"\"\"\n",
    "\n",
    "    response = lm.basic_request(prompt)\n",
    "\n",
    "    operations = []\n",
    "    operations_dict = {}\n",
    "\n",
    "    try:\n",
    "        for line in response.strip().split('\\n'):\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "            if \".\" in line:\n",
    "                num, rest = line.split(\".\", 1)\n",
    "                if \":\" in rest:\n",
    "                    name, desc = rest.strip().split(\":\", 1)\n",
    "                    name = name.strip()\n",
    "                    desc = desc.strip()\n",
    "                    operations.append(name)\n",
    "                    operations_dict[num.strip()] = {\"operation\": name, \"description\": desc}\n",
    "\n",
    "        with open(output_json, 'w', encoding='utf-8') as f:\n",
    "            json.dump(operations_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"✅ 操作清單與描述已儲存至 {output_json}\")\n",
    "        return operations\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 回應處理失敗: {e}\\n原始回應:\\n{response}\")\n",
    "        return []\n",
    "\n",
    "ops = analyze_operations(\"analyze_response.txt\", \"operations_info.json\")\n",
    "print(\"\\n✅ 操作名稱陣列:\")\n",
    "print(ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cebfb8",
   "metadata": {},
   "source": [
    "# STEP 4\n",
    "\n",
    "使LLM自動分析table選出合適的operation放入操作池(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14dcba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationSignature(dspy.Signature):\n",
    "    \"\"\"Identify suitable operations for analyzing badminton match data.\"\"\"\n",
    "    data_description = dspy.InputField(desc=\"Overview and sample of the dataset\")\n",
    "    column_descriptions = dspy.InputField(desc=\"Descriptions of each column in the dataset\")\n",
    "    rules = dspy.InputField(desc=\"Rules for selecting operations\")\n",
    "    operations_list = dspy.OutputField(desc=\"A list of suitable operations number (e.g., [1, 2, 3, 4])\")\n",
    "\n",
    "def read_badminton_data(file_path):\n",
    "    \"\"\"\n",
    "    讀取羽球比賽數據 CSV 文件\n",
    "    \n",
    "    Args:\n",
    "        file_path: CSV 文件路徑\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 讀取的數據\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    讀取 JSON 文件\n",
    "    \n",
    "    Args:\n",
    "        file_path: JSON 文件路徑\n",
    "    \n",
    "    Returns:\n",
    "        dict: JSON 數據\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "def parse_column_descriptions(description_text):\n",
    "    \"\"\"\n",
    "    解析欄位描述文本\n",
    "    \n",
    "    Args:\n",
    "        description_text: 欄位描述文本\n",
    "    \n",
    "    Returns:\n",
    "        dict: 欄位名稱到描述的映射\n",
    "    \"\"\"\n",
    "    descriptions = {}\n",
    "    pattern = r'''\n",
    "        ^                # Line start\n",
    "        (\\w+)            # Column name\n",
    "        :\\s+             # Colon and space\n",
    "        (.+?)            # Description text\n",
    "        (?=\\n\\w+:\\s+|\\Z) # Lookahead for next column or end of file\n",
    "    '''\n",
    "    matches = re.findall(pattern, description_text, flags=re.M | re.X)\n",
    "    for col_name, desc in matches:\n",
    "        clean_desc = ' '.join(desc.split()).strip()\n",
    "        descriptions[col_name] = clean_desc\n",
    "    return descriptions\n",
    "\n",
    "class BadmintonOperationSelector(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.chain_of_thought = dspy.ChainOfThought(OperationSignature)\n",
    "\n",
    "    def forward(self, data_description, column_descriptions, rules):\n",
    "        result = self.chain_of_thought(\n",
    "            data_description=data_description,\n",
    "            column_descriptions=str(column_descriptions),\n",
    "            rules=str(rules)\n",
    "        )\n",
    "        return self.extract_operations_from_result(result.operations_list)\n",
    "\n",
    "    def extract_operations_from_result(self, operations_text):\n",
    "        \"\"\"\n",
    "        從回應中提取操作編號列表\n",
    "        支援多種格式:\n",
    "        - [1, 2, 3, 4]\n",
    "        - 1, 2, 3, 4\n",
    "        - 1 2 3 4\n",
    "        - Operation 1, Operation 2, etc.\n",
    "        \"\"\"\n",
    "        operations = []\n",
    "        \n",
    "        # 移除 markdown 代碼塊標記\n",
    "        operations_text = re.sub(r'```(?:python|json)?\\s*', '', operations_text)\n",
    "        operations_text = operations_text.strip('`').strip()\n",
    "        \n",
    "        # 嘗試解析 JSON 格式 [1, 2, 3]\n",
    "        try:\n",
    "            # 尋找方括號中的內容\n",
    "            list_match = re.search(r'\\[([^\\]]+)\\]', operations_text)\n",
    "            if list_match:\n",
    "                list_content = list_match.group(1)\n",
    "                # 提取所有數字\n",
    "                numbers = re.findall(r'\\d+', list_content)\n",
    "                operations = [int(num) for num in numbers]\n",
    "                if operations:\n",
    "                    return operations\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 如果沒有方括號,嘗試直接提取所有數字\n",
    "        numbers = re.findall(r'\\d+', operations_text)\n",
    "        if numbers:\n",
    "            operations = [int(num) for num in numbers]\n",
    "            return operations\n",
    "        \n",
    "        # 如果以上都失敗,嘗試逐行處理\n",
    "        lines = operations_text.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # 提取該行中的所有數字\n",
    "            line_numbers = re.findall(r'\\d+', line)\n",
    "            operations.extend([int(num) for num in line_numbers])\n",
    "        \n",
    "        # 去重並排序\n",
    "        if operations:\n",
    "            operations = sorted(list(set(operations)))\n",
    "        \n",
    "        return operations\n",
    "\n",
    "\n",
    "def analyze_badminton_match(data_path, column_desc_path, rules_path, model_name=\"gemini-2.0-flash-exp\"):\n",
    "    \"\"\"\n",
    "    分析羽球比賽數據並識別適合的操作\n",
    "    \n",
    "    Args:\n",
    "        data_path: 比賽數據 CSV 文件路徑\n",
    "        column_desc_path: 欄位描述文件路徑\n",
    "        rules_path: 操作規則 JSON 文件路徑\n",
    "        model_name: 使用的模型名稱\n",
    "    \n",
    "    Returns:\n",
    "        list: 識別出的操作編號列表 (整數)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Reading badminton match data...\")\n",
    "    try:\n",
    "        match_data = read_badminton_data(data_path)\n",
    "        columns_desc_content = read_text_file(column_desc_path)\n",
    "        rules = read_json_file(rules_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading files: {e}\")\n",
    "        return []\n",
    "\n",
    "    column_descriptions = parse_column_descriptions(columns_desc_content)\n",
    "    setup_gemini_api(api_key, model_name)\n",
    "\n",
    "    data_sample = match_data.to_string()\n",
    "    data_description = f\"\"\"\n",
    "    one match data:\n",
    "    {data_sample}\n",
    "\n",
    "    Data shape: {match_data.shape[0]} rows, {match_data.shape[1]} columns\n",
    "    Columns: {', '.join(match_data.columns)}\n",
    "    \"\"\"\n",
    "\n",
    "    selector = BadmintonOperationSelector()\n",
    "    operations = selector.forward(data_description, column_descriptions, rules)\n",
    "\n",
    "    print(f\"✅ Identified {len(operations)} suitable operations:\")\n",
    "    for i, op in enumerate(operations, 1):\n",
    "        print(f\"{i}. Operation {op}\")\n",
    "\n",
    "    return operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e586506d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading badminton match data...\n",
      "✅ Identified 6 suitable operations:\n",
      "1. Operation 14\n",
      "2. Operation 4\n",
      "3. Operation 5\n",
      "4. Operation 15\n",
      "5. Operation 6\n",
      "6. Operation 8\n",
      "\n",
      "Final operations array: [14, 4, 5, 15, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "operations = analyze_badminton_match(\n",
    "    data_path=\"set1.csv\",\n",
    "    column_desc_path=\"data_description.txt\",\n",
    "    rules_path=\"operations_info.json\"\n",
    ")\n",
    "print(\"\\nFinal operations array:\", operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162d09a",
   "metadata": {},
   "source": [
    "將所挑選出來的操作寫入\"operations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "689bc29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ operations.json has been created with 6 operations.\n",
      "Selected operations: [14, 4, 5, 15, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 從 JSON 檔案讀取 operations\n",
    "original_operations_dict = read_json_file(\"operations_info.json\")\n",
    "\n",
    "# 你想要挑選的 operation 編號（根據實際需求修改這個 list）\n",
    "selected_numbers = operations\n",
    "\n",
    "# 根據 selected_numbers 選出對應操作，並從 1 開始重新編號\n",
    "filtered_operations = []\n",
    "for new_number, original_number in enumerate(selected_numbers, start=1):\n",
    "    # 將數字轉換為字串鍵來查找\n",
    "    key = str(original_number)\n",
    "    if key in original_operations_dict:\n",
    "        op_data = original_operations_dict[key]\n",
    "        filtered_operations.append({\n",
    "            \"number\": new_number,\n",
    "            \"operation\": op_data[\"operation\"],\n",
    "            \"description\": op_data[\"description\"]\n",
    "        })\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Operation {original_number} not found in operations_info.json\")\n",
    "\n",
    "# 新的 JSON 結構\n",
    "output_json = {\n",
    "    \"description\": \"Selected operations for badminton data analysis.\",\n",
    "    \"requirements\": [\n",
    "        \"The output must be based on the input data; do not hallucinate.\",\n",
    "        \"Give me the list of numbers.\"\n",
    "    ],\n",
    "    \"operations\": filtered_operations\n",
    "}\n",
    "\n",
    "# 寫入 JSON 檔案\n",
    "with open(\"operations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ operations.json has been created with {len(filtered_operations)} operations.\")\n",
    "print(f\"Selected operations: {selected_numbers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743109f4",
   "metadata": {},
   "source": [
    "# STEP 5\n",
    "\n",
    "篩選出最合適的1/2 operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e3f7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "def load_operations_from_json(json_file_path):\n",
    "    \"\"\"\n",
    "    Load operations from JSON file\n",
    "    支援兩種格式:\n",
    "    1. 舊格式: {\"1\": {\"operation\": \"...\", \"description\": \"...\"}, ...}\n",
    "    2. 新格式: {\"operations\": [{\"number\": 1, \"name\": \"...\", \"description\": \"...\"}, ...]}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = read_json_file(json_file_path)\n",
    "        \n",
    "        operations_data = []\n",
    "        \n",
    "        # 檢查是新格式還是舊格式\n",
    "        if 'operations' in data and isinstance(data['operations'], list):\n",
    "            # 新格式\n",
    "            operations_data = data['operations']\n",
    "        else:\n",
    "            # 舊格式: 數字字串作為鍵\n",
    "            for key in sorted(data.keys(), key=lambda x: int(x) if x.isdigit() else 0):\n",
    "                if key.isdigit():\n",
    "                    op_data = data[key]\n",
    "                    operations_data.append({\n",
    "                        'number': int(key),\n",
    "                        'name': op_data.get('operation', ''),\n",
    "                        'description': op_data.get('description', '')\n",
    "                    })\n",
    "        \n",
    "        # Create formatted operation strings for LLM processing\n",
    "        operation_strings = []\n",
    "        operation_details = []\n",
    "        \n",
    "        for op in operations_data:\n",
    "            number = op.get('number', '')\n",
    "            name = op.get('name', '')\n",
    "            description = op.get('description', '')\n",
    "            \n",
    "            # Format as: \"number. name: description\"\n",
    "            if number and name and description:\n",
    "                formatted_op = f\"{number}. {name}: {description}\"\n",
    "                operation_strings.append(formatted_op)\n",
    "                operation_details.append({\n",
    "                    'number': number,\n",
    "                    'name': name,\n",
    "                    'description': description,\n",
    "                    'formatted': formatted_op\n",
    "                })\n",
    "        \n",
    "        print(f\"從 {json_file_path} 成功載入 {len(operation_strings)} 個操作\")\n",
    "        return operation_details, operation_strings\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"錯誤: 找不到文件 {json_file_path}\")\n",
    "        return [], []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"錯誤: {json_file_path} 不是有效的 JSON 文件\")\n",
    "        return [], []\n",
    "    except Exception as e:\n",
    "        print(f\"載入操作時發生錯誤: {e}\")\n",
    "        return [], []\n",
    "\n",
    "\n",
    "def filter_operations_direct_gemini(api_key, operations_list, operation_details, data_sample, data_info, removal_percentage=0.25, model_name=\"gemini-2.0-flash\"):\n",
    "    \"\"\"\n",
    "    Use Gemini API directly to filter operations and return operation numbers\n",
    "    \"\"\"\n",
    "    gemini_lm = GeminiOpenAI(api_key=api_key, model_name=model_name)\n",
    "    \n",
    "    operations_count = len(operations_list)\n",
    "    operations_to_remove = int(operations_count * removal_percentage)\n",
    "    operations_to_keep = operations_count - operations_to_remove\n",
    "    \n",
    "    # Create numbered list of operations for easier reference\n",
    "    numbered_operations = \"\\n\".join([f\"{i+1}. {op}\" for i, op in enumerate(operations_list)])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "我有一個羽球比賽的資料集和 {operations_count} 個分析操作。\n",
    "\n",
    "資料樣本:\n",
    "{data_sample}\n",
    "\n",
    "資料集資訊:\n",
    "{data_info}\n",
    "\n",
    "操作清單:\n",
    "{numbered_operations}\n",
    "\n",
    "請幫我分析並移除 {operations_to_remove} 個最不合適的操作（約 {removal_percentage*100:.0f}%），保留 {operations_to_keep} 個最適合的操作。\n",
    "\n",
    "請考慮以下標準來決定移除哪些操作：\n",
    "1. 與實際資料欄位的相關性\n",
    "2. 在給定資料集結構下的可行性\n",
    "3. 對羽球比賽分析的實用價值\n",
    "4. 避免重複或過於相似的操作\n",
    "\n",
    "請先說明你的分析思路，然後**只提供要保留操作的編號**（從操作描述開頭提取的編號）。\n",
    "\n",
    "請用以下格式回答：\n",
    "\n",
    "分析思路：\n",
    "[你的分析]\n",
    "\n",
    "保留的操作編號：\n",
    "[編號1, 編號2, 編號3, ...]\n",
    "\"\"\"\n",
    "    \n",
    "    response = gemini_lm.basic_request(prompt)\n",
    "    \n",
    "    # Extract kept operation numbers from the response\n",
    "    kept_operation_numbers = extract_operation_numbers_from_response(response, operation_details)\n",
    "    \n",
    "    return kept_operation_numbers, response\n",
    "\n",
    "\n",
    "def extract_operation_numbers_from_response(response, operation_details):\n",
    "    \"\"\"\n",
    "    Extract the operation numbers to keep from Gemini's response\n",
    "    \"\"\"\n",
    "    kept_numbers = []\n",
    "    \n",
    "    # Look for the section with kept operation numbers\n",
    "    lines = response.split('\\n')\n",
    "    \n",
    "    # Find the start of the operations list\n",
    "    start_extracting = False\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Look for section headers\n",
    "        if any(keyword in line.lower() for keyword in ['保留的操作編號', '保留操作編號', '編號', 'numbers']):\n",
    "            start_extracting = True\n",
    "            # 檢查標題行本身是否包含數字\n",
    "            bracket_match = re.search(r'\\[(.*?)\\]', line)\n",
    "            if bracket_match:\n",
    "                numbers_text = bracket_match.group(1)\n",
    "                for item in numbers_text.split(','):\n",
    "                    number = re.search(r'(\\d+)', item.strip())\n",
    "                    if number:\n",
    "                        kept_numbers.append(int(number.group(1)))\n",
    "                if kept_numbers:\n",
    "                    break\n",
    "            continue\n",
    "        \n",
    "        if start_extracting and line:\n",
    "            # Try to extract numbers from various formats\n",
    "            bracket_match = re.search(r'\\[(.*?)\\]', line)\n",
    "            if bracket_match:\n",
    "                numbers_text = bracket_match.group(1)\n",
    "                for item in numbers_text.split(','):\n",
    "                    number = re.search(r'(\\d+)', item.strip())\n",
    "                    if number:\n",
    "                        kept_numbers.append(int(number.group(1)))\n",
    "                break\n",
    "            \n",
    "            # Format 2: Numbered list or comma-separated numbers\n",
    "            numbers = re.findall(r'\\b(\\d+)\\b', line)\n",
    "            if numbers:\n",
    "                kept_numbers.extend([int(n) for n in numbers])\n",
    "                break\n",
    "    \n",
    "    # Remove duplicates and validate against available operations\n",
    "    valid_numbers = []\n",
    "    available_numbers = [detail['number'] for detail in operation_details]\n",
    "    \n",
    "    for num in kept_numbers:\n",
    "        if num in available_numbers and num not in valid_numbers:\n",
    "            valid_numbers.append(num)\n",
    "    \n",
    "    return valid_numbers\n",
    "\n",
    "\n",
    "def get_data_summary(dataframe):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary of the dataset\n",
    "    \"\"\"\n",
    "    summary = f\"\"\"\n",
    "資料集概要:\n",
    "- 總行數: {dataframe.shape[0]}\n",
    "- 總列數: {dataframe.shape[1]}\n",
    "- 欄位名稱: {', '.join(dataframe.columns)}\n",
    "\n",
    "各欄位資訊:\n",
    "\"\"\"\n",
    "    \n",
    "    for col in dataframe.columns:\n",
    "        col_info = f\"  - {col}: \"\n",
    "        if dataframe[col].dtype in ['object', 'string']:\n",
    "            unique_values = dataframe[col].unique()[:10]\n",
    "            col_info += f\"類別型資料, 獨特值範例: {', '.join(map(str, unique_values))}\"\n",
    "        else:\n",
    "            col_info += f\"數值型資料, 範圍: {dataframe[col].min()} - {dataframe[col].max()}\"\n",
    "        \n",
    "        summary += col_info + \"\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "def filter_badminton_operations(operations_list, operation_details, dataframe, removal_percentage=0.25, model_name=\"gemini-2.0-flash\"):\n",
    "    \"\"\"\n",
    "    Main function to filter operations using Gemini LLM and return operation numbers\n",
    "    (只保留方法二: 直接 Gemini API)\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"Gemini_API\")\n",
    "    \n",
    "    print(f\"原始操作數量: {len(operations_list)}\")\n",
    "    print(\"原始操作清單:\")\n",
    "    for i, op in enumerate(operations_list, 1):\n",
    "        print(f\"  {i}. {op}\")\n",
    "    \n",
    "    # Get data summary\n",
    "    data_summary = get_data_summary(dataframe)\n",
    "    data_sample = dataframe.head(5).to_string()\n",
    "    \n",
    "    print(f\"\\n使用 Gemini LLM 過濾操作 (移除 {removal_percentage*100:.0f}%)...\")\n",
    "    \n",
    "    # Method 2: Direct Gemini API call\n",
    "    try:\n",
    "        print(\"方法: 直接使用 Gemini API...\")\n",
    "        direct_filtered_numbers, gemini_response = filter_operations_direct_gemini(\n",
    "            api_key, \n",
    "            operations_list, \n",
    "            operation_details,\n",
    "            data_sample, \n",
    "            data_summary, \n",
    "            removal_percentage,\n",
    "            model_name\n",
    "        )\n",
    "        print(f\"直接 API 方法保留了 {len(direct_filtered_numbers)} 個操作編號\")\n",
    "        \n",
    "        print(\"\\nGemini 回應:\")\n",
    "        print(\"=\"*50)\n",
    "        print(gemini_response)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"直接 API 方法失敗: {e}\")\n",
    "        direct_filtered_numbers = []\n",
    "    \n",
    "    # Final results\n",
    "    if direct_filtered_numbers:\n",
    "        final_operation_numbers = direct_filtered_numbers\n",
    "        print(f\"\\n使用直接 API 方法的結果\")\n",
    "    else:\n",
    "        # Fallback\n",
    "        target_count = int(len(operations_list) * (1 - removal_percentage))\n",
    "        final_operation_numbers = [detail['number'] for detail in operation_details[:target_count]]\n",
    "        print(f\"\\n直接 API 方法失敗，使用前 {target_count} 個操作編號作為備案\")\n",
    "    \n",
    "    print(f\"\\n最終保留的操作編號 ({len(final_operation_numbers)} 個):\")\n",
    "    for i, number in enumerate(final_operation_numbers, 1):\n",
    "        for detail in operation_details:\n",
    "            if detail['number'] == number:\n",
    "                print(f\"  {i}. 編號 {number}: {detail['name']}\")\n",
    "                break\n",
    "    \n",
    "    return final_operation_numbers\n",
    "\n",
    "\n",
    "def create_filtered_operations_json(original_json_path, filtered_numbers, output_path=\"filtered_operations.json\"):\n",
    "    \"\"\"\n",
    "    創建過濾後的操作 JSON 文件\n",
    "    \"\"\"\n",
    "    # 讀取原始 JSON\n",
    "    all_data = read_json_file(original_json_path)\n",
    "    \n",
    "    # 處理兩種格式\n",
    "    if 'operations' in all_data and isinstance(all_data['operations'], list):\n",
    "        # 新格式\n",
    "        original_operations = all_data['operations']\n",
    "    else:\n",
    "        # 舊格式: 轉換為新格式\n",
    "        original_operations = []\n",
    "        for key in sorted(all_data.keys(), key=lambda x: int(x) if x.isdigit() else 0):\n",
    "            if key.isdigit():\n",
    "                op_data = all_data[key]\n",
    "                original_operations.append({\n",
    "                    'number': int(key),\n",
    "                    'name': op_data.get('operation', ''),\n",
    "                    'description': op_data.get('description', '')\n",
    "                })\n",
    "    \n",
    "    # 根據 filtered_numbers 選出對應操作，並從 1 開始重新編號\n",
    "    filtered_operations = []\n",
    "    for new_number, original_number in enumerate(filtered_numbers, start=1):\n",
    "        for op in original_operations:\n",
    "            if op[\"number\"] == original_number:\n",
    "                # 使用 'name' 或 'operation' 欄位\n",
    "                op_name = op.get('name') or op.get('operation', '')\n",
    "                filtered_operations.append({\n",
    "                    \"number\": new_number,\n",
    "                    \"operation\": op_name,\n",
    "                    \"description\": op[\"description\"]\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    # 新的 JSON 結構\n",
    "    output_json = {\n",
    "        \"description\": \"Selected operations for badminton data analysis.\",\n",
    "        \"requirements\": [\n",
    "            \"The output must be based on the input data; do not hallucinate.\",\n",
    "            \"Give me the list of numbers.\"\n",
    "        ],\n",
    "        \"operations\": filtered_operations\n",
    "    }\n",
    "    \n",
    "    # 寫入 JSON 檔案\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_json, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"✅ {output_path} has been created with {len(filtered_operations)} operations.\")\n",
    "    return filtered_operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc4facc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從 operations_info.json 成功載入 15 個操作\n",
      "原始操作數量: 15\n",
      "原始操作清單:\n",
      "  1. 1. write: Generate text based on the table after other operations, providing insights and conclusions. This operation transforms data into a readable news story. Useful functions: N/A\n",
      "  2. 2. select_row: Select a subset of rows based on specific criteria (e.g., score range, player, rally length). This allows focusing on particular game situations. Useful functions: `df.loc[]`, `df.iloc[]`\n",
      "  3. 3. select_column: Select specific columns relevant to the analysis (e.g., `type`, `time`, `roundscore_A`, `roundscore_B`). Useful functions: `df[['column1', 'column2']]`\n",
      "  4. 4. groupby: Group rows based on one or more columns (e.g., `player`, `type`, `lose_reason`) to calculate aggregate statistics. This helps identify trends and patterns. Useful functions: `df.groupby()`\n",
      "  5. 5. aggregate: Calculate summary statistics (e.g., mean, median, standard deviation, count) for grouped data. This quantifies trends and differences. Useful functions: `df.agg()`\n",
      "  6. 6. sort: Sort the data by one or more columns (e.g., `time`, `rally`, `roundscore_A`) to identify trends and patterns over time or score progression. Useful functions: `df.sort_values()`\n",
      "  7. 7. filter: Remove rows based on specified conditions (e.g., rallies shorter than a certain time, specific `lose_reasons`). Allows focusing on relevant data subsets. Useful functions: `df[df['column'] > value]`\n",
      "  8. 8. calculate: Create new columns based on existing data (e.g., rally duration, time between shots, score difference). This generates features for further analysis. Useful functions: `df['new_column'] = ...`\n",
      "  9. 9. merge: Combine data from different sources or tables based on a common column. Useful functions: `pd.merge()`\n",
      "  10. 10. join: Combine columns of two potentially different-sized DataFrames into a single DataFrame. Useful functions: `df.join()`\n",
      "  11. 11. pivot_table: Summarize data by creating a table that aggregates values based on two or more columns. Useful functions: `pd.pivot_table()`\n",
      "  12. 12. rolling_window: Calculate statistics over a moving window of rows (e.g., average rally duration over the last 10 rallies). Useful functions: `df.rolling()`\n",
      "  13. 13. shift: Shift the values in a column by a certain number of rows.  Useful functions: `df['column'].shift()`\n",
      "  14. 14. value_counts: Count the occurrences of each unique value in a column. Useful functions: `df['column'].value_counts()`\n",
      "  15. 15. corr: Calculate the correlation between columns. Useful functions: `df.corr()`\n",
      "\n",
      "使用 Gemini LLM 過濾操作 (移除 20%)...\n",
      "方法: 直接使用 Gemini API...\n",
      "直接 API 方法保留了 12 個操作編號\n",
      "\n",
      "Gemini 回應:\n",
      "==================================================\n",
      "分析思路：\n",
      "\n",
      "首先，我會考慮資料集的特性。資料集包含羽球比賽中每一回合的詳細資訊，例如擊球類型、位置、得分等。基於這些資訊，一些操作比其他操作更適合進行深入分析。\n",
      "\n",
      "1. **不相關性**: `merge` 和 `join` 操作需要額外的資料集進行合併。由於我們只有一個資料集，因此這兩個操作不直接適用。雖然可以考慮自合併，但其價值不大，不如其他操作。\n",
      "2. **可行性**: `rolling_window` 雖然理論上可行，例如可以分析過去幾回合的平均擊球高度，但在這個資料集中，回合的順序可能並不代表時間上的連續性，因為資料是按照`rally`和`ball_round`排序，無法反映比賽的真實時間流逝，因此其實用性較低。\n",
      "3. **實用價值**: 剩下的操作都直接或間接地提供了有價值的羽球比賽分析資訊。例如，`groupby` 可以分析不同擊球類型或失誤原因的頻率，`calculate` 可以計算回合持續時間，`corr` 可以找出不同變數之間的關聯性。`value_counts` 可以提供關於特定欄位（例如，球的種類）的統計資訊，而 `pivot_table` 可以用二維的方式呈現數據，更容易理解和分析。`select_row`，`select_column`，`sort`和`filter`是基本但有力的工具，幫助我們聚焦於數據的子集，以便更好地分析。最後，`write`可以將分析結果轉化為易於理解的文字報告。\n",
      "\n",
      "綜上所述，`merge`、`join`和 `rolling_window` 相對不適合，因為它們或者需要額外的資料集，或者在這個資料集上的應用價值有限。\n",
      "\n",
      "保留的操作編號：\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 14, 15]\n",
      "\n",
      "==================================================\n",
      "\n",
      "使用直接 API 方法的結果\n",
      "\n",
      "最終保留的操作編號 (12 個):\n",
      "  1. 編號 1: write\n",
      "  2. 編號 2: select_row\n",
      "  3. 編號 3: select_column\n",
      "  4. 編號 4: groupby\n",
      "  5. 編號 5: aggregate\n",
      "  6. 編號 6: sort\n",
      "  7. 編號 7: filter\n",
      "  8. 編號 8: calculate\n",
      "  9. 編號 11: pivot_table\n",
      "  10. 編號 13: shift\n",
      "  11. 編號 14: value_counts\n",
      "  12. 編號 15: corr\n",
      "\n",
      "保留的操作編號清單: [1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 14, 15]\n",
      "✅ filtered_operations.json has been created with 6 operations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'number': 1,\n",
       "  'operation': 'value_counts',\n",
       "  'description': \"Count the occurrences of each unique value in a column. Useful functions: `df['column'].value_counts()`\"},\n",
       " {'number': 2,\n",
       "  'operation': 'groupby',\n",
       "  'description': 'Group rows based on one or more columns (e.g., `player`, `type`, `lose_reason`) to calculate aggregate statistics. This helps identify trends and patterns. Useful functions: `df.groupby()`'},\n",
       " {'number': 3,\n",
       "  'operation': 'aggregate',\n",
       "  'description': 'Calculate summary statistics (e.g., mean, median, standard deviation, count) for grouped data. This quantifies trends and differences. Useful functions: `df.agg()`'},\n",
       " {'number': 4,\n",
       "  'operation': 'corr',\n",
       "  'description': 'Calculate the correlation between columns. Useful functions: `df.corr()`'},\n",
       " {'number': 5,\n",
       "  'operation': 'sort',\n",
       "  'description': 'Sort the data by one or more columns (e.g., `time`, `rally`, `roundscore_A`) to identify trends and patterns over time or score progression. Useful functions: `df.sort_values()`'},\n",
       " {'number': 6,\n",
       "  'operation': 'calculate',\n",
       "  'description': \"Create new columns based on existing data (e.g., rally duration, time between shots, score difference). This generates features for further analysis. Useful functions: `df['new_column'] = ...`\"}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load operations from JSON file\n",
    "json_file_path = \"operations_info.json\"  # 支援舊格式\n",
    "operation_details, operation_strings = load_operations_from_json(json_file_path)\n",
    "\n",
    "# Load badminton data\n",
    "example_df = read_badminton_data('set1.csv')\n",
    "\n",
    "# Filter operations and get operation numbers\n",
    "filtered_operation_numbers = filter_badminton_operations(\n",
    "    operation_strings,\n",
    "    operation_details,\n",
    "    example_df, \n",
    "    removal_percentage=0.2\n",
    ")\n",
    "\n",
    "print(f\"\\n保留的操作編號清單: {filtered_operation_numbers}\")\n",
    "\n",
    "# 創建過濾後的 JSON 文件\n",
    "create_filtered_operations_json(\n",
    "    \"operations.json\",\n",
    "    filtered_operation_numbers,\n",
    "    \"filtered_operations.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c31ebe",
   "metadata": {},
   "source": [
    "# STEP 6\n",
    "\n",
    "根據真實table只保留重要70%操作，保留'write' 'select_col' 'select_row'三個重要操作，到'selected_operations.json'\n",
    "\n",
    "操作提取已完成!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4cef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正式版 - 使用 Gemini 過濾羽球比賽分析操作\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dspy\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "\n",
    "def get_data_summary(dataframe):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary of the dataset\n",
    "    \"\"\"\n",
    "    summary = f\"資料集概要:\\n- 總行數: {dataframe.shape[0]}\\n- 總列數: {dataframe.shape[1]}\\n- 欄位名稱: {', '.join(dataframe.columns)}\\n\\n各欄位資訊:\\n\"\n",
    "    for col in dataframe.columns:\n",
    "        summary += f\"  - {col}: \"\n",
    "        if dataframe[col].dtype in ['object', 'string']:\n",
    "            summary += f\"類別型資料, 獨特值範例: {', '.join(map(str, dataframe[col].unique()[:10]))}\\n\"\n",
    "        else:\n",
    "            summary += f\"數值型資料, 範圍: {dataframe[col].min()} - {dataframe[col].max()}\\n\"\n",
    "    return summary\n",
    "\n",
    "def extract_operation_numbers_from_response(response):\n",
    "    \"\"\"\n",
    "    從回應中提取操作編號列表\n",
    "    支援多種格式\n",
    "    \"\"\"\n",
    "    # 方法1: 匹配代碼塊中的數組\n",
    "    pattern1 = r'```\\s*\\[([\\d,\\s]+)\\]\\s*```'\n",
    "    match = re.search(pattern1, response)\n",
    "    \n",
    "    if match:\n",
    "        array_str = match.group(1)\n",
    "        operation_list = [int(num) for num in array_str.replace(' ', '').split(',')]\n",
    "        print(f\"提取到操作列表: {operation_list}\")\n",
    "        return operation_list\n",
    "    \n",
    "    # 方法2: 匹配普通方括號中的數組\n",
    "    pattern2 = r'\\[([\\d,\\s]+)\\]'\n",
    "    match = re.search(pattern2, response)\n",
    "    \n",
    "    if match:\n",
    "        array_str = match.group(1)\n",
    "        operation_list = [int(num) for num in array_str.replace(' ', '').split(',')]\n",
    "        print(f\"提取到操作列表: {operation_list}\")\n",
    "        return operation_list\n",
    "    \n",
    "    # 方法3: 提取所有數字\n",
    "    numbers = re.findall(r'\\b(\\d+)\\b', response)\n",
    "    if numbers:\n",
    "        operation_list = [int(num) for num in numbers]\n",
    "        print(f\"提取到操作列表: {operation_list}\")\n",
    "        return operation_list\n",
    "    \n",
    "    print(\"⚠️ 未找到排序數組\")\n",
    "    return []\n",
    "\n",
    "def filter_badminton_operations(operation_details, operation_strings, df, api_key, outline_path='outline.txt', model_name=\"gemini-2.0-flash\", max_retries=3):\n",
    "    \"\"\"\n",
    "    使用 Gemini 根據重要性排序操作\n",
    "    \n",
    "    Args:\n",
    "        operation_details: 操作詳細資訊列表\n",
    "        operation_strings: 操作格式化字串列表\n",
    "        df: 數據框\n",
    "        api_key: API 金鑰\n",
    "        outline_path: 大綱文件路徑\n",
    "        model_name: 模型名稱\n",
    "        max_retries: 最大重試次數\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (排序後的操作編號列表, 完整回應)\n",
    "    \"\"\"\n",
    "    gemini = GeminiOpenAI(api_key=api_key, model_name=model_name)\n",
    "    data_summary = get_data_summary(df)\n",
    "    \n",
    "    # 限制資料樣本大小\n",
    "    data_sample = df.head(10).to_string()\n",
    "    if len(data_sample) > 3000:\n",
    "        data_sample = data_sample[:3000] + \"...\\n[資料已截斷]\"\n",
    "    \n",
    "    outline = read_text_file(outline_path)\n",
    "    \n",
    "    print(f\"操作數量: {len(operation_strings)}\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "我有一個撰寫新聞的大綱與比賽的資料集和 {len(operation_strings)} 個分析操作，請依據操作重要性排序(由高到低)。\n",
    "\n",
    "大綱:\n",
    "{outline}\n",
    "\n",
    "資料樣本:\n",
    "{data_sample}\n",
    "\n",
    "資料集資訊:\n",
    "{data_summary}\n",
    "\n",
    "操作清單:\n",
    "{chr(10).join(operation_strings)}\n",
    "\n",
    "請先根據 chain-of-thought 分析，然後將操作編號根據重要性排序，每個編號僅在陣列中出現一次，陣列長度應為 {len(operation_strings)}。\n",
    "\n",
    "最後請以以下格式輸出排序結果:[1, 2, 3, ...]\"\"\"\n",
    "    \n",
    "    response = gemini.basic_request(prompt, max_retries=max_retries)\n",
    "    \n",
    "    # 檢查是否為錯誤回應\n",
    "    if \"⚠️\" in response:\n",
    "        print(f\"❌ API 回應錯誤\")\n",
    "        return [], response\n",
    "    \n",
    "    return extract_operation_numbers_from_response(response), response\n",
    "\n",
    "def create_selected_operations_json(operation_details, sorted_numbers, keep_percentage=0.7, force_include=[1, 2, 3], output_path=\"selected_operations.json\"):\n",
    "    \"\"\"\n",
    "    創建選擇的操作 JSON 文件\n",
    "    \n",
    "    Args:\n",
    "        operation_details: 操作詳細資訊列表\n",
    "        sorted_numbers: 排序後的操作編號列表\n",
    "        keep_percentage: 保留比例\n",
    "        force_include: 強制包含的操作編號\n",
    "        output_path: 輸出文件路徑\n",
    "    \n",
    "    Returns:\n",
    "        list: 選擇的操作列表\n",
    "    \"\"\"\n",
    "    # 計算要保留的操作數量\n",
    "    keep_count = int(keep_percentage * len(sorted_numbers))\n",
    "    \n",
    "    # 選擇前 N 個操作\n",
    "    selected_numbers = sorted_numbers[:keep_count]\n",
    "    \n",
    "    # 確保強制包含的操作在列表中\n",
    "    selected_numbers = list(set(selected_numbers) | set(force_include))\n",
    "    \n",
    "    print(f\"選擇了 {len(selected_numbers)} 個操作 (保留比例: {keep_percentage*100:.0f}%)\")\n",
    "    print(f\"選擇的操作編號: {selected_numbers}\")\n",
    "    \n",
    "    # 創建新的操作列表\n",
    "    new_operations = []\n",
    "    for new_id, num in enumerate(selected_numbers, 1):\n",
    "        for detail in operation_details:\n",
    "            if int(detail['number']) == int(num):\n",
    "                new_operations.append({\n",
    "                    'number': new_id,\n",
    "                    'operation': detail['operation'],\n",
    "                    'description': detail['description']\n",
    "                })\n",
    "                break\n",
    "    \n",
    "    # 寫入 JSON 文件\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(new_operations, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"✅ {output_path} has been created with {len(new_operations)} operations.\")\n",
    "    return new_operations\n",
    "\n",
    "def read_badminton_data(file_path):\n",
    "    \"\"\"\n",
    "    讀取羽球比賽數據 CSV 文件\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(file_path, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7229122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從 operations_info.json 成功載入 15 個操作\n",
      "操作數量: 15\n",
      "提取到操作列表: [1, 3, 4, 5, 14, 8, 6, 2, 7, 11, 12, 13, 15, 9, 10]\n",
      "完整回應:\n",
      "Let's analyze the importance of each operation for generating badminton news from the given dataset. The goal is to extract insights that are newsworthy and insightful for badminton fans, while adhering to the restriction of avoiding common sense observations.\n",
      "\n",
      "Here's a chain of thought process:\n",
      "\n",
      "* **Essential for initial overview and context:**\n",
      "    * **1. Observe the outcome of the game and the final score:** This is the most basic information. Understanding who won and by how much is fundamental to any news report. Thus, calculating final scores is vital.\n",
      "    * **2. The duration of the entire competition:** The length of the match puts the result into context. A long, grueling match tells a different story than a quick victory.  So, total time is vital.\n",
      "\n",
      "* **Core for understanding game dynamics:**\n",
      "    * **Analyzing point scoring patterns and trends:** How were points scored? Where there extended rallies, or was one player dominating?\n",
      "        * **Calculate/Aggregate score differences and trends:** How did one player lead? Were there comebacks?\n",
      "    * **Understanding the rally structure and common plays:**\n",
      "        * **Analyzing common shot types and how points were won or lost:** What were the most common plays leading to points scored or mistakes?\n",
      "\n",
      "* **Operations contributing to specific insights:**\n",
      "    * Operations contributing to understanding the most common point-scoring patterns.\n",
      "        * **`value_counts`**: This operation is crucial for determining the frequency of different shot types (`type`) and the reasons for losing points (`lose_reason`). This will reveal which strategies are most effective and where players make the most mistakes.\n",
      "        * **`groupby` and `aggregate`**: Grouping by player and then by shot type to find out common play/strategy. We can also analyze win/lose reasons for each player to identify weaknesses and strengths.\n",
      "        * **`calculate`**: Create new columns for score difference and rally duration. This helps in analyzing momentum swings and the impact of long rallies.\n",
      "\n",
      "* **Operations useful for deeper analysis (but less critical for basic reporting):**\n",
      "    * **`sort`**: Sorting is useful for examining the chronological order of events, especially score changes. It allows for understanding momentum and crucial turning points.\n",
      "    * **`select_row`**: This will enable focusing on important moments (e.g., when a player is close to winning), which may reveal interesting strategies or psychological factors.\n",
      "    * **`filter`**: If certain anomalies needed filtering out (e.g., very short or long rallies, outliers).\n",
      "\n",
      "* **Less critical operations for initial news report generation:**\n",
      "    * **`pivot_table`**:  Pivot tables can be useful for summarizing data in a more organized way, but not essential.\n",
      "    * **`rolling_window`**: Calculating rolling statistics could be useful for identifying trends in performance over time, but this is a more advanced analysis.\n",
      "    * **`shift`**: Shifting data can be used to calculate differences between consecutive rallies or scores, providing insights into momentum changes. Could enhance reporting, but not essential at the start.\n",
      "    * **`merge` and `join`**: These operations are only useful if there are additional data sources.  Since we only have one dataset, they are not essential at all.\n",
      "    * **`corr`**: Correlation may not be too relevant in generating the initial news.\n",
      "\n",
      "* **Final Step:**\n",
      "    * **`write`**: Translates analysis into readable article.\n",
      "\n",
      "Therefore, based on this chain of thought, the operations can be ranked in the following order:\n",
      "\n",
      "[1, 3, 4, 5, 14, 8, 6, 2, 7, 11, 12, 13, 15, 9, 10]\n",
      "\n",
      "\n",
      "排序後的操作編號: [1, 3, 4, 5, 14, 8, 6, 2, 7, 11, 12, 13, 15, 9, 10]\n",
      "選擇了 10 個操作 (保留比例: 70%)\n",
      "選擇的操作編號: [1, 2, 3, 4, 5, 6, 7, 8, 11, 14]\n",
      "✅ selected_operations.json has been created with 10 operations.\n"
     ]
    }
   ],
   "source": [
    "# 載入操作\n",
    "json_file_path = \"operations_info.json\"\n",
    "operation_details, operation_strings = load_operations_from_json(json_file_path)\n",
    "\n",
    "# 載入數據\n",
    "df = read_badminton_data(\"filtered_set1.csv\")\n",
    "\n",
    "# 獲取 API 金鑰\n",
    "api_key = os.getenv(\"Gemini_API\") \n",
    "# 排序操作\n",
    "sorted_numbers, response = filter_badminton_operations(\n",
    "    operation_details, \n",
    "    operation_strings, \n",
    "    df, \n",
    "    api_key, \n",
    "    outline_path='main.txt'\n",
    ")\n",
    "\n",
    "print(f\"完整回應:\\n{response}\\n\")\n",
    "print(f\"排序後的操作編號: {sorted_numbers}\")\n",
    "\n",
    "# 創建選擇的操作 JSON\n",
    "selected_ops = create_selected_operations_json(\n",
    "    operation_details,\n",
    "    sorted_numbers,\n",
    "    keep_percentage=0.7,\n",
    "    force_include=[1, 2, 3],\n",
    "    output_path=\"selected_operations.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93c578c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有操作編號: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "總操作數量: 9\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 讀取 filtered_operations.json\n",
    "with open('filtered_operations.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 取得目前最大 number\n",
    "existing_numbers = [op['number'] for op in data['operations']]\n",
    "max_number = max(existing_numbers) if existing_numbers else 0\n",
    "\n",
    "# 新增的 operations (注意使用 'operation' 而非 'name')\n",
    "new_operations = [\n",
    "    {\n",
    "        \"number\": max_number + 1,\n",
    "        \"operation\": \"select_row\",\n",
    "        \"description\": \"Selects rows based on their row indices.\"\n",
    "    },\n",
    "    {\n",
    "        \"number\": max_number + 2,\n",
    "        \"operation\": \"select_col\",\n",
    "        \"description\": \"Selects columns based on their column names.\"\n",
    "    },\n",
    "    {\n",
    "        \"number\": max_number + 3,\n",
    "        \"operation\": \"write\",\n",
    "        \"description\": \"If the table is small enough, generates text based on the tables using the LLM; represents the leaf node of the tree.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 將新操作加入原始資料\n",
    "data['operations'].extend(new_operations)\n",
    "\n",
    "# 寫回 JSON 檔\n",
    "with open('selected_operations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 輸出所有操作的 number 列表\n",
    "all_numbers = [op['number'] for op in data['operations']]\n",
    "print(f\"所有操作編號: {all_numbers}\")\n",
    "print(f\"總操作數量: {len(all_numbers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf7a14",
   "metadata": {},
   "source": [
    "# STEP 7\n",
    "\n",
    "根據Table,得到要執行的操作與參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a65ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "class ContentPlanner:\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = GeminiOpenAI(api_key=api_key, model_name=model_name)\n",
    "        \n",
    "    def generate_operations(self, tables, table_description, operation_description, \n",
    "                          operation_history, operation_pool, max_depth=5, max_degree=3, outline_path='main.txt'):\n",
    "        \"\"\"\n",
    "        使用Gemini生成operations和arguments\n",
    "        \"\"\"\n",
    "        \n",
    "        # 構建完整的提示詞\n",
    "        prompt = f\"\"\"System : You are a content planner for the report. Please follow the outline. Please select candidate Operations and corresponding Arguments from the Operation Pool based on the input Tables and Operation History. These candidate Operations will be the next Operation in the Operation History .\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in English .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The length of Operation History must be less than or equal to {max_depth}.\n",
    "5. The number of Operations must be less than or equal to {max_degree}.\n",
    "6. Only select Operations from the Operation Pool .\n",
    "7. Arguments must match the format required by the corresponding Operations .\n",
    "8. Operations & Arguments must follow this format : [ operation_1 ( argument_1 , ...) , operation_2 ( argument_2 , ...) , operation_3 ( argument_3 , ...) , ...]\n",
    "9. Only output Operations & Arguments !\n",
    "10. If Table is big or Level is low, it should be more Operations include select_col or select_row not write.\n",
    "11. If the length of Operation History is short, then more operations or more arguments.\n",
    "12. Write operations do not need argument.\n",
    "\n",
    "#outline\n",
    "{read_text_file(outline_path)}\n",
    "\n",
    "# Table Description\n",
    "{table_description}\n",
    "\n",
    "# Operation Description\n",
    "{json.dumps(operation_description, indent=2, ensure_ascii=False)}\n",
    "\n",
    "User : # Test\n",
    "## Tables\n",
    "{tables}\n",
    "\n",
    "## Operation History\n",
    "{operation_history}\n",
    "\n",
    "## Operation Pool\n",
    "{operation_pool}\n",
    "\n",
    "## Operations & Arguments\"\"\"\n",
    "\n",
    "        try:\n",
    "            print(\"正在向Gemini發送請求...\")\n",
    "            response = self.model.basic_request(prompt)\n",
    "            \n",
    "            if response and \"⚠️\" not in response:\n",
    "                print(\"成功獲得Gemini回應\")\n",
    "                return response.strip()\n",
    "            else:\n",
    "                print(\"Gemini回應為空或出現錯誤\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Gemini API請求失敗: {e}\")\n",
    "            return None\n",
    "\n",
    "def run_content_planner(csv_path='filtered_set1.csv', \n",
    "                       table_desc_path='filtered_data_description.txt',\n",
    "                       operations_path='selected_operations.json',\n",
    "                       outline_path='analyze_response.txt',\n",
    "                       max_depth=5,\n",
    "                       max_degree=5):\n",
    "    \"\"\"\n",
    "    運行內容規劃器\n",
    "    \n",
    "    Args:\n",
    "        csv_path: CSV 數據文件路徑\n",
    "        table_desc_path: 表格描述文件路徑\n",
    "        operations_path: 操作描述 JSON 文件路徑\n",
    "        outline_path: 大綱文件路徑\n",
    "        max_depth: 最大深度\n",
    "        max_degree: 最大分支度\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (操作和參數字串, 更新後的操作歷史, 當前層級)\n",
    "    \"\"\"\n",
    "    # 設置API密鑰\n",
    "    api_key = os.getenv(\"Gemini_API\")\n",
    "    if not api_key:\n",
    "        print(\"❌ Gemini_API 環境變數未設定\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(\"Content Planner for Badminton Game Report\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"正在載入數據...\")\n",
    "    \n",
    "    # 讀取CSV檔案\n",
    "    TABLES = pd.read_csv(csv_path)\n",
    "    tables_str = TABLES.head(10).to_string()  # 限制顯示前10行\n",
    "    if len(tables_str) > 3000:\n",
    "        tables_str = tables_str[:3000] + \"...\\n[資料已截斷]\"\n",
    "    print(f\"成功載入CSV: {TABLES.shape[0]} 行, {TABLES.shape[1]} 列\")\n",
    "    \n",
    "    # 讀取表格描述\n",
    "    TABLE_DESCRIPTION = read_text_file(table_desc_path)\n",
    "    if not TABLE_DESCRIPTION:\n",
    "        TABLE_DESCRIPTION = \"No table description available\"\n",
    "    print(f\"載入表格描述: {len(TABLE_DESCRIPTION)} 字符\")\n",
    "    \n",
    "    # 讀取操作描述\n",
    "    OPERATION_DESCRIPTION = read_json_file(operations_path)\n",
    "    print(f\"載入操作描述 JSON\")\n",
    "    \n",
    "    # 設置其他變數\n",
    "    OPERATION_HISTORY = ['root(None)']\n",
    "    Level = 0\n",
    "    \n",
    "    # 從操作描述中提取操作池\n",
    "    # 處理新格式: 直接是操作列表\n",
    "    if isinstance(OPERATION_DESCRIPTION, list):\n",
    "        OPERATION_POOL = [op.get('operation', op.get('name', '')) for op in OPERATION_DESCRIPTION if op.get('operation') or op.get('name')]\n",
    "    # 處理舊格式: {\"operations\": [...]}\n",
    "    elif isinstance(OPERATION_DESCRIPTION, dict) and 'operations' in OPERATION_DESCRIPTION:\n",
    "        OPERATION_POOL = [op.get('operation', op.get('name', '')) for op in OPERATION_DESCRIPTION['operations'] if op.get('operation') or op.get('name')]\n",
    "    else:\n",
    "        print(\"❌ 無法識別的 JSON 格式\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"操作池 ({len(OPERATION_POOL)} 個): {OPERATION_POOL}\")\n",
    "    print(f\"操作歷史: {OPERATION_HISTORY}\")\n",
    "    \n",
    "    # 初始化內容規劃器\n",
    "    planner = ContentPlanner(api_key)\n",
    "    \n",
    "    # 生成操作和參數\n",
    "    print(\"\\n開始生成操作和參數...\")\n",
    "    operations_and_arguments = planner.generate_operations(\n",
    "        tables=tables_str,\n",
    "        table_description=TABLE_DESCRIPTION,\n",
    "        operation_description=OPERATION_DESCRIPTION,\n",
    "        operation_history=OPERATION_HISTORY,\n",
    "        operation_pool=OPERATION_POOL,\n",
    "        max_depth=max_depth,\n",
    "        max_degree=max_degree,\n",
    "        outline_path=outline_path\n",
    "    )\n",
    "    \n",
    "    # 更新操作歷史\n",
    "    if operations_and_arguments:\n",
    "        OPERATION_HISTORY.append(operations_and_arguments)\n",
    "        Level += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GEMINI 輸出結果:\")\n",
    "        print(\"=\"*50)\n",
    "        print(operations_and_arguments)\n",
    "        print(\"=\"*50)\n",
    "        print(f\"當前層級: {Level}\")\n",
    "        print(f\"更新後的操作歷史: {OPERATION_HISTORY}\")\n",
    "        \n",
    "        return operations_and_arguments, OPERATION_HISTORY, Level\n",
    "    else:\n",
    "        print(\"❌ 未能生成操作和參數\")\n",
    "        return None, OPERATION_HISTORY, Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704d252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Planner for Badminton Game Report\n",
      "==================================================\n",
      "正在載入數據...\n",
      "成功載入CSV: 315 行, 9 列\n",
      "載入表格描述: 481 字符\n",
      "載入操作描述 JSON\n",
      "操作池 (9 個): ['value_counts', 'groupby', 'aggregate', 'corr', 'sort', 'calculate', 'select_row', 'select_col', 'write']\n",
      "操作歷史: ['root(None)']\n",
      "\n",
      "開始生成操作和參數...\n",
      "正在向Gemini發送請求...\n",
      "嘗試 1/3 失敗: Error code: 503 - [{'error': {'code': 503, 'message': 'The service is currently unavailable.', 'status': 'UNAVAILABLE'}}]\n",
      "服務暫時不可用，等待 2 秒後重試...\n",
      "嘗試 2/3 失敗: Error code: 503 - [{'error': {'code': 503, 'message': 'The service is currently unavailable.', 'status': 'UNAVAILABLE'}}]\n",
      "服務暫時不可用，等待 4 秒後重試...\n",
      "成功獲得Gemini回應\n",
      "\n",
      "==================================================\n",
      "GEMINI 輸出結果:\n",
      "==================================================\n",
      "[select_col ( type , player , getpoint_player )]\n",
      "==================================================\n",
      "當前層級: 1\n",
      "更新後的操作歷史: ['root(None)', '[select_col ( type , player , getpoint_player )]']\n",
      "Content Planner for Badminton Game Report\n",
      "==================================================\n",
      "正在載入數據...\n",
      "成功載入CSV: 315 行, 9 列\n",
      "載入表格描述: 481 字符\n",
      "載入操作描述 JSON\n",
      "操作池 (9 個): ['value_counts', 'groupby', 'aggregate', 'corr', 'sort', 'calculate', 'select_row', 'select_col', 'write']\n",
      "操作歷史: ['root(None)']\n",
      "\n",
      "開始生成操作和參數...\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "\n",
      "==================================================\n",
      "GEMINI 輸出結果:\n",
      "==================================================\n",
      "[select_col ( player, type, lose_reason, getpoint_player ), value_counts ( player ), value_counts ( type ), value_counts ( lose_reason ), value_counts ( getpoint_player )]\n",
      "==================================================\n",
      "當前層級: 1\n",
      "更新後的操作歷史: ['root(None)', '[select_col ( player, type, lose_reason, getpoint_player ), value_counts ( player ), value_counts ( type ), value_counts ( lose_reason ), value_counts ( getpoint_player )]']\n",
      "\n",
      "生成的操作: [select_col ( player, type, lose_reason, getpoint_player ), value_counts ( player ), value_counts ( type ), value_counts ( lose_reason ), value_counts ( getpoint_player )]\n",
      "操作歷史長度: 2\n",
      "當前層級: 1\n"
     ]
    }
   ],
   "source": [
    "# 或指定自定義參數\n",
    "operations_result, history, level = run_content_planner(\n",
    "    csv_path='filtered_set1.csv',\n",
    "    table_desc_path='filtered_data_description.txt',\n",
    "    operations_path='selected_operations.json',\n",
    "    outline_path='analyze_response.txt',\n",
    "    max_depth=5,\n",
    "    max_degree=5\n",
    ")\n",
    "\n",
    "if operations_result:\n",
    "    print(f\"\\n生成的操作: {operations_result}\")\n",
    "    print(f\"操作歷史長度: {len(history)}\")\n",
    "    print(f\"當前層級: {level}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38a100",
   "metadata": {},
   "source": [
    "解析LLM response內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "59f439c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select_col ( player, type, lose_reason, getpoint_player )', 'value_counts ( player )', 'value_counts ( type )', 'value_counts ( lose_reason )', 'value_counts ( getpoint_player )']\n"
     ]
    }
   ],
   "source": [
    "# 提取方括号内的内容\n",
    "start = operations_result.find('[') + 1\n",
    "end = operations_result.rfind(']')\n",
    "content = operations_result[start:end].strip()\n",
    "\n",
    "elements = []\n",
    "current = []\n",
    "stack = 0\n",
    "\n",
    "# 遍历字符进行解析\n",
    "for char in content:\n",
    "    if char == '(':\n",
    "        stack += 1\n",
    "        current.append(char)\n",
    "    elif char == ')':\n",
    "        stack -= 1\n",
    "        current.append(char)\n",
    "    elif char == ',' and stack == 0:\n",
    "        elements.append(''.join(current).strip())\n",
    "        current = []\n",
    "    else:\n",
    "        current.append(char)\n",
    "\n",
    "# 添加最后一个元素\n",
    "if current:\n",
    "    elements.append(''.join(current).strip())\n",
    "\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a56c58",
   "metadata": {},
   "source": [
    "# STEP 8\n",
    "\n",
    "根據欄位型態與'operation_name' 和 'operation_argument'，請LLM撰寫可以執行的操作程式碼\n",
    "\n",
    "取欄位型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "093b3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          int64\n",
      "rally               int64\n",
      "time               object\n",
      "roundscore_A        int64\n",
      "roundscore_B        int64\n",
      "player             object\n",
      "type               object\n",
      "lose_reason        object\n",
      "getpoint_player    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_copy = pd.read_csv(\"filtered_set1.csv\")\n",
    "df = df_copy\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "557c4675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315 entries, 0 to 314\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       315 non-null    int64 \n",
      " 1   rally            315 non-null    int64 \n",
      " 2   time             315 non-null    object\n",
      " 3   roundscore_A     315 non-null    int64 \n",
      " 4   roundscore_B     315 non-null    int64 \n",
      " 5   player           315 non-null    object\n",
      " 6   type             315 non-null    object\n",
      " 7   lose_reason      36 non-null     object\n",
      " 8   getpoint_player  36 non-null     object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 22.3+ KB\n",
      "生成的程式碼：\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# 讀取CSV數據集\n",
      "df = pd.read_csv('filtered_set1.csv')\n",
      "\n",
      "# 要執行的操作：select_col ( player, type, lose_reason, getpoint_player )\n",
      "# 假設 select_col 的功能是選擇指定的欄位\n",
      "\n",
      "selected_columns = ['player', 'type', 'lose_reason', 'getpoint_player']\n",
      "df_selected = df[selected_columns]\n",
      "\n",
      "# 將修改後的DataFrame存入 'tmp.csv'\n",
      "df_selected.to_csv('tmp.csv', index=False)\n",
      "\n",
      "# (可選) 顯示DataFrame的前幾行，以確認結果\n",
      "print(df_selected.head())\n",
      "```\n",
      "  player type lose_reason getpoint_player\n",
      "0      B  發長球         NaN             NaN\n",
      "1      A   切球         NaN             NaN\n",
      "2      B   挑球         NaN             NaN\n",
      "3      A   長球         NaN             NaN\n",
      "4      B   殺球         NaN             NaN\n",
      "\n",
      "處理結果：\n",
      "    player  type lose_reason getpoint_player\n",
      "0        B   發長球         NaN             NaN\n",
      "1        A    切球         NaN             NaN\n",
      "2        B    挑球         NaN             NaN\n",
      "3        A    長球         NaN             NaN\n",
      "4        B    殺球         NaN             NaN\n",
      "..     ...   ...         ...             ...\n",
      "310      B  未知球種         NaN             NaN\n",
      "311      A    切球         NaN             NaN\n",
      "312      B    挑球         NaN             NaN\n",
      "313      A    長球         NaN             NaN\n",
      "314      B    長球          出界               A\n",
      "\n",
      "[315 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class DataFrameOperator:\n",
    "    def __init__(self, api_key):\n",
    "        self.lm = setup_gemini_api(api_key)\n",
    "\n",
    "    def generate_code(self, operation, df_info, df_path):\n",
    "        prompt = f\"\"\"\n",
    "        你是一個專業的Python資料分析助手。欄位名稱以資料欄位類型提供為主，根據以下要求生成操作DataFrame的程式碼：\n",
    "\n",
    "        要執行的操作: {operation}\n",
    "\n",
    "        CSV數據集: {df_path}\n",
    "\n",
    "        資料欄位類型:\n",
    "        {df_info}\n",
    "\n",
    "        生成要求：\n",
    "        讀取CSV數據集，並存入DataFrame後，使用要執行的操作後，將修改後的DataFrame存入'tmp.csv'，撰寫完整python code.\n",
    "        切忌每個操作參數都需要使用\n",
    "\n",
    "        輸出格式：\n",
    "        ```python\n",
    "        # 你的程式碼\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return self.lm.basic_request(prompt)\n",
    "\n",
    "    def safe_execute(self, code, df):\n",
    "        try:\n",
    "            code_block = re.search(r'```python\\n(.*?)\\n```', code, re.DOTALL)\n",
    "            if code_block:\n",
    "                code = code_block.group(1)\n",
    "\n",
    "            # 寫入暫存 CSV 檔案作為模擬 df.csv 路徑\n",
    "            df.to_csv(\"input_tmp.csv\", index=False)\n",
    "\n",
    "            # 建立安全執行環境\n",
    "            exec_globals = {'pd': pd}\n",
    "            exec_locals = {}\n",
    "\n",
    "            # 執行生成的程式碼\n",
    "            exec(code, exec_globals, exec_locals)\n",
    "\n",
    "            # 從 tmp.csv 讀取處理後的結果\n",
    "            result_df = pd.read_csv(\"tmp.csv\")\n",
    "            return result_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"執行錯誤: {str(e)}\")\n",
    "            return df\n",
    "\n",
    "\n",
    "\n",
    "# 初始化\n",
    "API_KEY = os.getenv(\"Gemini_API\")\n",
    "operator = DataFrameOperator(API_KEY)\n",
    "\n",
    "# 獲取資料資訊\n",
    "df_info = df.info()\n",
    "df_path = \"filtered_set1.csv\"\n",
    "operation_def = elements[0]\n",
    "#print(operation)\n",
    "\n",
    "generated_code = operator.generate_code(\n",
    "    operation=operation_def,\n",
    "    df_info=df_info,\n",
    "    df_path=df_path\n",
    ")\n",
    "\n",
    "print(\"生成的程式碼：\")\n",
    "print(generated_code)\n",
    "\n",
    "# 執行操作\n",
    "processed_df = operator.safe_execute(generated_code, df)\n",
    "\n",
    "print(\"\\n處理結果：\")\n",
    "print(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1, Node 1: 1 children\n",
      "Level 2, Node 2: 2 children\n",
      "Level 3, Node 4: 5 children\n",
      "Level 4, Node 6: 1 children\n",
      "Level 4, Node 10: 5 children\n",
      "\n",
      "樹狀結構:\n",
      "- Node(1, Level=1)\n",
      "  - Node(2, Level=2)\n",
      "    - Node(3, Level=3)\n",
      "    - Node(4, Level=3)\n",
      "      - Node(5, Level=4)\n",
      "      - Node(6, Level=4)\n",
      "        - Node(7, Level=5)\n",
      "      - Node(8, Level=4)\n",
      "      - Node(9, Level=4)\n",
      "      - Node(10, Level=4)\n",
      "        - Node(11, Level=5)\n",
      "        - Node(12, Level=5)\n",
      "        - Node(13, Level=5)\n",
      "        - Node(14, Level=5)\n",
      "        - Node(15, Level=5)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#可刪\n",
    "class TreeNode:\n",
    "    def __init__(self, value, level=0, text=\"\", table=None):\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "        self.level = level\n",
    "        self.text = text\n",
    "        self.table = table\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"TreeNode({self.value}, level={self.level})\"\n",
    "\n",
    "def build_random_tree(current_depth=1, max_depth=5, max_degree=5, value_counter=None):\n",
    "    if value_counter is None:\n",
    "        value_counter = [0]\n",
    "    \n",
    "    value_counter[0] += 1\n",
    "    node = TreeNode(value_counter[0], level=current_depth)\n",
    "\n",
    "    if current_depth >= max_depth or random.random() < 0.3:\n",
    "        return node  # 葉節點\n",
    "\n",
    "    degree = random.randint(1, max_degree)\n",
    "    print(f\"Level {current_depth}, Node {value_counter[0]}: {degree} children\")\n",
    "    \n",
    "    for _ in range(degree):\n",
    "        child = build_random_tree(current_depth + 1, max_depth, max_degree, value_counter)\n",
    "        node.children.append(child)\n",
    "\n",
    "    return node\n",
    "\n",
    "def print_tree(node, level=0):\n",
    "    print(\"  \" * level + f\"- Node({node.value}, Level={node.level})\")\n",
    "    for child in node.children:\n",
    "        print_tree(child, level + 1)\n",
    "\n",
    "# 建立並印出隨機樹\n",
    "random.seed(42)  # 可重現性\n",
    "root = build_random_tree()\n",
    "print(\"\\n樹狀結構:\")\n",
    "print_tree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a7919",
   "metadata": {},
   "source": [
    "# STEP final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:28,229 - INFO - Tree-of-Report for Data Analysis (改進版)\n",
      "2025-09-28 18:24:28,230 - INFO - ==================================================\n",
      "2025-09-28 18:24:28,231 - INFO - 正在載入數據...\n",
      "2025-09-28 18:24:28,234 - INFO - 成功載入CSV: 315 行, 9 列\n",
      "2025-09-28 18:24:28,235 - INFO - 最大深度: 3\n",
      "2025-09-28 18:24:28,235 - INFO - 最大分支度: 4\n",
      "2025-09-28 18:24:28,237 - INFO - 載入操作池: ['description', 'requirements', 'operations']\n",
      "2025-09-28 18:24:28,238 - INFO - 開始建構報告樹...\n",
      "2025-09-28 18:24:28,239 - INFO - 處理節點 - Level: 0, Operation: root(None)\n",
      "2025-09-28 18:24:28,261 - INFO - 正在向Gemini發送請求...\n",
      "2025-09-28 18:24:30,509 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:24:30,510 - INFO - 生成操作: ['value_counts(type)', 'value_counts(lose_reason)', 'value_counts(getpoint_player)']\n",
      "2025-09-28 18:24:32,694 - INFO - 操作成功，結果形狀: (18, 2)\n",
      "2025-09-28 18:24:32,695 - INFO - 創建數據操作節點: value_counts(type), 結果形狀: (18, 2)\n",
      "2025-09-28 18:24:32,695 - INFO - 添加子節點: 80f7ab6b to 74b9da25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts('type') 操作完成，結果已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:34,318 - INFO - 操作成功，結果形狀: (4, 2)\n",
      "2025-09-28 18:24:34,318 - INFO - 創建數據操作節點: value_counts(lose_reason), 結果形狀: (4, 2)\n",
      "2025-09-28 18:24:34,319 - INFO - 添加子節點: a03b196e to 74b9da25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts 操作完成，結果已儲存至 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:36,517 - INFO - 操作成功，結果形狀: (2, 2)\n",
      "2025-09-28 18:24:36,518 - INFO - 創建數據操作節點: value_counts(getpoint_player), 結果形狀: (2, 2)\n",
      "2025-09-28 18:24:36,519 - INFO - 添加子節點: a7746a65 to 74b9da25\n",
      "2025-09-28 18:24:36,519 - INFO - 處理節點 - Level: 1, Operation: value_counts(type)\n",
      "2025-09-28 18:24:36,521 - INFO - 正在向Gemini發送請求...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts操作完成，結果已儲存至 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:37,269 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:24:37,269 - WARNING - 未知操作: groupby\n",
      "2025-09-28 18:24:37,270 - WARNING - 無效操作被忽略: groupby(type)\n",
      "2025-09-28 18:24:37,271 - INFO - 生成操作: ['value_counts(type)', 'aggregate(count)']\n",
      "2025-09-28 18:24:38,932 - INFO - 操作成功，結果形狀: (18, 2)\n",
      "2025-09-28 18:24:38,932 - INFO - 創建數據操作節點: value_counts(type), 結果形狀: (18, 2)\n",
      "2025-09-28 18:24:38,933 - WARNING - 子節點驗證失敗: ['檢測到冗餘操作: value_counts(type)']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts 操作已完成，結果已保存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:40,234 - INFO - 操作成功，結果形狀: (18, 2)\n",
      "2025-09-28 18:24:40,235 - INFO - 創建數據操作節點: aggregate(count), 結果形狀: (18, 2)\n",
      "2025-09-28 18:24:40,236 - INFO - 添加子節點: 853d93ae to 80f7ab6b\n",
      "2025-09-28 18:24:40,236 - INFO - 處理節點 - Level: 1, Operation: value_counts(lose_reason)\n",
      "2025-09-28 18:24:40,239 - INFO - 正在向Gemini發送請求...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "操作成功完成，結果已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:41,307 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:24:41,307 - INFO - 生成操作: ['aggregate(count)', 'sort(count, ascending=False)', 'write()']\n",
      "2025-09-28 18:24:45,342 - INFO - 操作成功，結果形狀: (3, 2)\n",
      "2025-09-28 18:24:45,343 - INFO - 創建數據操作節點: aggregate(count), 結果形狀: (3, 2)\n",
      "2025-09-28 18:24:45,344 - INFO - 添加子節點: b58fd399 to a03b196e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aggregated data from 'input_tmp.csv' and saved to 'tmp.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:46,631 - INFO - 操作成功，結果形狀: (4, 2)\n",
      "2025-09-28 18:24:46,632 - INFO - 創建數據操作節點: sort(count, ascending=False), 結果形狀: (4, 2)\n",
      "2025-09-28 18:24:46,633 - INFO - 添加子節點: 7cad4196 to a03b196e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully processed and saved to tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:47,809 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:24:47,810 - INFO - 添加子節點: b8dd5319 to a03b196e\n",
      "2025-09-28 18:24:47,810 - INFO - 處理節點 - Level: 1, Operation: value_counts(getpoint_player)\n",
      "2025-09-28 18:24:47,813 - INFO - 正在向Gemini發送請求...\n",
      "2025-09-28 18:24:49,401 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:24:49,402 - INFO - 生成操作: ['aggregate(count)', 'sort(count)', 'write()']\n",
      "2025-09-28 18:24:51,702 - INFO - 操作成功，結果形狀: (2, 2)\n",
      "2025-09-28 18:24:51,703 - INFO - 創建數據操作節點: aggregate(count), 結果形狀: (2, 2)\n",
      "2025-09-28 18:24:51,704 - INFO - 添加子節點: 4f0385c0 to a7746a65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame aggregated and saved to tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:53,389 - INFO - 操作成功，結果形狀: (2, 2)\n",
      "2025-09-28 18:24:53,390 - INFO - 創建數據操作節點: sort(count), 結果形狀: (2, 2)\n",
      "2025-09-28 18:24:53,391 - INFO - 添加子節點: 30009f71 to a7746a65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame排序完成並已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:24:54,526 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:24:54,526 - INFO - 添加子節點: 683fa451 to a7746a65\n",
      "2025-09-28 18:24:54,527 - INFO - 處理節點 - Level: 2, Operation: value_counts(type)\n",
      "2025-09-28 18:24:54,529 - INFO - 正在向Gemini發送請求...\n",
      "2025-09-28 18:24:55,195 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:24:55,196 - INFO - 生成操作: ['value_counts(type)', 'write()']\n",
      "2025-09-28 18:24:55,265 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 4.990579594s. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "]\n",
      "2025-09-28 18:24:56,942 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 3.303939243s. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "2025-09-28 18:24:56,943 - WARNING - 無法生成操作代碼: value_counts(type)\n",
      "2025-09-28 18:24:57,005 - ERROR - Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 3.246608793s. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "2025-09-28 18:24:57,005 - INFO - 已達配額限制，等待 30 秒後重試 (1/3)...\n",
      "2025-09-28 18:25:27,091 - ERROR - Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 33.160406608s. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "]\n",
      "2025-09-28 18:25:27,092 - INFO - 已達配額限制，等待 30 秒後重試 (2/3)...\n",
      "2025-09-28 18:25:58,442 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:25:58,443 - INFO - 添加子節點: dfb875fe to 7571620e\n",
      "2025-09-28 18:25:58,444 - INFO - 處理節點 - Level: 2, Operation: aggregate(count)\n",
      "2025-09-28 18:25:58,446 - INFO - 正在向Gemini發送請求...\n",
      "2025-09-28 18:25:59,482 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:25:59,483 - WARNING - 未知操作: select_col\n",
      "2025-09-28 18:25:59,483 - WARNING - 無效操作被忽略: select_col(type, count)\n",
      "2025-09-28 18:25:59,484 - INFO - 生成操作: ['sort(count, ascending=False)', 'write()']\n",
      "2025-09-28 18:26:01,293 - INFO - 操作成功，結果形狀: (18, 2)\n",
      "2025-09-28 18:26:01,294 - INFO - 創建數據操作節點: sort(count, ascending=False), 結果形狀: (18, 2)\n",
      "2025-09-28 18:26:01,294 - INFO - 添加子節點: 0044ff01 to 853d93ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV檔案處理完成，已儲存至 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_27704\\2190742969.py:516: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if table[col].nunique() <= 10 or dtype == 'object' or pd.api.types.is_categorical_dtype(table[col]):\n",
      "2025-09-28 18:26:02,283 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:26:02,283 - INFO - 添加子節點: 5c760aab to 853d93ae\n",
      "2025-09-28 18:26:02,284 - INFO - 處理節點 - Level: 2, Operation: aggregate(count)\n",
      "2025-09-28 18:26:02,286 - INFO - 正在向Gemini發送請求...\n",
      "2025-09-28 18:26:03,064 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:26:03,064 - WARNING - 未知操作: select_col\n",
      "2025-09-28 18:26:03,065 - WARNING - 無效操作被忽略: select_col(lose_reason, count)\n",
      "2025-09-28 18:26:03,065 - INFO - 生成操作: ['write()']\n",
      "2025-09-28 18:26:04,024 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:26:04,025 - INFO - 添加子節點: 06f5bc63 to b58fd399\n",
      "2025-09-28 18:26:04,026 - INFO - 處理節點 - Level: 2, Operation: sort(count, ascending=False)\n",
      "2025-09-28 18:26:04,028 - INFO - 正在向Gemini發送請求...\n",
      "2025-09-28 18:26:04,836 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:26:04,838 - WARNING - 未知操作: groupby\n",
      "2025-09-28 18:26:04,839 - WARNING - 無效操作被忽略: groupby(lose_reason)\n",
      "2025-09-28 18:26:04,839 - INFO - 生成操作: ['aggregate(count)', 'write()']\n",
      "2025-09-28 18:26:06,655 - INFO - 操作成功，結果形狀: (4, 2)\n",
      "2025-09-28 18:26:06,655 - INFO - 創建數據操作節點: aggregate(count), 結果形狀: (4, 2)\n",
      "2025-09-28 18:26:06,656 - INFO - 添加子節點: 20bd6840 to 7cad4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聚合操作完成，結果已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:26:07,794 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:26:07,795 - INFO - 添加子節點: 9908ae30 to 7cad4196\n",
      "2025-09-28 18:26:07,796 - INFO - 處理節點 - Level: 2, Operation: aggregate(count)\n",
      "2025-09-28 18:26:07,798 - INFO - 正在向Gemini發送請求...\n",
      "2025-09-28 18:26:08,633 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:26:08,634 - WARNING - 未知操作: select_col\n",
      "2025-09-28 18:26:08,634 - WARNING - 無效操作被忽略: select_col(getpoint_player, count)\n",
      "2025-09-28 18:26:08,635 - WARNING - 未知操作: corr\n",
      "2025-09-28 18:26:08,636 - WARNING - 無效操作被忽略: corr()\n",
      "2025-09-28 18:26:08,637 - INFO - 生成操作: ['sort(count)']\n",
      "2025-09-28 18:26:10,345 - INFO - 操作成功，結果形狀: (2, 2)\n",
      "2025-09-28 18:26:10,346 - INFO - 創建數據操作節點: sort(count), 結果形狀: (2, 2)\n",
      "2025-09-28 18:26:10,346 - WARNING - 子節點驗證失敗: ['表格內容未發生變化但非寫作操作']\n",
      "2025-09-28 18:26:10,347 - INFO - 處理節點 - Level: 2, Operation: sort(count)\n",
      "2025-09-28 18:26:10,349 - INFO - 正在向Gemini發送請求...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "排序完成，並已將結果儲存到 'tmp.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:26:11,226 - INFO - 成功獲得Gemini回應\n",
      "2025-09-28 18:26:11,226 - WARNING - 未知操作: select_col\n",
      "2025-09-28 18:26:11,227 - WARNING - 無效操作被忽略: select_col(getpoint_player, count)\n",
      "2025-09-28 18:26:11,227 - INFO - 生成操作: ['write()']\n",
      "2025-09-28 18:26:12,222 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:26:12,223 - INFO - 添加子節點: d6b2e02e to 30009f71\n",
      "C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_27704\\2190742969.py:516: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if table[col].nunique() <= 10 or dtype == 'object' or pd.api.types.is_categorical_dtype(table[col]):\n",
      "2025-09-28 18:26:13,515 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:26:13,516 - INFO - 添加子節點: ec945e12 to 0044ff01\n",
      "2025-09-28 18:26:14,592 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:26:14,593 - INFO - 添加子節點: 9d8e71de to 20bd6840\n",
      "2025-09-28 18:26:15,464 - INFO - 創建 write 節點: write()\n",
      "2025-09-28 18:26:15,465 - INFO - 添加子節點: 2ea717ac to d39ff5e0\n",
      "2025-09-28 18:26:15,466 - INFO - 節點 ec945e12 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:      type  count\n",
      "0      長球     55\n",
      "1      殺球     36\n",
      "2      挑球     35\n",
      "3      切球     31\n",
      "4      推球     31\n",
      "5     放小球     28\n",
      "6     擋小球     20\n",
      "7    未知球種     16\n",
      "8      勾球     12\n",
      "9     發長球     10\n",
      "10    發短球     10\n",
      "11  後場抽平球      7\n",
      "12   過度切球      6\n",
      "13     撲球      5\n",
      "14   防守回抽      5\n",
      "15     點扣      4\n",
      "16     平球      2\n",
      "17   防守回挑      2\n",
      "節點文本: 從數據來看，長球的使用次數最多，達到55次，而殺球也相當頻繁，有36次。值得注意的是，未知球種出現了16次，這部分可能影響了更精確的戰術分析。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:26:15,979 - ERROR - Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 44.326981714s. [violations {\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 44\n",
      "}\n",
      "]\n",
      "2025-09-28 18:26:15,980 - INFO - 已達配額限制，等待 30 秒後重試 (1/3)...\n",
      "2025-09-28 18:26:53,092 - INFO - 節點 0044ff01 文本生成完成\n",
      "2025-09-28 18:26:53,094 - INFO - 節點 5c760aab 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:      type  count\n",
      "0      長球     55\n",
      "1      殺球     36\n",
      "2      挑球     35\n",
      "3      切球     31\n",
      "4      推球     31\n",
      "5     放小球     28\n",
      "6     擋小球     20\n",
      "7    未知球種     16\n",
      "8      勾球     12\n",
      "9     發長球     10\n",
      "10    發短球     10\n",
      "11  後場抽平球      7\n",
      "12   過度切球      6\n",
      "13     撲球      5\n",
      "14   防守回抽      5\n",
      "15     點扣      4\n",
      "16     平球      2\n",
      "17   防守回挑      2\n",
      "節點文本: 從數據分析，長球使用頻率最高，共55次，殺球次數也多，有36次。另外，未知球種出現16次，可能影響戰術分析的準確性。\n",
      "node.table:      type  count\n",
      "0      切球     31\n",
      "1      勾球     12\n",
      "2      平球      2\n",
      "3   後場抽平球      7\n",
      "4      挑球     35\n",
      "5      推球     31\n",
      "6      撲球      5\n",
      "7     擋小球     20\n",
      "8     放小球     28\n",
      "9    未知球種     16\n",
      "10     殺球     36\n",
      "11    發短球     10\n",
      "12    發長球     10\n",
      "13   過度切球      6\n",
      "14     長球     55\n",
      "15   防守回抽      5\n",
      "16   防守回挑      2\n",
      "17     點扣      4\n",
      "節點文本: 本場比賽殺球得分次數達到36次，而長球的使用更是高達55次，但要注意的是，不明原因的失分也不少，高達16次，需要進一步分析改進。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:26:55,245 - INFO - 節點 853d93ae 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:      type  count\n",
      "0      切球     31\n",
      "1      勾球     12\n",
      "2      平球      2\n",
      "3   後場抽平球      7\n",
      "4      挑球     35\n",
      "5      推球     31\n",
      "6      撲球      5\n",
      "7     擋小球     20\n",
      "8     放小球     28\n",
      "9    未知球種     16\n",
      "10     殺球     36\n",
      "11    發短球     10\n",
      "12    發長球     10\n",
      "13   過度切球      6\n",
      "14     長球     55\n",
      "15   防守回抽      5\n",
      "16   防守回挑      2\n",
      "17     點扣      4\n",
      "節點文本: 本場比賽數據顯示，球員大量使用長球，次數高達55次，殺球次數也多，有36次得分。然而，有16次不明原因的失分，以及16次未知球種，這些都需進一步分析和改進，以提升戰術執行的準確性。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:26:56,426 - INFO - 節點 80f7ab6b 文本生成完成\n",
      "2025-09-28 18:26:56,429 - INFO - 節點 06f5bc63 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:      type  count\n",
      "0      長球     55\n",
      "1      殺球     36\n",
      "2      挑球     35\n",
      "3      切球     31\n",
      "4      推球     31\n",
      "5     放小球     28\n",
      "6     擋小球     20\n",
      "7    未知球種     16\n",
      "8      勾球     12\n",
      "9     發長球     10\n",
      "10    發短球     10\n",
      "11  後場抽平球      7\n",
      "12   過度切球      6\n",
      "13   防守回抽      5\n",
      "14     撲球      5\n",
      "15     點扣      4\n",
      "16   防守回挑      2\n",
      "17     平球      2\n",
      "節點文本: 本場比賽數據顯示，球員大量使用長球（55次）和殺球（36次得分）。然而，出現了16次不明原因的失分和16次未知球種，需要進一步分析和改進，以提升戰術執行的準確性。\n",
      "node.table:   lose_reason  count\n",
      "0           a      4\n",
      "1           b      2\n",
      "2           c      4\n",
      "節點文本: 本場比賽失分主要集中在\"a\"原因，高達4次，需要重點檢討。同時，未知球員表現亮眼，多次得分，值得進一步分析其打法和優勢。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:26:57,775 - INFO - 節點 b58fd399 文本生成完成\n",
      "2025-09-28 18:26:57,776 - INFO - 節點 9d8e71de 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   lose_reason  count\n",
      "0           a      4\n",
      "1           b      2\n",
      "2           c      4\n",
      "節點文本: 本場比賽失分集中在\"a\"原因，共4次，需重點檢討。同時，未知球員表現亮眼，多次得分，其打法和優勢值得進一步分析。\n",
      "node.table:   lose_reason  count\n",
      "0          出界      1\n",
      "1      對手落地致勝      1\n",
      "2          掛網      1\n",
      "3         未過網      1\n",
      "節點文本: 本場比賽失誤環節，出界次數稍多，需要多加注意。對手進攻犀利，多次採用落地致勝的策略，我方需提升防守質量。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:26:59,088 - INFO - 節點 20bd6840 文本生成完成\n",
      "2025-09-28 18:26:59,091 - INFO - 節點 9908ae30 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   lose_reason  count\n",
      "0          出界      1\n",
      "1      對手落地致勝      1\n",
      "2          掛網      1\n",
      "3         未過網      1\n",
      "節點文本: 本場比賽我方失誤較多，尤其出界次數偏高，需加強控制。對手進攻犀利，頻繁利用落地得分，因此我方需提升防守質量。\n",
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 各位觀眾，本場比賽雙方互有攻防，失誤方面「對手落地致勝」與「出界」次數最多，都是12次，可見防守和控球仍有加強空間。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:27:02,624 - INFO - 節點 7cad4196 文本生成完成\n",
      "2025-09-28 18:27:02,626 - INFO - 節點 b8dd5319 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 各位觀眾，本場比賽雙方互有攻防，我方失誤較多，尤其出界次數偏高，需加強控制。對手進攻犀利，頻繁利用落地得分，因此我方需提升防守質量。失誤方面，「對手落地致勝」與「出界」次數最多，都是12次，可見防守和控球仍有加強空間。\n",
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 沒錯！對手今天在進攻端給足了壓力，「對手落地致勝」導致了12分丟失，同時也要留意自身失誤，出界和掛網同樣造成了不小的損失。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:27:05,247 - INFO - 節點 a03b196e 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 各位觀眾，本場比賽雙方互有攻防，我方失誤較多，尤其出界次數偏高，需加強控制。對手進攻犀利，頻繁利用落地得分，我方需提升防守質量。「對手落地致勝」與「出界」次數最多，皆為12次，防守和控球仍有加強空間。失分集中在\"a\"原因，共4次，需重點檢討。未知球員表現亮眼，多次得分，其打法和優勢值得分析。此外，出界和掛網也造成不少損失。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:27:06,527 - INFO - 節點 4f0385c0 文本生成完成\n",
      "2025-09-28 18:27:06,529 - INFO - 節點 d6b2e02e 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node table:   getpoint_player  count\n",
      "0               A      1\n",
      "1               B      1\n",
      "node.table:   getpoint_player  count\n",
      "0               A      1\n",
      "1               B      1\n",
      "節點文本: A隊得分一次，B隊也緊追在後，各得一分，雙方你來我往，互不相讓！\n",
      "node.table:   getpoint_player  count\n",
      "0               B     15\n",
      "1               A     21\n",
      "節點文本: 本場比賽A選手得分次數稍佔優勢，共計21分，B選手緊隨其後，拿下15分。值得注意的是，雙方在得分模式上仍有提升空間，仍有部分「無資料」情況，需進一步分析具體原因。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:27:07,885 - INFO - 節點 30009f71 文本生成完成\n",
      "2025-09-28 18:27:07,886 - INFO - 節點 683fa451 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   getpoint_player  count\n",
      "0               B     15\n",
      "1               A     21\n",
      "節點文本: A選手在本場比賽中以21分略勝B選手的15分。雙方得分模式有待加強，部分數據缺失（“無資料”），需進一步分析原因。\n",
      "node.table:   getpoint_player  count\n",
      "0               A     21\n",
      "1               B     15\n",
      "節點文本: A 隊今天在場上展現了強勁的進攻火力，得分高達 21 分，遠超 B 隊的 15 分。A 隊員在多拍相持中，總能抓住機會，一舉得分，奠定了勝局。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:27:09,800 - INFO - 節點 a7746a65 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   getpoint_player  count\n",
      "0               A     21\n",
      "1               B     15\n",
      "節點文本: A隊與B隊比分緊咬，互不相讓，各得一分！A隊在本場比賽中以21分略勝B隊的15分。A隊今天在場上展現強勁進攻火力，遠超B隊。A隊員在多拍相持中總能抓住機會得分，奠定勝局。雙方得分模式有待加強，部分數據缺失，需進一步分析原因。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:27:11,932 - INFO - 節點 74b9da25 文本生成完成\n",
      "2025-09-28 18:27:11,936 - INFO - 生成最終報告...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:      Unnamed: 0  rally      time  roundscore_A  roundscore_B player  type  \\\n",
      "0             0      1  00:05:47             1             0      B   發長球   \n",
      "1             1      1  00:05:49             1             0      A    切球   \n",
      "2             2      1  00:05:50             1             0      B    挑球   \n",
      "3             3      1  00:05:51             1             0      A    長球   \n",
      "4             4      1  00:05:52             1             0      B    殺球   \n",
      "..          ...    ...       ...           ...           ...    ...   ...   \n",
      "310         310     36  00:24:44            21            15      B  未知球種   \n",
      "311         311     36  00:24:58            21            15      A    切球   \n",
      "312         312     36  00:25:00            21            15      B    挑球   \n",
      "313         313     36  00:25:01            21            15      A    長球   \n",
      "314         314     36  00:25:02            21            15      B    長球   \n",
      "\n",
      "    lose_reason getpoint_player  \n",
      "0           NaN             NaN  \n",
      "1           NaN             NaN  \n",
      "2           NaN             NaN  \n",
      "3           NaN             NaN  \n",
      "4           NaN             NaN  \n",
      "..          ...             ...  \n",
      "310         NaN             NaN  \n",
      "311         NaN             NaN  \n",
      "312         NaN             NaN  \n",
      "313         NaN             NaN  \n",
      "314          出界               A  \n",
      "\n",
      "[315 rows x 9 columns]\n",
      "節點文本: 資料分析報告\n",
      "\n",
      "本場比賽數據顯示，球員大量使用長球（55次）和殺球（36次得分）。然而，出現16次不明原因失分和16次未知球種，需進一步分析改進。雙方互有攻防，我方失誤較多，尤其出界次數（12次）偏高，需加強控制。對手頻繁利用落地得分（12次），我方需提升防守質量。失分集中在\"a\"原因（4次），需重點檢討。未知球員表現亮眼，多次得分。A隊以21分略勝B隊的15分，展現強勁進攻火力，多拍相持中總能抓住機會得分。雙方得分模式有待加強，部分數據缺失。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 18:27:16,086 - INFO - 樹結構已導出至: tree_structure.json\n",
      "2025-09-28 18:27:16,089 - INFO - \n",
      "==================================================\n",
      "2025-09-28 18:27:16,090 - INFO - TREE-OF-REPORT 最終報告\n",
      "2025-09-28 18:27:16,090 - INFO - ==================================================\n",
      "2025-09-28 18:27:16,099 - INFO - 報告生成完成，耗時: 167.86 秒\n",
      "2025-09-28 18:27:16,100 - INFO - 生成的文件:\n",
      "2025-09-28 18:27:16,100 - INFO - - tree_of_report.md: 最終報告\n",
      "2025-09-28 18:27:16,101 - INFO - - tree_of_report.txt: 純文本報告\n",
      "2025-09-28 18:27:16,102 - INFO - - tree_structure.json: 樹結構數據\n",
      "2025-09-28 18:27:16,103 - INFO - - execution_report.md: 執行過程報告\n",
      "2025-09-28 18:27:16,103 - INFO - - tree_visualization.html: 可視化頁面\n",
      "2025-09-28 18:27:16,106 - INFO - 清理暫存檔案: input_tmp.csv\n",
      "2025-09-28 18:27:16,107 - INFO - 清理暫存檔案: tmp.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generate report\n",
      "## 強攻制勝！A隊險勝B隊，關鍵在於長球與殺球的精準運用\n",
      "\n",
      "一場激烈的羽球對決昨日落幕，A隊以21比15的比分險勝B隊。縱觀全場，雙方你來我往，互不相讓，但A隊憑藉更具侵略性的進攻，最終成功鎖定勝局。\n",
      "\n",
      "本場比賽的焦點在於球員們對長球和殺球的頻繁運用。球員們多次利用長球調動對手，伺機以雷霆萬鈞的殺球直取分數，總計36次的殺球得分證明了這一戰術的有效性。A隊在多拍相持中展現出更強的得分能力，往往能在關鍵時刻抓住機會，給予對手致命一擊。\n",
      "\n",
      "然而，比賽中也暴露出一些問題。雙方球員都出現了非受迫性失誤，其中出界次數偏高，顯示球員在控球方面仍有提升空間。此外，一些失分原因不明，以及未知球種的出現，都提醒教練團隊需要深入分析比賽錄影，找出潛在的技術漏洞。\n",
      "\n",
      "B隊方面，雖然在防守端做出了努力，但仍難以抵擋A隊如潮水般的攻勢。對手頻繁利用落地得分，使得B隊在防守上疲於奔命。更令人擔憂的是，B隊在“a”原因上失分較多，這將是他們未來訓練中需要重點檢討的環節。\n",
      "\n",
      "值得一提的是，有\"未知球員\"在本場比賽中表現亮眼，多次得分，為比賽增添了不少看點。\n",
      "\n",
      "總體而言，A隊憑藉更強大的進攻火力，特別是長球和殺球的有效配合，贏得了這場比賽的勝利。然而，雙方在得分模式上都有待加強，並需針對各自的弱點進行改進，期待他們在未來的比賽中帶來更精彩的表現。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import dspy\n",
    "import ast\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional, Set\n",
    "import copy\n",
    "import hashlib\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import builtins\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===== 基於參考程式碼的函數 =====\n",
    "def read_text_file(file_path):\n",
    "    \"\"\"讀取文本文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"No file available\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"讀取文件錯誤: {e}\")\n",
    "        return \"Error reading file\"\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"讀取JSON文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # 返回默認操作集合\n",
    "        return [\n",
    "            {\"name\": \"select_column\", \"description\": \"選擇特定欄位\"},\n",
    "            {\"name\": \"value_counts\", \"description\": \"計算值的頻次\"},\n",
    "            {\"name\": \"groupby\", \"description\": \"按欄位分組\"},\n",
    "            {\"name\": \"sort_values\", \"description\": \"排序數據\"},\n",
    "            {\"name\": \"filter_rows\", \"description\": \"過濾行數據\"},\n",
    "            {\"name\": \"write\", \"description\": \"撰寫分析文本\"}\n",
    "        ]\n",
    "\n",
    "# ===== 改進的樹節點類別 =====\n",
    "class TreeNode:\n",
    "    \"\"\"改進的樹節點類別，增加語意驗證和追蹤功能\"\"\"\n",
    "    def __init__(self, level: int = 0, text: str = \"\", table: pd.DataFrame = None, operation: str = None):\n",
    "        self.children: List['TreeNode'] = []\n",
    "        self.level: int = level\n",
    "        self.text: str = text\n",
    "        self.table: pd.DataFrame = table if table is not None else pd.DataFrame()\n",
    "        self.operation: str = operation\n",
    "        self.parent: Optional['TreeNode'] = None\n",
    "        self.operation_history: List[str] = []\n",
    "        \n",
    "        # 新增屬性用於改進功能\n",
    "        self.node_id: str = self._generate_node_id()\n",
    "        self.created_at: datetime = datetime.now()\n",
    "        self.validation_errors: List[str] = []\n",
    "        self.table_hash: str = self._calculate_table_hash()\n",
    "        self.semantic_score: float = 0.0\n",
    "        \n",
    "    def _generate_node_id(self) -> str:\n",
    "        \"\"\"生成唯一節點ID\"\"\"\n",
    "        content = f\"{self.level}_{self.operation}_{datetime.now().isoformat()}\"\n",
    "        return hashlib.md5(content.encode()).hexdigest()[:8]\n",
    "        \n",
    "    def _calculate_table_hash(self) -> str:\n",
    "        \"\"\"計算表格內容的哈希值，用於檢測重複\"\"\"\n",
    "        if self.table.empty:\n",
    "            return \"\"\n",
    "        try:\n",
    "            return hashlib.md5(str(self.table.values.tobytes()).encode()).hexdigest()[:8]\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    def add_child(self, child: 'TreeNode'):\n",
    "        \"\"\"添加子節點並進行驗證\"\"\"\n",
    "        if self._validate_child(child):\n",
    "            child.parent = self\n",
    "            self.children.append(child)\n",
    "            logger.info(f\"添加子節點: {child.node_id} to {self.node_id}\")\n",
    "        else:\n",
    "            logger.warning(f\"子節點驗證失敗: {child.validation_errors}\")\n",
    "    \n",
    "    def _validate_child(self, child: 'TreeNode') -> bool:\n",
    "        \"\"\"驗證子節點的合理性\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # 檢查是否有重複的表格狀態\n",
    "        if child.table_hash and child.table_hash == self.table_hash:\n",
    "            if not child.operation.lower().startswith('write'):\n",
    "                errors.append(\"表格內容未發生變化但非寫作操作\")\n",
    "        \n",
    "        # 檢查操作是否邏輯合理\n",
    "        if self._is_redundant_operation(child.operation):\n",
    "            errors.append(f\"檢測到冗餘操作: {child.operation}\")\n",
    "        \n",
    "        child.validation_errors = errors\n",
    "        return len(errors) == 0\n",
    "    \n",
    "    def _is_redundant_operation(self, operation: str) -> bool:\n",
    "        \"\"\"檢查操作是否冗餘\"\"\"\n",
    "        if len(self.operation_history) < 2:\n",
    "            return False\n",
    "            \n",
    "        # 檢查是否有相同操作在近期歷史中\n",
    "        recent_ops = self.operation_history[-3:]  # 檢查最近3個操作\n",
    "        op_name = operation.split('(')[0].lower()\n",
    "        \n",
    "        for hist_op in recent_ops:\n",
    "            if hist_op.split('(')[0].lower() == op_name:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_leaf(self) -> bool:\n",
    "        \"\"\"判斷是否為葉節點\"\"\"\n",
    "        return len(self.children) == 0\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"將節點轉換為字典格式，用於可視化\"\"\"\n",
    "        return {\n",
    "            \"node_id\": self.node_id,\n",
    "            \"level\": self.level,\n",
    "            \"operation\": self.operation,\n",
    "            \"text_preview\": self.text[:100] + \"...\" if len(self.text) > 100 else self.text,\n",
    "            \"table_shape\": list(self.table.shape) if not self.table.empty else [0, 0],\n",
    "            \"table_columns\": list(self.table.columns) if not self.table.empty else [],\n",
    "            \"children_count\": len(self.children),\n",
    "            \"validation_errors\": self.validation_errors,\n",
    "            \"semantic_score\": self.semantic_score,\n",
    "            \"created_at\": self.created_at.isoformat(),\n",
    "            \"table_hash\": self.table_hash\n",
    "        }\n",
    "\n",
    "# ===== 改進的操作解析器 =====\n",
    "class OperationParser:\n",
    "    \"\"\"專門負責解析和驗證操作的類別\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.valid_operations = {\n",
    "            'select_column', 'select_row',  'sort', 'calculate',\n",
    "            'group_by', 'value_counts', 'aggregate', 'crosstab','pivot_table', 'write'\n",
    "        }\n",
    "        \n",
    "    def parse_operations(self, response_text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"改進的操作解析，返回結構化結果\"\"\"\n",
    "        try:\n",
    "            parsed_operations = []\n",
    "            \n",
    "            # 多種解析策略\n",
    "            operations = self._extract_operations_multiple_strategies(response_text)\n",
    "            \n",
    "            for op_str in operations:\n",
    "                parsed_op = self._parse_single_operation(op_str)\n",
    "                if parsed_op and self._validate_operation(parsed_op):\n",
    "                    parsed_operations.append(parsed_op)\n",
    "                else:\n",
    "                    logger.warning(f\"無效操作被忽略: {op_str}\")\n",
    "            \n",
    "            return parsed_operations[:5]  # 限制最多5個操作\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"解析操作失敗: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_operations_multiple_strategies(self, text: str) -> List[str]:\n",
    "        \"\"\"使用多種策略提取操作\"\"\"\n",
    "        operations = []\n",
    "        \n",
    "        # 策略1: 尋找方括號內容\n",
    "        bracket_match = re.search(r'\\[(.*?)\\]', text, re.DOTALL)\n",
    "        if bracket_match:\n",
    "            content = bracket_match.group(1)\n",
    "            # 使用正則提取函數調用格式\n",
    "            pattern = r'([a-zA-Z_]+\\([^)]*\\))'\n",
    "            ops = re.findall(pattern, content)\n",
    "            operations.extend(ops)\n",
    "        \n",
    "        # 策略2: 逐行解析\n",
    "        if not operations:\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#') and '(' in line and ')' in line:\n",
    "                    operations.append(line)\n",
    "        \n",
    "        # 策略3: 逗號分割\n",
    "        if not operations:\n",
    "            parts = text.replace('[', '').replace(']', '').split(',')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if part and '(' in part:\n",
    "                    operations.append(part)\n",
    "        \n",
    "        return operations\n",
    "    \n",
    "    def _parse_single_operation(self, op_str: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"解析單個操作字符串\"\"\"\n",
    "        try:\n",
    "            # 移除多餘的字符\n",
    "            op_str = op_str.strip().rstrip(',').strip()\n",
    "            \n",
    "            # 提取操作名稱和參數\n",
    "            if '(' not in op_str:\n",
    "                return {\"name\": op_str, \"args\": [], \"raw\": op_str}\n",
    "            \n",
    "            name_part = op_str.split('(')[0].strip()\n",
    "            args_part = op_str[op_str.find('(')+1:op_str.rfind(')')].strip()\n",
    "            \n",
    "            # 解析參數\n",
    "            args = []\n",
    "            if args_part:\n",
    "                # 簡單的參數分割（可以進一步改進）\n",
    "                for arg in args_part.split(','):\n",
    "                    arg = arg.strip().strip('\\'\"')\n",
    "                    if arg:\n",
    "                        args.append(arg)\n",
    "            \n",
    "            return {\n",
    "                \"name\": name_part.lower(),\n",
    "                \"args\": args,\n",
    "                \"raw\": op_str\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"解析操作 '{op_str}' 失敗: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _validate_operation(self, operation: Dict[str, Any]) -> bool:\n",
    "        \"\"\"驗證操作的有效性\"\"\"\n",
    "        name = operation.get(\"name\", \"\").lower()\n",
    "        \n",
    "        # 檢查操作名稱是否有效\n",
    "        if name not in self.valid_operations:\n",
    "            logger.warning(f\"未知操作: {name}\")\n",
    "            return False\n",
    "        \n",
    "        # 檢查特定操作的參數\n",
    "        args = operation.get(\"args\", [])\n",
    "        \n",
    "        if name in ['select_column', 'sort_values'] and not args:\n",
    "            logger.warning(f\"{name} 操作需要參數\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "# ===== 改進的內容規劃器 =====\n",
    "class ContentPlanner:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.parser = OperationParser()\n",
    "        \n",
    "    def generate_operations(self, tables, table_description, operation_description, \n",
    "                          operation_history, operation_pool, max_depth=5, max_degree=3, outline_path='main.txt'):\n",
    "        \"\"\"\n",
    "        改進的操作生成，加入重複檢測和語意驗證\n",
    "        \"\"\"\n",
    "        \n",
    "        # 檢測近期操作，避免重複\n",
    "        recent_operations = self._extract_recent_operations(operation_history)\n",
    "        \n",
    "        # 構建改進的提示詞\n",
    "        prompt = f\"\"\"System : You are a content planner for the report. Please follow the outline. Please select candidate Operations and corresponding Arguments from the Operation Pool based on the input Tables and Operation History. These candidate Operations will be the next Operation in the Operation History .\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in English .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The length of Operation History must be less than or equal to {max_depth}.\n",
    "5. The number of Operations must be less than or equal to {max_degree}  and more than zero.\n",
    "6. Only select Opertions from the Operation Pool .\n",
    "7. Arguments must match the format required by the corresponding Operations .\n",
    "8. Operations & Arguments must follow this format : [ operation_1 ( argument_1 , ...) , operation_2 ( argument_2 , ...) , operation_3 ( argument_3 , ...) , ...]\n",
    "9. Only output Operations & Arguments !\n",
    "10. If Table is big or Level is low, it should be more Operations include select_col or select_row not write.\n",
    "11. If the length of Operation History is short, then more operations or more arguments.\n",
    "12. Write operations do not need argument.\n",
    "13. AVOID repeating recent operations: {recent_operations}\n",
    "14. Prioritize operations that will meaningfully transform the data.\n",
    "15. Avoid give the arguments that not match by the operation.\n",
    "\n",
    "#outline\n",
    "{read_text_file(outline_path) if os.path.exists(outline_path) else \"Generate comprehensive data analysis\"}\n",
    "\n",
    "# Table Description\n",
    "{table_description}\n",
    "\n",
    "# Operation Description\n",
    "{json.dumps(operation_description, indent=2, ensure_ascii=False)}\n",
    "\n",
    "User : # Test\n",
    "## Tables\n",
    "{tables}\n",
    "\n",
    "## Operation History\n",
    "{operation_history}\n",
    "\n",
    "## Operation Pool\n",
    "{operation_pool}\n",
    "\n",
    "## Operations & Arguments\"\"\"\n",
    "\n",
    "        try:\n",
    "            logger.info(\"正在向Gemini發送請求...\")\n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            if response.text:\n",
    "                logger.info(\"成功獲得Gemini回應\")\n",
    "                parsed_ops = self.parser.parse_operations(response.text.strip())\n",
    "                return [op[\"raw\"] for op in parsed_ops]  # 返回原始字符串格式\n",
    "            else:\n",
    "                logger.warning(\"Gemini回應為空\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Gemini API請求失敗: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_recent_operations(self, operation_history: List[str]) -> List[str]:\n",
    "        \"\"\"提取最近的操作名稱\"\"\"\n",
    "        recent = []\n",
    "        for op in operation_history[-3:]:  # 最近3個操作\n",
    "            if '(' in op:\n",
    "                name = op.split('(')[0].strip()\n",
    "                recent.append(name)\n",
    "        return recent\n",
    "\n",
    "# ===== 安全的DataFrame操作器 =====\n",
    "class SafeDataFrameOperator:\n",
    "    \"\"\"安全的DataFrame操作器，使用AST驗證而非直接exec\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.allowed_modules = {'pandas', 'numpy', 're'}\n",
    "        self.allowed_functions = {\n",
    "            'pd.read_csv', 'pd.DataFrame', 'df.head', 'df.tail', 'df.sort_values',\n",
    "            'df.groupby', 'df.filter', 'df.select', 'df.drop', 'df.fillna',\n",
    "            'df.to_csv', 'df.value_counts', 'df.describe', 'df.info'\n",
    "        }\n",
    "\n",
    "    def generate_code(self, operation, df_info, df_path=\"input_tmp.csv\"):\n",
    "        prompt = f\"\"\"\n",
    "        你是一個專業的Python資料分析助手。欄位名稱以資料欄位類型提供為主，根據以下要求生成操作DataFrame的程式碼：\n",
    "\n",
    "        要執行的操作: {operation}\n",
    "\n",
    "        CSV數據集: {df_path}\n",
    "\n",
    "        資料欄位類型:\n",
    "        {df_info}\n",
    "\n",
    "        生成要求：\n",
    "        1. 讀取CSV數據集，並存入DataFrame後，使用要執行的操作後，將修改後的DataFrame存入'tmp.csv'\n",
    "        2. 只使用pandas基本操作，避免複雜的自定義函數\n",
    "        3. 確保代碼安全，不包含文件系統操作（除了指定的CSV讀寫）\n",
    "        4. 撰寫完整python code，包含錯誤處理\n",
    "\n",
    "        輸出格式：\n",
    "        ```python\n",
    "        # 你的程式碼\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "    def _retry_generate(self, prompt, max_retries=2):\n",
    "        \"\"\"帶重試的生成請求\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(prompt)\n",
    "                if response.text:\n",
    "                    return response.text.strip()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"生成代碼失敗 (嘗試 {attempt+1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    import time\n",
    "                    time.sleep(1)\n",
    "        return \"\"\n",
    "\n",
    "    def safe_execute(self, code: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"安全執行生成的代碼\"\"\"\n",
    "        try:\n",
    "            # 提取代碼塊\n",
    "            code_block = re.search(r'```python\\n(.*?)\\n```', code, re.DOTALL)\n",
    "            #print(f'python code: {code_block}')\n",
    "            if code_block:\n",
    "                code = code_block.group(1)\n",
    "\n",
    "            # AST安全驗證\n",
    "            if not self._validate_code_safety(code):\n",
    "                logger.error(\"代碼安全驗證失敗\")\n",
    "                return df\n",
    "\n",
    "            # 寫入暫存 CSV 檔案\n",
    "            df.to_csv(\"input_tmp.csv\", index=False)\n",
    "\n",
    "            allowed_builtin_names = [\n",
    "                'int', 'float', 'str', 'bool', 'list', 'dict', 'set', 'tuple',\n",
    "                'len', 'range', 'enumerate', 'zip', 'min', 'max', 'sum', 'abs',\n",
    "                'print',\n",
    "                'Exception', 'TypeError', 'ValueError', 'KeyError', 'IndexError',\n",
    "                'FileNotFoundError', 'ZeroDivisionError', 'AttributeError', 'ImportError',\n",
    "                '__import__'\n",
    "            ]\n",
    "\n",
    "            safe_globals = {\n",
    "                'pd': pd,\n",
    "                '__name__': '__main__',\n",
    "                '__builtins__': {name: getattr(builtins, name) for name in allowed_builtin_names}\n",
    "            }\n",
    "\n",
    "            safe_locals = {}\n",
    "\n",
    "            # 執行代碼\n",
    "            exec(code, safe_globals, safe_locals)\n",
    "\n",
    "            # 讀取結果\n",
    "            if os.path.exists(\"tmp.csv\"):\n",
    "                result_df = pd.read_csv(\"tmp.csv\")\n",
    "                logger.info(f\"操作成功，結果形狀: {result_df.shape}\")\n",
    "                return result_df\n",
    "            else:\n",
    "                logger.warning(\"未生成結果文件，返回原始DataFrame\")\n",
    "                return df\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"執行錯誤: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            print(\"錯誤代碼如下：\\n\" + \"-\" * 30)\n",
    "            print(code)  # ✅ 輸出造成錯誤的程式碼\n",
    "            print(\"-\" * 30)\n",
    "            logger.error(error_msg)\n",
    "            sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "    def _validate_code_safety(self, code: str) -> bool:\n",
    "        \"\"\"使用AST驗證代碼安全性\"\"\"\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            \n",
    "            for node in ast.walk(tree):\n",
    "                # 檢查危險的函數調用\n",
    "                if isinstance(node, ast.Call):\n",
    "                    if isinstance(node.func, ast.Name):\n",
    "                        func_name = node.func.id\n",
    "                        if func_name in ['exec', 'eval', 'compile', '__import__', 'open']:\n",
    "                            logger.error(f\"檢測到危險函數: {func_name}\")\n",
    "                            return False\n",
    "                \n",
    "                # 檢查文件操作（除了允許的CSV操作）\n",
    "                if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):\n",
    "                    if hasattr(node.func, 'attr'):\n",
    "                        attr_name = node.func.attr\n",
    "                        if attr_name in ['system', 'popen', 'subprocess']:\n",
    "                            logger.error(f\"檢測到系統調用: {attr_name}\")\n",
    "                            return False\n",
    "                \n",
    "                # 檢查導入語句\n",
    "                if isinstance(node, ast.Import):\n",
    "                    for alias in node.names:\n",
    "                        if alias.name not in self.allowed_modules:\n",
    "                            logger.error(f\"檢測到不允許的模組導入: {alias.name}\")\n",
    "                            return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except SyntaxError as e:\n",
    "            logger.error(f\"代碼語法錯誤: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"AST驗證失敗: {e}\")\n",
    "            return False\n",
    "\n",
    "# ===== 文本生成器 =====\n",
    "import time\n",
    "\n",
    "class TextGenerator:\n",
    "    def __init__(self, api_key, table_description=\"\"):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.table_description = table_description\n",
    "\n",
    "    def extract_highlights_from_table(self, table: pd.DataFrame) -> str:\n",
    "        try:\n",
    "            if 'lose_reason' in table.columns:\n",
    "                top_reason = table['lose_reason'].value_counts().idxmax()\n",
    "            else:\n",
    "                top_reason = \"無資料\"\n",
    "            if 'getpoint_player' in table.columns:\n",
    "                top_player = table['getpoint_player'].value_counts().idxmax()\n",
    "            else:\n",
    "                top_player = \"未知球員\"\n",
    "            return f\"最多失分原因為「{top_reason}」，得分最多的是 {top_player}。\"\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "    def extract_table_features(self, table: pd.DataFrame) -> str:\n",
    "        summary = []\n",
    "        for col in table.columns:\n",
    "            dtype = str(table[col].dtype)\n",
    "            line = f\"欄位「{col}」類型：{dtype}\"\n",
    "\n",
    "            # 顯示常見值僅限類別型欄位\n",
    "            if table[col].nunique() <= 10 or dtype == 'object' or pd.api.types.is_categorical_dtype(table[col]):\n",
    "                top_values = table[col].value_counts().head(3).to_dict()\n",
    "                line += f\"，常見值：{list(top_values.keys())}\"\n",
    "            summary.append(line)\n",
    "        return \"\\n\".join(summary)\n",
    "\n",
    "    def _retry_generate(self, prompt, max_retries=3, delay_seconds=30):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(prompt)\n",
    "                if response.text:\n",
    "                    return response.text.strip()\n",
    "            except Exception as e:\n",
    "                err = str(e)\n",
    "                logger.error(f\"Gemini 回應失敗: {err}\")\n",
    "                if \"429\" in err:\n",
    "                    logger.info(f\"已達配額限制，等待 {delay_seconds} 秒後重試 ({attempt+1}/{max_retries})...\")\n",
    "                    time.sleep(delay_seconds)\n",
    "                else:\n",
    "                    break\n",
    "        return \"⚠️ 寫作請求失敗：API 限制或其他錯誤\"\n",
    "\n",
    "    def generate_text_for_write_operation(self, table: pd.DataFrame, operation_history: List[str]) -> str:\n",
    "        table_str = table.to_string()\n",
    "        WRITE_TOKENS = 50\n",
    "        TABLE_FORMAT = \"Pandas DataFrame as plain text\"\n",
    "        highlight_summary = self.extract_highlights_from_table(table)\n",
    "        table_feature_summary = self.extract_table_features(table)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "System :\n",
    "You are a professional content writer for the badminton game report .\n",
    "Please write the Report based on the input Table, just pick one or two lightspots.\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in 中文 .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The Table format is {TABLE_FORMAT}.\n",
    "5. The Report can only describe the content included in the Tables and cannot describe anything not included in the Tables .\n",
    "6. The Report must consist of only one paragraph .\n",
    "7. The number of tokens in the Report must be within {WRITE_TOKENS}.\n",
    "8. 請專注描述得分與失分模式、關鍵欄位趨勢或球員亮點。\n",
    "9. 請模仿比賽轉播員或教練的語氣描述，句式自然、有節奏感。\n",
    "10. 請特別觀察球種之間的連續轉換，例如 放小球 接 殺球 等，找出其中有效得分或不尋常的組合並描述。\n",
    "\n",
    "# Highlights Summary\n",
    "{highlight_summary}\n",
    "\n",
    "# Table Features\n",
    "{table_feature_summary}\n",
    "\n",
    "# Table Description\n",
    "{self.table_description}\n",
    "\n",
    "User :\n",
    "# Test\n",
    "## Tables\n",
    "{table_str}\n",
    "## Report\n",
    "\"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "    def merge_child_texts(self, child_texts: List[str], parent_operation: str) -> str:\n",
    "        if not child_texts:\n",
    "            return \"\"\n",
    "\n",
    "        GENERATING_TOKENS = 100\n",
    "        reports_str = \"\\n\".join([f\"- {txt}\" for txt in child_texts])\n",
    "        prompt = f\"\"\"\n",
    "System :\n",
    "You are a content generator for the badminton game report .\n",
    "Please merge and rewrite a New Report based on the input Reports .\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in 中文 .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The New Report must include all the content from the input Reports ; do not omit any information .\n",
    "5. The New Report must follow the order of the input Reports .\n",
    "6. The number of tokens in the New Report must be within {GENERATING_TOKENS}.\n",
    "7. 請依序整合每段內容，形成結構清晰的段落，包括亮點、失誤模式與球員貢獻。\n",
    "\n",
    "User :\n",
    "# Test\n",
    "## Reports\n",
    "{reports_str}\n",
    "## New Report\n",
    "\"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "# ===== OperationParser._validate_operation 強化參數驗證（補入 df 欄位比對） =====\n",
    "def validate_operation_with_columns(operation: Dict[str, Any], df_columns: List[str]) -> bool:\n",
    "    name = operation.get(\"name\", \"\").lower()\n",
    "    args = operation.get(\"args\", [])\n",
    "\n",
    "    # 檢查操作名稱是否有效\n",
    "    if name not in {\n",
    "        'select_column', 'select_row', 'sort', 'calculate',\n",
    "        'group_by', 'value_counts', 'aggregate', 'crosstab', 'pivot_table', 'write'\n",
    "    }:\n",
    "        return False\n",
    "\n",
    "    # 僅針對需參數操作檢查欄位\n",
    "    if name in ['select_column', 'sort', 'group_by']:\n",
    "        for arg in args:\n",
    "            if arg not in df_columns:\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "# ===== 改進的TreeOfReport類別 =====\n",
    "class TreeOfReport:\n",
    "    def __init__(self, api_key: str, max_depth: int = 5, max_degree: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.max_depth = max_depth\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "        # 載入配置檔案\n",
    "        self.load_configurations()\n",
    "\n",
    "        # 初始化改進的組件\n",
    "        self.content_planner = ContentPlanner(api_key)\n",
    "        self.df_operator = SafeDataFrameOperator(api_key)  # 使用安全版本\n",
    "        self.text_generator = TextGenerator(api_key, table_description=self.table_description)\n",
    "        \n",
    "        # 新增追蹤功能\n",
    "        self.execution_log: List[Dict[str, Any]] = []\n",
    "        self.node_registry: Dict[str, TreeNode] = {}\n",
    "\n",
    "    def load_configurations(self):\n",
    "        self.table_description = read_text_file(\"filtered_data _description.txt\")\n",
    "        if not self.table_description or self.table_description == \"No file available\":\n",
    "            self.table_description = \"數據分析表格，包含各種欄位用於分析\"\n",
    "\n",
    "        self.operation_description = read_json_file(\"selected_operations.json\")\n",
    "        if isinstance(self.operation_description, list):\n",
    "            self.operation_pool = [op['name'] for op in self.operation_description]\n",
    "        else:\n",
    "            self.operation_pool = list(self.operation_description.keys())\n",
    "\n",
    "        logger.info(f\"載入操作池: {self.operation_pool}\")\n",
    "\n",
    "    def build_tree(self, root_table: pd.DataFrame) -> TreeNode:\n",
    "        \"\"\"改進的樹構建，加入完整的追蹤和驗證\"\"\"\n",
    "        root = TreeNode(level=0, text=\"資料分析報告\", table=root_table, operation=\"root(None)\")\n",
    "        root.operation_history = ['root(None)']\n",
    "        self.node_registry[root.node_id] = root\n",
    "        \n",
    "        queue = [root]\n",
    "        \n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "            \n",
    "            # 記錄處理日誌\n",
    "            self._log_node_processing(current_node)\n",
    "\n",
    "            if current_node.operation.lower().startswith('write'):\n",
    "                continue\n",
    "\n",
    "            if current_node.level >= self.max_depth:\n",
    "                write_node = self.create_child_node(current_node, 'write()')\n",
    "                if write_node:\n",
    "                    current_node.add_child(write_node)\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"處理節點 - Level: {current_node.level}, Operation: {current_node.operation}\")\n",
    "\n",
    "            tables_str = current_node.table.to_string()\n",
    "            operations = self.content_planner.generate_operations(\n",
    "                tables=tables_str,\n",
    "                table_description=self.table_description,\n",
    "                operation_description=self.operation_description,\n",
    "                operation_history=current_node.operation_history,\n",
    "                operation_pool=self.operation_pool,\n",
    "                max_depth=self.max_depth,\n",
    "                max_degree=self.max_degree\n",
    "            )\n",
    "\n",
    "            logger.info(f\"生成操作: {operations}\")\n",
    "\n",
    "            for operation in operations[:self.max_degree]:\n",
    "                if operation.strip():\n",
    "                    child_node = self.create_child_node(current_node, operation)\n",
    "                    if child_node:\n",
    "                        current_node.add_child(child_node)\n",
    "                        queue.append(child_node)\n",
    "\n",
    "        self.generate_all_texts(root)\n",
    "        return root\n",
    "    \n",
    "    def _log_node_processing(self, node: TreeNode):\n",
    "        \"\"\"記錄節點處理日誌\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"node_id\": node.node_id,\n",
    "            \"level\": node.level,\n",
    "            \"operation\": node.operation,\n",
    "            \"table_shape\": list(node.table.shape) if not node.table.empty else [0, 0],\n",
    "            \"validation_errors\": node.validation_errors\n",
    "        }\n",
    "        self.execution_log.append(log_entry)\n",
    "    \n",
    "    def create_child_node(self, parent: TreeNode, operation: str) -> Optional[TreeNode]:\n",
    "        \"\"\"改進的子節點創建，加入完整驗證\"\"\"\n",
    "        try:\n",
    "            # 建立新的操作歷史\n",
    "            new_operation_history = parent.operation_history + [operation]\n",
    "            \n",
    "            # 檢查是否為 write 操作\n",
    "            if operation.lower().startswith('write'):\n",
    "                text = self.text_generator.generate_text_for_write_operation(\n",
    "                    parent.table,\n",
    "                    new_operation_history\n",
    "                )\n",
    "                child = TreeNode(\n",
    "                    level=parent.level + 1,\n",
    "                    text=text,\n",
    "                    table=parent.table.copy(),\n",
    "                    operation=operation\n",
    "                )\n",
    "                child.operation_history = new_operation_history\n",
    "                self.node_registry[child.node_id] = child\n",
    "                logger.info(f\"創建 write 節點: {operation}\")\n",
    "                return child\n",
    "            else:\n",
    "                # 其他操作：執行數據操作\n",
    "                df_info = f\"Shape: {parent.table.shape}\\nColumns: {list(parent.table.columns)}\\nData types:\\n{parent.table.dtypes.to_string()}\"\n",
    "                code = self.df_operator.generate_code(operation, df_info)\n",
    "                \n",
    "                if code:\n",
    "                    result_df = self.df_operator.safe_execute(code, parent.table)\n",
    "                    child = TreeNode(\n",
    "                        level=parent.level + 1,\n",
    "                        text=\"\",\n",
    "                        table=result_df,\n",
    "                        operation=operation\n",
    "                    )\n",
    "                    child.operation_history = new_operation_history\n",
    "                    self.node_registry[child.node_id] = child\n",
    "                    logger.info(f\"創建數據操作節點: {operation}, 結果形狀: {result_df.shape}\")\n",
    "                    return child\n",
    "                else:\n",
    "                    logger.warning(f\"無法生成操作代碼: {operation}\")\n",
    "                    return None\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"創建子節點失敗: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_all_texts(self, node: TreeNode):\n",
    "        \"\"\"遞歸生成所有節點的文本\"\"\"\n",
    "        for child in node.children:\n",
    "            self.generate_all_texts(child)\n",
    "        \n",
    "        if node.is_leaf() and not node.text and node.operation and not node.operation.lower().startswith('write'):\n",
    "            node.text = self.text_generator.generate_text_for_write_operation(\n",
    "                node.table, \n",
    "                node.operation_history\n",
    "            )\n",
    "            print(f'node table: {node.table}')\n",
    "        elif node.children:\n",
    "            child_texts = [child.text for child in node.children if child.text.strip()]\n",
    "            if child_texts:\n",
    "                merged_text = self.text_generator.merge_child_texts(\n",
    "                    child_texts, \n",
    "                    node.operation or \"root\"\n",
    "                )\n",
    "                if node.text:\n",
    "                    node.text = node.text + \"\\n\\n\" + merged_text\n",
    "                else:\n",
    "                    node.text = merged_text\n",
    "        logger.info(f'節點 {node.node_id} 文本生成完成')\n",
    "        print(f'node.table: {node.table}')\n",
    "        print(f'節點文本: {node.text}')\n",
    "        \n",
    "    def export_tree_structure(self, root: TreeNode, output_path: str = \"tree_structure.json\"):\n",
    "        \"\"\"導出樹結構為JSON格式，用於可視化和分析\"\"\"\n",
    "        def node_to_dict(node: TreeNode) -> Dict[str, Any]:\n",
    "            result = node.to_dict()\n",
    "            result[\"children\"] = [node_to_dict(child) for child in node.children]\n",
    "            return result\n",
    "        \n",
    "        tree_data = {\n",
    "            \"metadata\": {\n",
    "                \"export_time\": datetime.now().isoformat(),\n",
    "                \"total_nodes\": len(self.node_registry),\n",
    "                \"max_depth\": self.max_depth,\n",
    "                \"max_degree\": self.max_degree\n",
    "            },\n",
    "            \"execution_log\": self.execution_log,\n",
    "            \"tree\": node_to_dict(root)\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(tree_data, f, indent=2, ensure_ascii=False)\n",
    "            logger.info(f\"樹結構已導出至: {output_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"導出樹結構失敗: {e}\")\n",
    "    \n",
    "    def generate_execution_report(self) -> str:\n",
    "        \"\"\"生成執行過程報告\"\"\"\n",
    "        total_nodes = len(self.node_registry)\n",
    "        error_nodes = sum(1 for node in self.node_registry.values() if node.validation_errors)\n",
    "        \n",
    "        report = f\"\"\"\n",
    "# Tree-of-Report 執行報告\n",
    "\n",
    "## 統計信息\n",
    "- 總節點數: {total_nodes}\n",
    "- 錯誤節點數: {error_nodes}\n",
    "- 樹最大深度: {self.max_depth}\n",
    "- 最大分支度: {self.max_degree}\n",
    "\n",
    "## 節點分布\n",
    "\"\"\"\n",
    "        \n",
    "        # 按層級統計節點\n",
    "        level_counts = {}\n",
    "        for node in self.node_registry.values():\n",
    "            level = node.level\n",
    "            level_counts[level] = level_counts.get(level, 0) + 1\n",
    "        \n",
    "        for level, count in sorted(level_counts.items()):\n",
    "            report += f\"- Level {level}: {count} 個節點\\n\"\n",
    "        \n",
    "        # 錯誤摘要\n",
    "        if error_nodes > 0:\n",
    "            report += \"\\n## 驗證錯誤摘要\\n\"\n",
    "            for node in self.node_registry.values():\n",
    "                if node.validation_errors:\n",
    "                    report += f\"- 節點 {node.node_id} ({node.operation}): {'; '.join(node.validation_errors)}\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "    def generate_report(self, node: TreeNode, level: int = 0) -> str:\n",
    "        \"\"\"改進的報告生成\"\"\"\n",
    "        if node.level == 0:\n",
    "            prompt = f\"\"\"\n",
    "            你是一位新聞記者，根據以下分析總結，請撰寫一篇賽事新聞報導，提供全面深入的分析，統整成新聞報導，文辭中過多直接使用欄位名稱與直接次數統計，用player_A與player_B表示兩球員，用生動的文句描述，勿出現累贅的句子，請從分析總結中提取轉換，禁止出現幻覺。\n",
    "            請用繁體中文撰寫，保持邏輯清晰，資訊準確。\n",
    "\n",
    "            分析總結:\n",
    "            {node.text}\n",
    "            \"\"\"\n",
    "            final_text = self.text_generator._retry_generate(prompt)\n",
    "            \n",
    "            # 保存多種格式的報告\n",
    "            with open(\"tree_of_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(final_text)\n",
    "            \n",
    "            # 導出樹結構\n",
    "            self.export_tree_structure(node)\n",
    "            \n",
    "            # 生成執行報告\n",
    "            exec_report = self.generate_execution_report()\n",
    "            with open(\"execution_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(exec_report)\n",
    "                print(\"finish generate report\")\n",
    "            \n",
    "            return final_text\n",
    "        else:\n",
    "            logger.info(f'generate report from not root')\n",
    "            indent = \"  \" * level\n",
    "            report = f\"{indent}{'#' * (level + 1)} {node.operation or 'Root'}\\n\\n\"\n",
    "\n",
    "            if node.text:\n",
    "                report += f\"{indent}{node.text}\\n\\n\"\n",
    "\n",
    "            if node.table is not None and not node.table.empty and level < 2:\n",
    "                report += f\"{indent}**資料摘要:** Shape {node.table.shape}\\n\"\n",
    "                if len(node.table) <= 10:\n",
    "                    report += f\"{indent}```\\n{node.table.to_string()}\\n{indent}```\\n\\n\"\n",
    "                else:\n",
    "                    report += f\"{indent}```\\n{node.table.head().to_string()}\\n{indent}```\\n\\n\"\n",
    "\n",
    "            for child in node.children:\n",
    "                report += self.generate_report(child, level + 1)\n",
    "\n",
    "            return report\n",
    "\n",
    "\n",
    "# ===== 主程序 =====\n",
    "def main():\n",
    "    \"\"\"改進的主函數\"\"\"\n",
    "    \n",
    "    # 設置API密鑰\n",
    "    api_key = os.getenv(\"Gemini_API\")\n",
    "    if not api_key:\n",
    "        logger.error(\"請設置 Gemini_AP 環境變數\")\n",
    "        return\n",
    "    \n",
    "    logger.info(\"Tree-of-Report for Data Analysis (改進版)\")\n",
    "    logger.info(\"=\"*50)\n",
    "    \n",
    "    logger.info(\"正在載入數據...\")\n",
    "    \n",
    "    # 讀取CSV檔案\n",
    "\n",
    "    TABLES = pd.read_csv('filtered_set1.csv')\n",
    "    logger.info(f\"成功載入CSV: {TABLES.shape[0]} 行, {TABLES.shape[1]} 列\")\n",
    "\n",
    "    \n",
    "    # 設置參數\n",
    "    MAX_DEPTH = 3\n",
    "    MAX_DEGREE = 4\n",
    "    \n",
    "    logger.info(f\"最大深度: {MAX_DEPTH}\")\n",
    "    logger.info(f\"最大分支度: {MAX_DEGREE}\")\n",
    "    \n",
    "    # 初始化改進的 Tree-of-Report\n",
    "    tree_report = TreeOfReport(api_key, max_depth=MAX_DEPTH, max_degree=MAX_DEGREE)\n",
    "    \n",
    "    # 建構報告樹\n",
    "    logger.info(\"開始建構報告樹...\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        root = tree_report.build_tree(TABLES)\n",
    "        \n",
    "        # 生成最終報告\n",
    "        logger.info(\"生成最終報告...\")\n",
    "        final_report = tree_report.generate_report(root)\n",
    "        \n",
    "        # 輸出報告\n",
    "        logger.info(\"\\n\" + \"=\"*50)\n",
    "        logger.info(\"TREE-OF-REPORT 最終報告\")\n",
    "        logger.info(\"=\"*50)\n",
    "        print(final_report)\n",
    "        \n",
    "        # 儲存報告\n",
    "        with open('tree_of_report.md', 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# Tree-of-Report 數據分析報告 (改進版)\\n\\n\")\n",
    "            f.write(final_report)\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        logger.info(f\"報告生成完成，耗時: {duration:.2f} 秒\")\n",
    "        logger.info(\"生成的文件:\")\n",
    "        logger.info(\"- tree_of_report.md: 最終報告\")\n",
    "        logger.info(\"- tree_of_report.txt: 純文本報告\")\n",
    "        logger.info(\"- tree_structure.json: 樹結構數據\")\n",
    "        logger.info(\"- execution_report.md: 執行過程報告\")\n",
    "        logger.info(\"- tree_visualization.html: 可視化頁面\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"程序執行失敗: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        # 清理暫存檔案\n",
    "        for temp_file in ['input_tmp.csv', 'tmp.csv']:\n",
    "            if os.path.exists(temp_file):\n",
    "                try:\n",
    "                    os.remove(temp_file)\n",
    "                    logger.info(f\"清理暫存檔案: {temp_file}\")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a1db8ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 第 1/3 次生成...\n",
      "⏳ 第 2/3 次生成...\n",
      "⏳ 第 3/3 次生成...\n",
      "\n",
      "✅ 所有版本已生成\n",
      "[1] 分數: 0.75 → 這場羽球賽事可謂高潮迭起，雙方你來我往，互不相讓。從比賽伊始，雙方便展開了激烈的攻防轉換，發球、過渡球、到進攻，每個回合都充滿了變數。可以看到球員A率先取得領先，一路將比分拉開，一度取得11:6的優勢。然而，球員B並沒有輕易放棄，展現了頑強的韌性，逐漸將比分追趕上來。\n",
      "\n",
      "比賽中，雙方選手都力圖在前場尋找機會，短球的運用頻繁，小球與挑球的搭配也考驗著雙方的技術。一些回合的拉鋸非常長，球員們不斷地進行攻防轉換，後場的強力擊球與前場的精巧控制相互交織，呈現出精彩的對抗場面。失誤也偶爾出現，掛網、出界等情況讓比賽更具懸念。\n",
      "\n",
      "比賽後半段，球員B逐漸找到狀態，憑藉積極的跑動和抓住機會的能力，將比分反超，最終以21:15的比分贏得了勝利。整場比賽節奏緊湊，雙方都展現了高超的羽球技藝和頑強的鬥志，是一場值得回味的精彩對決。\n",
      "[2] 分數: 0.6 → 這場羽球賽事戰況膠著，雙方你來我往，互不相讓。比賽初段，雙方都以試探性的發球開局，隨後球路變化多端，有時是輕巧的網前小球，有時是力道十足的後場重擊，看得出雙方選手都在積極尋找對方的破綻。\n",
      "\n",
      "比賽中，選手A一度取得領先，但選手B韌性十足，緊咬比分。在多拍來回中，雙方都展現了極佳的防守能力，多次將看似必殺的球路化解。網前的細膩手法和後場的強力進攻交織，讓觀眾看得目不暇給。\n",
      "\n",
      "在關鍵時刻，選手A利用一次精準的判斷，讓對手措手不及，成功得分。然而，選手B也毫不示弱，隨即以一記漂亮的落地得分還以顏色。比分交替上升，比賽氣氛也越發緊張。\n",
      "\n",
      "最終，選手A穩住陣腳，憑藉著穩定的發揮和關鍵時刻的果斷進攻，成功拿下分數。但選手B的表現也同樣精彩，雖敗猶榮。整場比賽高潮迭起，充分展現了羽球運動的魅力。觀眾們也為這場精彩的對決獻上了熱烈的掌聲。\n",
      "[3] 分數: 0.75 → 這場羽球賽事可謂高潮迭起，雙方選手你來我往，攻防轉換節奏快速。開局雙方互有領先，比分交替上升，首局前半段A選手稍佔優勢，一度將比分拉開至2:1，但B選手隨即展開反擊，利用精準的落點控制和強勢的進攻，將比分追平。\n",
      "\n",
      "比賽中，我們可以看到多回合的精采對決。例如第三分，雙方選手經過多次的短球、挑球、長球、抽球、切球等戰術運用，足足來回了17拍才由A選手抓住機會，一記對手無法接到的球拿下分數。儘管如此，B選手也沒有輕易放棄，隨後也以連續的積極進攻，包括多次的殺球，給A選手帶來了極大的壓力。\n",
      "\n",
      "比賽進入中段後，A選手在發球環節上更注意策略，偶爾採用短發，希望擾亂B選手的節奏。但B選手也積極調整，並利用A選手幾次判斷失誤及回球掛網的機會，成功將比分反超。\n",
      "\n",
      "比賽末段，雙方都展現了極強的韌性。儘管體力消耗巨大，但依舊努力在每一次擊球中尋找機會。A選手曾依靠精準的落點和幾次漂亮的防守反擊，將比分追近，但B選手總能在關鍵時刻挺身而出，多次利用強力的扣殺以及精準的網前小球，穩住陣腳。最終，B選手以一記角度刁鑽的撲球，讓A選手措手不及，成功拿下這局的第15分。隨後A選手雖奮力追趕，但最終B選手憑藉一記幸運的長球出界，以21:15拿下此局勝利。\n",
      "\n",
      "整場比賽充滿了各式各樣的戰術運用，包含長球、短球、切球、挑球、殺球、推球、勾球，以及網前小球的爭奪，雙方都展現了高超的球技和頑強的鬥志，為觀眾帶來了一場精采絕倫的羽球饗宴。 比賽結果雖有勝負，但雙方運動員的運動家精神，都令人印象深刻。\n",
      "\n",
      "🏆 最佳版本是第 1 次：這場羽球賽事可謂高潮迭起，雙方你來我往，互不相讓。從比賽伊始，雙方便展開了激烈的攻防轉換，發球、過渡球、到進攻，每個回合都充滿了變數。可以看到球員A率先取得領先，一路將比分拉開，一度取得11:6的優勢。然而，球員B並沒有輕易放棄，展現了頑強的韌性，逐漸將比分追趕上來。\n",
      "\n",
      "比賽中，雙方選手都力圖在前場尋找機會，短球的運用頻繁，小球與挑球的搭配也考驗著雙方的技術。一些回合的拉鋸非常長，球員們不斷地進行攻防轉換，後場的強力擊球與前場的精巧控制相互交織，呈現出精彩的對抗場面。失誤也偶爾出現，掛網、出界等情況讓比賽更具懸念。\n",
      "\n",
      "比賽後半段，球員B逐漸找到狀態，憑藉積極的跑動和抓住機會的能力，將比分反超，最終以21:15的比分贏得了勝利。整場比賽節奏緊湊，雙方都展現了高超的羽球技藝和頑強的鬥志，是一場值得回味的精彩對決。\n",
      "✔️ 已儲存至：best_of_three_report_20250928_195942.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# === 寫作風格詞彙 ===\n",
    "BADMINTON_TERMS = {\n",
    "    'net': '網前失誤', 'out': '出界', 'long': '過底線', 'smash': '殺球',\n",
    "    'clear': '高遠球', 'drop': '切球', 'drive': '平抽球', 'serve': '發球', 'return': '回球'\n",
    "}\n",
    "ACTION_VERBS = ['展現', '發揮', '掌握', '運用', '施展', '控制', '主導', '壓制', '突破', '創造', '締造', '奠定', '確立', '鞏固', '扭轉', '逆轉']\n",
    "TECHNICAL_TERMS = ['lose_reason', 'getpoint_player', 'type', 'column', 'row']\n",
    "\n",
    "# === Gemini 模型初始化 ===\n",
    "def init_model(api_key: str):\n",
    "    genai.configure(api_key=api_key)\n",
    "    return genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# === 品質評估 ===\n",
    "def assess_text_quality(text: str) -> float:\n",
    "    score = 0.0\n",
    "    if 30 <= len(text) <= 120:\n",
    "        score += 0.2\n",
    "    score += min(0.2, sum(1 for t in BADMINTON_TERMS.values() if t in text) * 0.1)\n",
    "    score += min(0.2, sum(1 for v in ACTION_VERBS if v in text) * 0.05)\n",
    "    if not any(t in text for t in TECHNICAL_TERMS):\n",
    "        score += 0.2\n",
    "    if '，' in text or '。' in text:\n",
    "        score += 0.2\n",
    "    return round(min(score, 1.0), 2)\n",
    "\n",
    "# === 主流程：重複3次生成並評估 ===\n",
    "def generate_best_of_three(df: pd.DataFrame, api_key: str):\n",
    "    model = init_model(api_key)\n",
    "    table_str = df.to_string(index=False)\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "你是一位專業體育新聞記者，擅長撰寫羽球比賽報導。\n",
    "請根據以下數據表格撰寫賽事描述，使用繁體中文，避免出現技術欄位名稱。\n",
    "\n",
    "# 賽事數據表格：\n",
    "{table_str}\n",
    "\n",
    "請撰寫描述：\n",
    "\"\"\"\n",
    "\n",
    "    results = []\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            print(f\"⏳ 第 {i+1}/3 次生成...\")\n",
    "            response = model.generate_content(prompt_template)\n",
    "            time.sleep(1)\n",
    "            text = response.text.strip() if response.text else \"⚠️ 無內容\"\n",
    "        except Exception as e:\n",
    "            text = f\"⚠️ 生成錯誤: {e}\"\n",
    "        score = assess_text_quality(text)\n",
    "        results.append({'index': i+1, 'text': text, 'score': score})\n",
    "\n",
    "    # 選出最佳結果\n",
    "    best = max(results, key=lambda x: x['score'])\n",
    "\n",
    "    # 輸出到檔案\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"best_of_three_report_{timestamp}.txt\"\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in results:\n",
    "            f.write(f\"[版本 {r['index']}] 品質分數: {r['score']}\\n{r['text']}\\n\\n\")\n",
    "        f.write(f\"🏆 最佳版本為第 {best['index']} 次，分數: {best['score']}\\n\")\n",
    "        f.write(best['text'])\n",
    "\n",
    "    print(\"\\n✅ 所有版本已生成\")\n",
    "    for r in results:\n",
    "        print(f\"[{r['index']}] 分數: {r['score']} → {r['text']}\")\n",
    "    print(f\"\\n🏆 最佳版本是第 {best['index']} 次：{best['text']}\")\n",
    "    print(f\"✔️ 已儲存至：{file_name}\")\n",
    "    return best\n",
    "\n",
    "# === 測試入口 ===\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = os.getenv(\"Gemini_API\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"請設置 Gemini_API 環境變數\")\n",
    "\n",
    "    df = pd.read_csv(\"filtered_set1.csv\")\n",
    "    \n",
    "\n",
    "    generate_best_of_three(df, api_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cotable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
