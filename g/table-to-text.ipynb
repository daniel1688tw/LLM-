{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "387fc1a5",
   "metadata": {},
   "source": [
    "此篇研究只需提供\n",
    "\"main.txt\"為使用者的大綱與簡短想法\n",
    "\"data_description.txt\"為要分析的table columns所代表的意義\n",
    "就可產生完整報導\n",
    "(可使用在產生任何報導上不限於羽球)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c8faf",
   "metadata": {},
   "source": [
    "# STEP 1\n",
    "\n",
    "刪減不必要的columns\n",
    "\n",
    "結果保留['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9666a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 原始回應: ```python\n",
      "['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']\n",
      "```\n",
      "✅ 篩選出的欄位: ['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']\n",
      "\n",
      "最終欄位清單:\n",
      "['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']\n"
     ]
    }
   ],
   "source": [
    "#正式\n",
    "import dspy\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional, ClassVar\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "class Gemini(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model_instance = genai.GenerativeModel(model_name)\n",
    "        super().__init__(model=model_name)\n",
    "     \n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "         \n",
    "        if isinstance(messages, list):\n",
    "            prompt_text = \"\".join([msg.get('content', '') for msg in messages])\n",
    "        else:\n",
    "            prompt_text = str(messages)\n",
    "         \n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt_text)\n",
    "            if not response.text:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return [{\n",
    "                'text': response.text,\n",
    "                'logprobs': None\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{\n",
    "                'text': \"⚠️ Gemini API 回應失敗,可能已達限額或出現錯誤。\",\n",
    "                'logprobs': None\n",
    "            }]\n",
    "     \n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "def setup_gemini_api(api_key):\n",
    "    lm = Gemini(api_key=api_key)\n",
    "    dspy.settings.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "\n",
    "def parse_list_from_response(response_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse a Python list from various response formats including markdown code blocks\n",
    "    \"\"\"\n",
    "    # Remove leading/trailing whitespace\n",
    "    text = response_text.strip()\n",
    "    \n",
    "    # Remove markdown code blocks\n",
    "    text = re.sub(r'```(?:python)?\\s*', '', text)\n",
    "    text = re.sub(r'```\\s*', '', text)\n",
    "    \n",
    "    # Remove any additional backticks\n",
    "    text = text.strip('`').strip()\n",
    "    \n",
    "    # Try to find a list pattern in the text\n",
    "    list_patterns = [\n",
    "        r'\\[([^\\]]+)\\]',  # Match content within square brackets\n",
    "        r'(\\[.*?\\])',     # Match the entire list including brackets\n",
    "    ]\n",
    "    \n",
    "    for pattern in list_patterns:\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            list_text = match.group(0) if pattern == r'(\\[.*?\\])' else '[' + match.group(1) + ']'\n",
    "            break\n",
    "    else:\n",
    "        # If no pattern matches, assume the entire cleaned text is the list\n",
    "        list_text = text\n",
    "    \n",
    "    # Clean up the list text\n",
    "    list_text = list_text.strip()\n",
    "    \n",
    "    # Handle both single and double quotes\n",
    "    try:\n",
    "        # First try parsing as-is\n",
    "        return json.loads(list_text)\n",
    "    except json.JSONDecodeError:\n",
    "\n",
    "        # Try converting single quotes to double quotes\n",
    "        list_text_double_quotes = list_text.replace(\"'\", '\"')\n",
    "        return json.loads(list_text_double_quotes)\n",
    "\n",
    "\n",
    "def extract_news_relevant_fields(description_path: str, main_path: str):\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"❌ GOOGLE_API_KEY 環境變數未設定\")\n",
    "        return []\n",
    "     \n",
    "    lm = setup_gemini_api(api_key)\n",
    "    main_content = read_text_file(main_path)\n",
    "    description = read_text_file(description_path)\n",
    "    \n",
    "    prompt = f\"\"\"Using the following outline and list of data column descriptions, select only the columns that are useful for the outline.\n",
    "\n",
    "## outline\n",
    "{main_content}\n",
    "\n",
    "## Data Column Descriptions:\n",
    "{description}\n",
    "\n",
    "---\n",
    "\n",
    "Please return only a Python list of column names, like this:\n",
    "['player_name', 'match_score', 'duration', ...]\n",
    "\n",
    "Do not include explanations or any other text. Return only the list.\"\"\"\n",
    "     \n",
    "    result = lm.basic_request(prompt)\n",
    "    \n",
    "    print(f\"🔍 原始回應: {result}\")\n",
    "    \n",
    "    selected_fields = parse_list_from_response(result)\n",
    "    \n",
    "    if selected_fields:\n",
    "        print(\"✅ 篩選出的欄位:\", selected_fields)\n",
    "    else:\n",
    "        print(\"❌ 未能成功解析欄位列表\")\n",
    "    \n",
    "    return selected_fields\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fields = extract_news_relevant_fields(\"data_description.txt\", \"main.txt\")\n",
    "    print(\"\\n最終欄位清單:\")\n",
    "    print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14f81b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fields = ['rally', 'time', 'roundscore_A', 'roundscore_B', 'player', 'type', 'lose_reason', 'getpoint_player']\n",
    "df = pd.read_csv(\"set1.csv\")\n",
    "filtered_df = df[fields]\n",
    "filtered_df.to_csv(\"filtered_set1.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609780f4",
   "metadata": {},
   "source": [
    "更改原始的\"data_description.txt\"到\"filtered_data_description.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bdc0bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已將欄位描述寫入 filtered_data_description.txt\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "\n",
    "def extract_descriptions_for_fields(fields: List[str], desc_path: str, output_path: str):\n",
    "    description_text = read_text_file(desc_path)\n",
    "\n",
    "    field_desc = {}\n",
    "    for line in description_text.splitlines():\n",
    "        for field in fields:\n",
    "            if line.lower().startswith(field.lower() + \":\"):\n",
    "                field_desc[field] = line.strip()\n",
    "\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for field in fields:\n",
    "                f.write(field_desc.get(field, f\"{field}: [Description not found]\") + \"\\n\")\n",
    "        print(f\"✅ 已將欄位描述寫入 {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 寫入失敗: {e}\")\n",
    "\n",
    "\n",
    "extract_descriptions_for_fields(fields, 'data_description.txt', \"filtered_data_description.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484f0a6",
   "metadata": {},
   "source": [
    "# STEP 2\n",
    "\n",
    "藉由人為輸入問題與方向提示，給LLM做完整分析問題與方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d8455eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Response saved to: analyze_response.txt\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional, ClassVar\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "class Gemini(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model_instance = genai.GenerativeModel(model_name)\n",
    "        super().__init__(model=model_name)\n",
    "\n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "\n",
    "        if isinstance(messages, list):\n",
    "            prompt_text = \"\".join([msg.get('content', '') for msg in messages])\n",
    "        else:\n",
    "            prompt_text = str(messages)\n",
    "\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt_text)\n",
    "            if not response.text:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return [{\n",
    "                'text': response.text,\n",
    "                'logprobs': None\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{\n",
    "                'text': \"⚠️ Gemini API 回應失敗,可能已達限額或出現錯誤。\",\n",
    "                'logprobs': None\n",
    "            }]\n",
    "\n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "def setup_gemini_api(api_key):\n",
    "    lm = Gemini(api_key=api_key)\n",
    "    dspy.settings.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "\n",
    "def generate_chain_of_thought_response(main_path: str, desc_path: str, output_path: str):\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"❌ GOOGLE_API_KEY 環境變數未設定\")\n",
    "        return\n",
    "\n",
    "    lm = setup_gemini_api(api_key)\n",
    "\n",
    "    main_content = read_text_file(main_path)\n",
    "    description = read_text_file(desc_path)\n",
    "\n",
    "    chain_prompt = f\"\"\"\n",
    "You are a planning assistant.\n",
    "Analyze the following outline and column descriptions.\n",
    "\n",
    "## Outline & Ideas:\n",
    "{main_content}\n",
    "\n",
    "## Data Column Descriptions:\n",
    "{description}\n",
    "\n",
    "---\n",
    "\n",
    "Step-by-step:\n",
    "1. Reflect on the structure and meaning of the content.\n",
    "2. Formulate relevant and meanful questions or planning strategies.\n",
    "3. Be explicit and detailed, use Chain-of-Thought reasoning.\n",
    "4. Output all thoughts and questions in English only.\n",
    "\"\"\"\n",
    "\n",
    "    result = lm.basic_request(chain_prompt)\n",
    "\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result)\n",
    "        print(f\"✅ Response saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to write output: {e}\")\n",
    "\n",
    "def main():\n",
    "    generate_chain_of_thought_response(\n",
    "        main_path=\"main.txt\",\n",
    "        desc_path=\"filtered_data_description.txt\",\n",
    "        output_path=\"analyze_response.txt\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b495c8",
   "metadata": {},
   "source": [
    "# STEP 3\n",
    "\n",
    "請LLM根據\"analyze_response.txt\"思考可以使用的operation並將結果存於 \"operations_info.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f5f0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 操作清單與描述已儲存至 operations_info.json\n",
      "\n",
      "✅ 操作名稱陣列:\n",
      "['write', 'select_row', 'select_column', 'group_by', 'aggregate', 'value_counts', 'crosstab', 'pivot_table', 'sort', 'calculate', 'merge', 'rolling_window', 'normalize', 'correlation', 'one_hot_encoding']\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional, ClassVar\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "class Gemini(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model_instance = genai.GenerativeModel(model_name)\n",
    "        super().__init__(model=model_name)\n",
    "\n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "\n",
    "        if isinstance(messages, list):\n",
    "            prompt_text = \"\".join([msg.get('content', '') for msg in messages])\n",
    "        else:\n",
    "            prompt_text = str(messages)\n",
    "\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt_text)\n",
    "            if not response.text:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return [{\n",
    "                'text': response.text,\n",
    "                'logprobs': None\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{\n",
    "                'text': \"⚠️ Gemini API 回應失敗,可能已達限額或出現錯誤。\",\n",
    "                'logprobs': None\n",
    "            }]\n",
    "\n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "def setup_gemini_api(api_key):\n",
    "    lm = Gemini(api_key=api_key)\n",
    "    dspy.settings.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "\n",
    "def analyze_operations(analyze_path: str, output_json: str) -> List[str]:\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"❌ GOOGLE_API_KEY 環境變數未設定\")\n",
    "        return []\n",
    "\n",
    "    lm = setup_gemini_api(api_key)\n",
    "    analysis = read_text_file(analyze_path)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a news journalist want to analyze data not forecaster.\n",
    "Based on the following text analysis, identify multiple useful table operations\n",
    "and describe the direct meaning of each operation.\n",
    "\n",
    "## Text Analysis:\n",
    "{analysis}\n",
    "\n",
    "---\n",
    "\n",
    "Please output a numbered list in this format:\n",
    "1. write: If the table is clear or small enough, generates text based on the tables using the LLM.\n",
    "2. select_row: Description\n",
    "3. select_column: Description\n",
    "4. operation_name: Description\n",
    "5. operation_name: Description\n",
    "...\n",
    "\n",
    "IMPORTANT: operation must contain select_row, select_column, and write in the first three operation.\n",
    "\n",
    "Give important operations and at most 15 operations.\n",
    "operation_name should be different and each operation can not be similar.\n",
    "operation can be apply on many columns is better.\n",
    "Description just give the original definition of the operation name and give some useful functions name in pandas.\n",
    "Only include operations and their descriptions. Be concise and clear.\n",
    "\"\"\"\n",
    "\n",
    "    response = lm.basic_request(prompt)\n",
    "\n",
    "    operations = []\n",
    "    operations_dict = {}\n",
    "\n",
    "    try:\n",
    "        for line in response.strip().split('\\n'):\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "            if \".\" in line:\n",
    "                num, rest = line.split(\".\", 1)\n",
    "                if \":\" in rest:\n",
    "                    name, desc = rest.strip().split(\":\", 1)\n",
    "                    name = name.strip()\n",
    "                    desc = desc.strip()\n",
    "                    operations.append(name)\n",
    "                    operations_dict[num.strip()] = {\"operation\": name, \"description\": desc}\n",
    "\n",
    "        with open(output_json, 'w', encoding='utf-8') as f:\n",
    "            json.dump(operations_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"✅ 操作清單與描述已儲存至 {output_json}\")\n",
    "        return operations\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 回應處理失敗: {e}\\n原始回應:\\n{response}\")\n",
    "        return []\n",
    "\n",
    "ops = analyze_operations(\"analyze_response.txt\", \"operations_info.json\")\n",
    "print(\"\\n✅ 操作名稱陣列:\")\n",
    "print(ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9545745",
   "metadata": {},
   "source": [
    "# STEP 4\n",
    "\n",
    "使LLM自動分析table選出合適的operation放入操作池(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "153883e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading badminton match data...\n",
      "Identified 1 suitable operations:\n",
      "1. [1, 2, 3, 5, 7, 9, 10, 11, 12, 18, 19]\n",
      "\n",
      "Final operations array: ['[1, 2, 3, 5, 7, 9, 10, 11, 12, 18, 19]']\n"
     ]
    }
   ],
   "source": [
    "# badminton_analysis.py\n",
    "#正式\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dspy\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Define a simple signature for the ChainOfThought\n",
    "class OperationSignature(dspy.Signature):\n",
    "    \"\"\"Identify suitable operations for analyzing badminton match data.\"\"\"\n",
    "    data_description = dspy.InputField(desc=\"Overview and sample of the dataset\")\n",
    "    column_descriptions = dspy.InputField(desc=\"Descriptions of each column in the dataset\")\n",
    "    rules = dspy.InputField(desc=\"Rules for selecting operations\")\n",
    "    operations_list = dspy.OutputField(desc=\"A list of suitable operations number\")\n",
    "\n",
    "def read_badminton_data(file_path):\n",
    "    try:\n",
    "        return pd.read_csv(file_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "def parse_column_descriptions(description_text):\n",
    "    descriptions = {}\n",
    "    pattern = r'''\n",
    "        ^                # Line start\n",
    "        (\\w+)            # Column name\n",
    "        :\\s+             # Colon and space\n",
    "        (.+?)            # Description text\n",
    "        (?=\\n\\w+:\\s+|\\Z) # Lookahead for next column or end of file\n",
    "    '''\n",
    "    matches = re.findall(pattern, description_text, flags=re.M | re.X)\n",
    "    for col_name, desc in matches:\n",
    "        clean_desc = ' '.join(desc.split()).strip()\n",
    "        descriptions[col_name] = clean_desc\n",
    "    return descriptions\n",
    "\n",
    "class BadmintonOperationSelector(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.chain_of_thought = dspy.ChainOfThought(OperationSignature)\n",
    "\n",
    "    def forward(self, data_description, column_descriptions, rules):\n",
    "        result = self.chain_of_thought(\n",
    "            data_description=data_description,\n",
    "            column_descriptions=str(column_descriptions),\n",
    "            rules=str(rules)\n",
    "        )\n",
    "        return self.extract_operations_from_result(result.operations_list)\n",
    "\n",
    "    def extract_operations_from_result(self, operations_text):\n",
    "        operations = []\n",
    "        lines = operations_text.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            line = re.sub(r'^[\\d\\.\\)\\-\\*]+\\s*', '', line)\n",
    "            if line and len(line) < 100:\n",
    "                operations.append(line)\n",
    "        return operations\n",
    "\n",
    "def analyze_badminton_match(data_path, column_desc_path, rules_path, api_key):\n",
    "    print(\"Reading badminton match data...\")\n",
    "    try:\n",
    "        match_data = read_badminton_data(data_path)\n",
    "        columns_desc_content = read_text_file(column_desc_path)\n",
    "        rules = read_json_file(rules_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files: {e}\")\n",
    "        return []\n",
    "\n",
    "    column_descriptions = parse_column_descriptions(columns_desc_content)\n",
    "    setup_gemini_api(api_key)\n",
    "\n",
    "    data_sample = match_data.to_string()\n",
    "    data_description = f\"\"\"\n",
    "    one match data:\n",
    "    {data_sample}\n",
    "\n",
    "    Data shape: {match_data.shape[0]} rows, {match_data.shape[1]} columns\n",
    "    Columns: {', '.join(match_data.columns)}\n",
    "    \"\"\"\n",
    "\n",
    "    selector = BadmintonOperationSelector()\n",
    "    operations = selector.forward(data_description, column_descriptions, rules)\n",
    "\n",
    "    print(f\"Identified {len(operations)} suitable operations:\")\n",
    "    for i, op in enumerate(operations, 1):\n",
    "        print(f\"{i}. {op}\")\n",
    "\n",
    "    return operations\n",
    "\n",
    "def setup_gemini_api(api_key):\n",
    "    os.environ['GOOGLE_API_KEY'] = api_key\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_path = \"set1.csv\"\n",
    "    column_desc_path = \"data_description.txt\"\n",
    "    rules_path = \"operation_description.json\"\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\", \"AIzaSyDI6yAgr689NOqj2G34cgDr-aa5tv2aO8g\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"Error: Google API key not found. Please set the GOOGLE_API_KEY environment variable.\")\n",
    "    else:\n",
    "        operations = analyze_badminton_match(data_path, column_desc_path, rules_path, api_key)\n",
    "        print(\"\\nFinal operations array:\", operations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db5ef4",
   "metadata": {},
   "source": [
    "將所挑選出來的操作寫入\"operations.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7a99127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operations.json has been created.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 從 JSON 檔案讀取 \"operations\" 分支\n",
    "with open(\"operation_description.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_data = json.load(f)\n",
    "    original_operations = all_data[\"operations\"]\n",
    "\n",
    "# 你想要挑選的 operation 編號（根據實際需求修改這個 list）\n",
    "selected_numbers = [1, 2, 3, 5, 7, 9, 10, 11, 12, 18, 19]\n",
    "\n",
    "# 根據 selected_numbers 選出對應操作，並從 1 開始重新編號\n",
    "filtered_operations = []\n",
    "for new_number, original_number in enumerate(selected_numbers, start=1):\n",
    "    for op in original_operations:\n",
    "        if op[\"number\"] == original_number:\n",
    "            filtered_operations.append({\n",
    "                \"number\": new_number,\n",
    "                \"name\": op[\"name\"],\n",
    "                \"description\": op[\"description\"]\n",
    "            })\n",
    "            break\n",
    "\n",
    "# 新的 JSON 結構\n",
    "output_json = {\n",
    "    \"description\": \"Selected operations for badminton data analysis.\",\n",
    "    \"requirements\": [\n",
    "        \"The output must be based on the input data ; do not hallucinate.\",\n",
    "        \"Give me the list of numbers.\"\n",
    "    ],\n",
    "    \"operations\": filtered_operations\n",
    "}\n",
    "\n",
    "# 寫入 JSON 檔案\n",
    "with open(\"operations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"operations.json has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef6c0a",
   "metadata": {},
   "source": [
    "# STEP 5\n",
    "\n",
    "篩選出最合適的1/2 operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258834da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從 operations.json 成功載入 11 個操作\n",
      "\n",
      "載入的操作詳情:\n",
      "  1. 編號: 1, 名稱: View data\n",
      "      描述: Inspect dataset preview and structure.\n",
      "  2. 編號: 2, 名稱: Add column\n",
      "      描述: Add new features, e.g., rally length or is_win.\n",
      "  3. 編號: 3, 名稱: Delete column\n",
      "      描述: Remove irrelevant or noisy fields.\n",
      "  4. 編號: 4, 名稱: Fill missing values\n",
      "      描述: Replace NaN with default or computed values.\n",
      "  5. 編號: 5, 名稱: Column statistics\n",
      "      描述: Compute stats like average rally time or shot count.\n",
      "  ... 還有 6 個操作\n",
      "\n",
      "成功載入資料集: 315 行, 30 列\n",
      "原始操作數量: 11\n",
      "原始操作清單:\n",
      "  1. 1. View data: Inspect dataset preview and structure.\n",
      "  2. 2. Add column: Add new features, e.g., rally length or is_win.\n",
      "  3. 3. Delete column: Remove irrelevant or noisy fields.\n",
      "  4. 4. Fill missing values: Replace NaN with default or computed values.\n",
      "  5. 5. Column statistics: Compute stats like average rally time or shot count.\n",
      "  6. 6. Sort data: Sort by duration, player, or score for ranking or filtering.\n",
      "  7. 7. Filter data: Use logical conditions to narrow down the dataset.\n",
      "  8. 8. Group data: Cluster data by player, match, or shot type for summarization.\n",
      "  9. 9. Aggregate data: Summarize grouped data via average, count, etc.\n",
      "  10. 10. Check/handle missing values: Diagnose and manage incomplete data.\n",
      "  11. 11. Count: Count unique values or occurrences in columns.\n",
      "\n",
      "使用 Gemini LLM 過濾操作 (移除 50%)...\n",
      "方法1: 使用自定義過濾器 + Gemini...\n",
      "response: 分析思路：\n",
      "\n",
      "首先，審視每個操作在羽球比賽資料分析中的作用和必要性，結合資料集的欄位資訊進行判斷。\n",
      "\n",
      "*   **1. View data (查看資料)**：這是任何資料分析的第一步，必須保留，用於初步了解資料集。\n",
      "\n",
      "*   **2. Add column (新增欄位)**：非常有用，可以基於現有欄位創建新的特徵，例如計算球速、擊球角度、回合持續時間，甚至使用現有的 `win_reason` 和 `lose_reason` 欄位創建一個 `is_win` 欄位。\n",
      "\n",
      "*   **3. Delete column (刪除欄位)**： 如果存在無意義或高度冗餘的欄位，則很有用，但需要小心操作，避免誤刪重要資訊。`db` 欄位只有一個值 0，沒有提供任何資訊，可以刪除。\n",
      "\n",
      "*   **4. Fill missing values (填補缺失值)**：鑑於 `lose_reason`, `win_reason`, 和 `getpoint_player` 欄位存在缺失值（nan），此操作非常重要，可以避免後續分析產生錯誤。\n",
      "\n",
      "*   **5. Column statistics (欄位統計)**：可以提供關於每個欄位的基本統計資訊，例如平均值、標準差、最大值、最小值等，有助於理解資料的分佈和特徵，有價值。\n",
      "\n",
      "*   **6. Sort data (排序資料)**：根據指定的欄位（例如時間、球員、得分）對資料進行排序，以便更容易地識別趨勢和模式，具有一定的實用性，例如按時間排序觀察比賽進程。\n",
      "\n",
      "*   **7. Filter data (篩選資料)**：允許基於特定條件選擇資料子集，例如只選擇特定球員的資料，或是篩選出特定類型的擊球，非常有用。\n",
      "\n",
      "*   **8. Group data (分組資料)**：將資料按特定欄位（例如球員、比賽、擊球類型）進行分組，以便進行彙總和比較，常用於分析不同球員的表現差異、不同擊球類型的效果等。\n",
      "\n",
      "*   **9. Aggregate data (彙總資料)**：對分組後的資料進行彙總計算，例如計算每個球員的平均得分、每種擊球類型的成功率等。 通常和 group data 一起使用。\n",
      "\n",
      "*   **10. Check/handle missing values (檢查/處理缺失值)**：本質上與操作 4 相同，作用重複，可以刪除。\n",
      "\n",
      "*   **11. Count (計數)**：統計各欄位中唯一值的數量，或者特定值的出現次數，例如，統計每種擊球類型的次數，或是每個球員的得分次數，比較實用。\n",
      "\n",
      "基於以上分析，以下操作應該移除：\n",
      "\n",
      "*   **3. Delete column**: 雖然 `db` 欄位可以刪除，但這個操作本身並不是絕對必須的，可以先不執行。\n",
      "*   **6. Sort data**: 雖然具有一定的實用性，但不如其他操作重要。如果目標不是按時間順序分析比賽過程，可以先不執行。\n",
      "*   **8. Group data**: 如果沒有明確的分析目標，例如要分析特定球員或比賽，這個操作的價值會降低。\n",
      "*   **9. Aggregate data**: 需要先分組資料才能進行彙總，因此移除 group data 後，這個操作也失去意義。\n",
      "*   **10. Check/handle missing values**: 與操作 4 重複。\n",
      "\n",
      "保留的操作編號：\n",
      "[1, 2, 4, 5, 7, 11]\n",
      "\n",
      "Debug - 正在分析回應文本...\n",
      "Debug - 檢查行: 分析思路：\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: 首先，審視每個操作在羽球比賽資料分析中的作用和必要性，結合資料集的欄位資訊進行判斷。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **1. View data (查看資料)**：這是任何資料分析的第一步，必須保留，用於初步了解資料集。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **2. Add column (新增欄位)**：非常有用，可以基於現有欄位創建新的特徵，例如計算球速、擊球角度、回合持續時間，甚至使用現有的 `win_reason` 和 `lose_reason` 欄位創建一個 `is_win` 欄位。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **3. Delete column (刪除欄位)**： 如果存在無意義或高度冗餘的欄位，則很有用，但需要小心操作，避免誤刪重要資訊。`db` 欄位只有一個值 0，沒有提供任何資訊，可以刪除。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **4. Fill missing values (填補缺失值)**：鑑於 `lose_reason`, `win_reason`, 和 `getpoint_player` 欄位存在缺失值（nan），此操作非常重要，可以避免後續分析產生錯誤。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **5. Column statistics (欄位統計)**：可以提供關於每個欄位的基本統計資訊，例如平均值、標準差、最大值、最小值等，有助於理解資料的分佈和特徵，有價值。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **6. Sort data (排序資料)**：根據指定的欄位（例如時間、球員、得分）對資料進行排序，以便更容易地識別趨勢和模式，具有一定的實用性，例如按時間排序觀察比賽進程。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **7. Filter data (篩選資料)**：允許基於特定條件選擇資料子集，例如只選擇特定球員的資料，或是篩選出特定類型的擊球，非常有用。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **8. Group data (分組資料)**：將資料按特定欄位（例如球員、比賽、擊球類型）進行分組，以便進行彙總和比較，常用於分析不同球員的表現差異、不同擊球類型的效果等。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **9. Aggregate data (彙總資料)**：對分組後的資料進行彙總計算，例如計算每個球員的平均得分、每種擊球類型的成功率等。 通常和 group data 一起使用。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **10. Check/handle missing values (檢查/處理缺失值)**：本質上與操作 4 相同，作用重複，可以刪除。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **11. Count (計數)**：統計各欄位中唯一值的數量，或者特定值的出現次數，例如，統計每種擊球類型的次數，或是每個球員的得分次數，比較實用。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: 基於以上分析，以下操作應該移除：\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: *   **3. Delete column**: 雖然 `db` 欄位可以刪除，但這個操作本身並不是絕對必須的，可以先不執行。\n",
      "Debug - 檢查行: *   **6. Sort data**: 雖然具有一定的實用性，但不如其他操作重要。如果目標不是按時間順序分析比賽過程，可以先不執行。\n",
      "Debug - 檢查行: *   **8. Group data**: 如果沒有明確的分析目標，例如要分析特定球員或比賽，這個操作的價值會降低。\n",
      "Debug - 檢查行: *   **9. Aggregate data**: 需要先分組資料才能進行彙總，因此移除 group data 後，這個操作也失去意義。\n",
      "Debug - 檢查行: *   **10. Check/handle missing values**: 與操作 4 重複。\n",
      "Debug - 檢查行: \n",
      "Debug - 檢查行: 保留的操作編號：\n",
      "Debug - 找到標題行，開始提取\n",
      "Debug - 檢查行: [1, 2, 4, 5, 7, 11]\n",
      "Debug - 找到方括號內容: 1, 2, 4, 5, 7, 11\n",
      "Debug - 提取到編號: 1\n",
      "Debug - 提取到編號: 2\n",
      "Debug - 提取到編號: 4\n",
      "Debug - 提取到編號: 5\n",
      "Debug - 提取到編號: 7\n",
      "Debug - 提取到編號: 11\n",
      "Debug - 原始提取的編號: ['1', '2', '4', '5', '7', '11']\n",
      "Debug - 可用的編號: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n",
      "Debug - 驗證後的有效編號: ['1', '2', '4', '5', '7', '11']\n",
      "自定義過濾器方法保留了 6 個操作編號\n",
      "\n",
      "自定義過濾器回應:\n",
      "==============================\n",
      "分析思路：\n",
      "\n",
      "首先，審視每個操作在羽球比賽資料分析中的作用和必要性，結合資料集的欄位資訊進行判斷。\n",
      "\n",
      "*   **1. View data (查看資料)**：這是任何資料分析的第一步，必須保留，用於初步了解資料集。\n",
      "\n",
      "*   **2. Add column (新增欄位)**：非常有用，可以基於現有欄位創建新的特徵，例如計算球速、擊球角度、回合持續時間，甚至使用現有的 `win_reason` 和 `lose_reason` 欄位創建一個 `is_win` 欄位。\n",
      "\n",
      "*   **3. Delete column (刪除欄位)**： 如果存在無意義或高度冗餘的欄位，則很有用，但需要小心操作，避免誤刪重要資訊。`db` 欄位只有一個值 0，沒有提供任何資訊，可以刪除。\n",
      "\n",
      "*   **4. Fill missing values (填補缺失值)**：鑑於 `lose_reason`, `win_reason`, 和 `getpoint_player` 欄位存在缺失值（nan），此操作非常重要，可以避免後續分析產生錯誤。\n",
      "\n",
      "*   **5. Column statistics (欄位統計)**：...\n",
      "==============================\n",
      "方法2: 直接使用 Gemini API...\n",
      "直接 API 方法保留了 6 個操作編號\n",
      "\n",
      "Gemini 回應:\n",
      "==================================================\n",
      "分析思路：\n",
      "\n",
      "1. **保留基礎資料檢視 (1):** 這是初步理解資料集的必要步驟，不論後續要進行什麼分析，都需要先了解資料的結構與內容。\n",
      "\n",
      "2. **保留新增欄位 (2):** 這個操作提供了很高的彈性，可以基於現有欄位創造更有意義的特徵，例如計算球員的擊球效率、判斷是否得分等。\n",
      "\n",
      "3. **保留填補遺漏值 (4):** 遺漏值是常見的資料問題，若要進行有效的統計或建模，需要先進行處理。\n",
      "\n",
      "4. **保留資料篩選 (7):** 篩選能夠讓我們針對特定情境進行分析，例如只觀察特定球員的表現、或特定分數段的來回球。\n",
      "\n",
      "5. **保留資料分組 (8):** 分組是進行數據分析的重要手段，透過按球員、比賽或其他關鍵變數進行分組，可以洞察數據的各個面向。\n",
      "\n",
      "6. **保留計數 (11):** 這個操作可以快速了解各個類別的分布狀況，例如各類型擊球的次數、每個球員得分的次數等等，有助於初步了解資料的特性。\n",
      "\n",
      "*   **移除原因：**\n",
      "\n",
      "    *   **操作 3（刪除欄位）：** 在這個階段，除非有明顯無用或洩漏目標變數的欄位，否則應盡可能保留所有欄位，以便後續特徵工程。\n",
      "    *   **操作 5（欄位統計）：** 操作 9（匯總數據）和 11（計數）可以包含統計分析。此操作與操作 9 和 11 高度相似。\n",
      "    *   **操作 6（排序資料）：** 排序本身並不是分析的核心，更多是輔助檢視資料的方式，在其他操作中也常常會用到排序。\n",
      "    *   **操作 9（匯總資料）：** 這個操作功能重複，因為統計分析可以透過分組和新增欄位來完成。\n",
      "    *   **操作 10（檢查/處理遺漏值）：** 雖然檢查遺漏值很重要，但更重要的是實際填補遺漏值 (操作 4)。單純檢查而不處理的實用價值較低。\n",
      "\n",
      "保留的操作編號：\n",
      "[1, 2, 4, 7, 8, 11]\n",
      "\n",
      "==================================================\n",
      "\n",
      "使用直接 API 方法的結果\n",
      "\n",
      "最終保留的操作編號 (6 個):\n",
      "\n",
      "操作過濾完成！從 11 個操作減少到 6 個操作。\n",
      "保留的操作編號清單: ['1', '2', '4', '7', '8', '11']\n",
      "selected_numbers: [1, 2, 4, 7, 8, 11]\n",
      "original_operations: [{'number': 1, 'name': 'View data', 'description': 'Inspect dataset preview and structure.'}, {'number': 2, 'name': 'Add column', 'description': 'Add new features, e.g., rally length or is_win.'}, {'number': 3, 'name': 'Delete column', 'description': 'Remove irrelevant or noisy fields.'}, {'number': 4, 'name': 'Fill missing values', 'description': 'Replace NaN with default or computed values.'}, {'number': 5, 'name': 'Column statistics', 'description': 'Compute stats like average rally time or shot count.'}, {'number': 6, 'name': 'Sort data', 'description': 'Sort by duration, player, or score for ranking or filtering.'}, {'number': 7, 'name': 'Filter data', 'description': 'Use logical conditions to narrow down the dataset.'}, {'number': 8, 'name': 'Group data', 'description': 'Cluster data by player, match, or shot type for summarization.'}, {'number': 9, 'name': 'Aggregate data', 'description': 'Summarize grouped data via average, count, etc.'}, {'number': 10, 'name': 'Check/handle missing values', 'description': 'Diagnose and manage incomplete data.'}, {'number': 11, 'name': 'Count', 'description': 'Count unique values or occurrences in columns.'}]\n",
      "filtered_operations.json has been created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dspy\n",
    "import re\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Define Gemini LLM class (same as before)\n",
    "class Gemini(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model_instance = genai.GenerativeModel(model_name)\n",
    "        super().__init__(model=model_name)\n",
    "    \n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "        \n",
    "        if isinstance(messages, list):\n",
    "            prompt_text = \"\".join([msg.get('content', '') for msg in messages])\n",
    "        else:\n",
    "            prompt_text = str(messages)\n",
    "        \n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt_text)\n",
    "            if not response.text:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return [{\n",
    "                'text': response.text,\n",
    "                'logprobs': None\n",
    "            }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{\n",
    "                'text': \"⚠️ Gemini API 回應失敗,可能已達限額或出現錯誤。\",\n",
    "                'logprobs': None\n",
    "            }]\n",
    "    \n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "# Set up Gemini API\n",
    "def setup_gemini_api(api_key):\n",
    "    lm = Gemini(api_key=api_key)\n",
    "    dspy.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "def load_operations_from_json(json_file_path):\n",
    "    \"\"\"\n",
    "    Load operations from JSON file\n",
    "    Returns a list of operation dictionaries and a formatted string list\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        operations_data = data.get('operations', [])\n",
    "        \n",
    "        # Create formatted operation strings for LLM processing\n",
    "        operation_strings = []\n",
    "        operation_details = []\n",
    "        \n",
    "        for op in operations_data:\n",
    "            number = op.get('number', '')\n",
    "            name = op.get('name', '')\n",
    "            description = op.get('description', '')\n",
    "            \n",
    "            # Format as: \"number. name: description\"\n",
    "            if number and name and description:\n",
    "                formatted_op = f\"{number}. {name}: {description}\"\n",
    "                operation_strings.append(formatted_op)\n",
    "                operation_details.append({\n",
    "                    'number': number,\n",
    "                    'name': name,\n",
    "                    'description': description,\n",
    "                    'formatted': formatted_op\n",
    "                })\n",
    "        \n",
    "        print(f\"從 {json_file_path} 成功載入 {len(operation_strings)} 個操作\")\n",
    "        return operation_details, operation_strings\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"錯誤: 找不到文件 {json_file_path}\")\n",
    "        return [], []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"錯誤: {json_file_path} 不是有效的 JSON 文件\")\n",
    "        return [], []\n",
    "    except Exception as e:\n",
    "        print(f\"載入操作時發生錯誤: {e}\")\n",
    "        return [], []\n",
    "\n",
    "class OperationFilter:\n",
    "    def __init__(self, gemini_api_key):\n",
    "        self.gemini_lm = Gemini(api_key=gemini_api_key)\n",
    "    \n",
    "    def forward(self, operations_list, operation_details, data_info, removal_percentage=0.25):\n",
    "        \"\"\"\n",
    "        Use Gemini to filter out inappropriate operations\n",
    "        \"\"\"\n",
    "        operations_count = len(operations_list)\n",
    "        operations_to_remove = int(operations_count * removal_percentage)\n",
    "        operations_to_keep = operations_count - operations_to_remove\n",
    "        \n",
    "        # Create numbered list of operations for easier reference\n",
    "        numbered_operations = \"\\n\".join([f\"{i+1}. {op}\" for i, op in enumerate(operations_list)])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        我有 {operations_count} 個用於分析羽球比賽資料的操作：\n",
    "\n",
    "        操作清單：\n",
    "        {numbered_operations}\n",
    "\n",
    "        資料集資訊：\n",
    "        {data_info}\n",
    "\n",
    "        我需要移除 {operations_to_remove} 個最不適合或最不相關的操作（約 {removal_percentage*100:.0f}%）。\n",
    "\n",
    "        請基於以下標準分析每個操作並識別應該移除哪些操作：\n",
    "        1. 與實際可用資料欄位的相關性\n",
    "        2. 在給定資料集結構下的可行性  \n",
    "        3. 對羽球比賽分析的實用價值\n",
    "        4. 避免重複或非常相似的操作\n",
    "\n",
    "        請保留 {operations_to_keep} 個最適合的操作並清楚列出它們的編號。\n",
    "        \n",
    "        請逐步思考為什麼某些操作應該被移除，然後提供要保留操作的編號清單。\n",
    "\n",
    "        請用以下格式回答：\n",
    "        分析思路：\n",
    "        [你的分析]\n",
    "\n",
    "        保留的操作編號：\n",
    "        [編號1, 編號2, 編號3, ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.gemini_lm.basic_request(prompt)\n",
    "        print(f\"response: {response}\")\n",
    "        # Extract the kept operation numbers from the result\n",
    "        kept_operation_numbers = self.extract_kept_operation_numbers(response, operation_details)\n",
    "        \n",
    "        return kept_operation_numbers, response\n",
    "    \n",
    "    def extract_kept_operation_numbers(self, filtered_text, operation_details):\n",
    "        \"\"\"\n",
    "        Extract the operation numbers that should be kept from the LLM response\n",
    "        \"\"\"\n",
    "        kept_numbers = []\n",
    "        \n",
    "        print(f\"Debug - 正在分析回應文本...\")\n",
    "        \n",
    "        # Look for the section with kept operation numbers\n",
    "        lines = filtered_text.split('\\n')\n",
    "        \n",
    "        # Find the start of the operations list\n",
    "        start_extracting = False\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            print(f\"Debug - 檢查行: {line}\")\n",
    "            \n",
    "            # Look for section headers that indicate the start of the kept operations list\n",
    "            if any(keyword in line.lower() for keyword in ['保留的操作編號', '保留操作編號', '編號', 'numbers']):\n",
    "                start_extracting = True\n",
    "                print(f\"Debug - 找到標題行，開始提取\")\n",
    "                # 檢查標題行本身是否包含數字\n",
    "                bracket_match = re.search(r'\\[(.*?)\\]', line)\n",
    "                if bracket_match:\n",
    "                    numbers_text = bracket_match.group(1)\n",
    "                    print(f\"Debug - 在標題行找到方括號內容: {numbers_text}\")\n",
    "                    # Split by comma and extract numbers\n",
    "                    for item in numbers_text.split(','):\n",
    "                        number = re.search(r'(\\d+)', item.strip())\n",
    "                        if number:\n",
    "                            kept_numbers.append(number.group(1))\n",
    "                            print(f\"Debug - 提取到編號: {number.group(1)}\")\n",
    "                    if kept_numbers:  # 如果在標題行找到數字，就不需要繼續了\n",
    "                        break\n",
    "                continue\n",
    "            \n",
    "            if start_extracting and line:\n",
    "                # Try to extract numbers from various formats\n",
    "                # Format 1: [編號1, 編號2, ...]\n",
    "                bracket_match = re.search(r'\\[(.*?)\\]', line)\n",
    "                if bracket_match:\n",
    "                    numbers_text = bracket_match.group(1)\n",
    "                    print(f\"Debug - 找到方括號內容: {numbers_text}\")\n",
    "                    # Split by comma and extract numbers\n",
    "                    for item in numbers_text.split(','):\n",
    "                        number = re.search(r'(\\d+)', item.strip())\n",
    "                        if number:\n",
    "                            kept_numbers.append(number.group(1))\n",
    "                            print(f\"Debug - 提取到編號: {number.group(1)}\")\n",
    "                    break\n",
    "                \n",
    "                # Format 2: Numbered list or comma-separated numbers\n",
    "                numbers = re.findall(r'\\b(\\d+)\\b', line)\n",
    "                if numbers:\n",
    "                    kept_numbers.extend(numbers)\n",
    "                    print(f\"Debug - 從行中提取到編號: {numbers}\")\n",
    "                    break\n",
    "        \n",
    "        print(f\"Debug - 原始提取的編號: {kept_numbers}\")\n",
    "        \n",
    "        # Remove duplicates and validate against available operations\n",
    "        valid_numbers = []\n",
    "        available_numbers = [str(detail['number']) for detail in operation_details]  # 確保都是字符串\n",
    "        \n",
    "        print(f\"Debug - 可用的編號: {available_numbers}\")\n",
    "        \n",
    "        for num in kept_numbers:\n",
    "            num_str = str(num)  # 確保是字符串\n",
    "            if num_str in available_numbers and num_str not in valid_numbers:\n",
    "                valid_numbers.append(num_str)\n",
    "        \n",
    "        print(f\"Debug - 驗證後的有效編號: {valid_numbers}\")\n",
    "        return valid_numbers\n",
    "\n",
    "def filter_operations_direct_gemini(api_key, operations_list, operation_details, data_sample, data_info, removal_percentage=0.25):\n",
    "    \"\"\"\n",
    "    Use Gemini API directly to filter operations and return operation numbers\n",
    "    \"\"\"\n",
    "    gemini_lm = Gemini(api_key=api_key)\n",
    "    \n",
    "    operations_count = len(operations_list)\n",
    "    operations_to_remove = int(operations_count * removal_percentage)\n",
    "    operations_to_keep = operations_count - operations_to_remove\n",
    "    \n",
    "    # Create numbered list of operations for easier reference\n",
    "    numbered_operations = \"\\n\".join([f\"{i+1}. {op}\" for i, op in enumerate(operations_list)])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    我有一個羽球比賽的資料集和 {operations_count} 個分析操作。\n",
    "\n",
    "    資料樣本:\n",
    "    {data_sample}\n",
    "\n",
    "    資料集資訊:\n",
    "    {data_info}\n",
    "\n",
    "    操作清單:\n",
    "    {numbered_operations}\n",
    "\n",
    "    請幫我分析並移除 {operations_to_remove} 個最不合適的操作（約 {removal_percentage*100:.0f}%），保留 {operations_to_keep} 個最適合的操作。\n",
    "\n",
    "    請考慮以下標準來決定移除哪些操作：\n",
    "    1. 與實際資料欄位的相關性\n",
    "    2. 在給定資料集結構下的可行性\n",
    "    3. 對羽球比賽分析的實用價值\n",
    "    4. 避免重複或過於相似的操作\n",
    "\n",
    "    請先說明你的分析思路，然後**只提供要保留操作的編號**（從操作描述開頭提取的編號）。\n",
    "\n",
    "    請用以下格式回答：\n",
    "\n",
    "    分析思路：\n",
    "    [你的分析]\n",
    "\n",
    "    保留的操作編號：\n",
    "    [編號1, 編號2, 編號3, ...]\n",
    "\n",
    "    確保只列出要保留的 {operations_to_keep} 個操作的編號。\n",
    "    \"\"\"\n",
    "    \n",
    "    response = gemini_lm.basic_request(prompt)\n",
    "    \n",
    "    # Extract kept operation numbers from the response\n",
    "    kept_operation_numbers = extract_operation_numbers_from_response(response, operation_details)\n",
    "    \n",
    "    return kept_operation_numbers, response\n",
    "\n",
    "def extract_operation_numbers_from_response(response, operation_details):\n",
    "    \"\"\"\n",
    "    Extract the operation numbers to keep from Gemini's response\n",
    "    \"\"\"\n",
    "    kept_numbers = []\n",
    "    \n",
    "    #print(f\"Debug - 正在分析回應文本...\")\n",
    "    \n",
    "    # Look for the section with kept operation numbers\n",
    "    lines = response.split('\\n')\n",
    "    \n",
    "    # Find the start of the operations list\n",
    "    start_extracting = False\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "       # print(f\"Debug - 檢查行: {line}\")\n",
    "        \n",
    "        # Look for section headers that indicate the start of the kept operations list\n",
    "        if any(keyword in line.lower() for keyword in ['保留的操作編號', '保留操作編號', '編號', 'numbers']):\n",
    "            start_extracting = True\n",
    "            #print(f\"Debug - 找到標題行，開始提取\")\n",
    "            # 檢查標題行本身是否包含數字\n",
    "            bracket_match = re.search(r'\\[(.*?)\\]', line)\n",
    "            if bracket_match:\n",
    "                numbers_text = bracket_match.group(1)\n",
    "                #print(f\"Debug - 在標題行找到方括號內容: {numbers_text}\")\n",
    "                # Split by comma and extract numbers\n",
    "                for item in numbers_text.split(','):\n",
    "                    number = re.search(r'(\\d+)', item.strip())\n",
    "                    if number:\n",
    "                        kept_numbers.append(number.group(1))\n",
    "                        #print(f\"Debug - 提取到編號: {number.group(1)}\")\n",
    "                if kept_numbers:  # 如果在標題行找到數字，就不需要繼續了\n",
    "                    break\n",
    "            continue\n",
    "        \n",
    "        if start_extracting and line:\n",
    "            # Try to extract numbers from various formats\n",
    "            # Format 1: [編號1, 編號2, ...]\n",
    "            bracket_match = re.search(r'\\[(.*?)\\]', line)\n",
    "            if bracket_match:\n",
    "                numbers_text = bracket_match.group(1)\n",
    "                #print(f\"Debug - 找到方括號內容: {numbers_text}\")\n",
    "                # Split by comma and extract numbers\n",
    "                for item in numbers_text.split(','):\n",
    "                    number = re.search(r'(\\d+)', item.strip())\n",
    "                    if number:\n",
    "                        kept_numbers.append(number.group(1))\n",
    "                       # print(f\"Debug - 提取到編號: {number.group(1)}\")\n",
    "                break\n",
    "            \n",
    "            # Format 2: Numbered list or comma-separated numbers\n",
    "            numbers = re.findall(r'\\b(\\d+)\\b', line)\n",
    "            if numbers:\n",
    "                kept_numbers.extend(numbers)\n",
    "                #print(f\"Debug - 從行中提取到編號: {numbers}\")\n",
    "                break\n",
    "    \n",
    "    #print(f\"Debug - 原始提取的編號: {kept_numbers}\")\n",
    "    \n",
    "    # Remove duplicates and validate against available operations\n",
    "    valid_numbers = []\n",
    "    available_numbers = [str(detail['number']) for detail in operation_details]  # 確保都是字符串\n",
    "    \n",
    "    #print(f\"Debug - 可用的編號: {available_numbers}\")\n",
    "    \n",
    "    for num in kept_numbers:\n",
    "        num_str = str(num)  # 確保是字符串\n",
    "        if num_str in available_numbers and num_str not in valid_numbers:\n",
    "            valid_numbers.append(num_str)\n",
    "    \n",
    "    #print(f\"Debug - 驗證後的有效編號: {valid_numbers}\")\n",
    "    return valid_numbers\n",
    "\n",
    "def get_data_summary(dataframe):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary of the dataset\n",
    "    \"\"\"\n",
    "    summary = f\"\"\"\n",
    "    資料集概要:\n",
    "    - 總行数: {dataframe.shape[0]}\n",
    "    - 總列数: {dataframe.shape[1]}\n",
    "    - 欄位名稱: {', '.join(dataframe.columns)}\n",
    "    \n",
    "    各欄位資訊:\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in dataframe.columns:\n",
    "        col_info = f\"  - {col}: \"\n",
    "        if dataframe[col].dtype in ['object', 'string']:\n",
    "            unique_values = dataframe[col].unique()[:10]  # Show first 10 unique values\n",
    "            col_info += f\"類別型資料, 獨特值範例: {', '.join(map(str, unique_values))}\"\n",
    "        else:\n",
    "            col_info += f\"數值型資料, 範圍: {dataframe[col].min()} - {dataframe[col].max()}\"\n",
    "        \n",
    "        summary += col_info + \"\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def filter_badminton_operations(operations_list, operation_details, dataframe, api_key, removal_percentage=0.25):\n",
    "    \"\"\"\n",
    "    Main function to filter operations using Gemini LLM and return operation numbers\n",
    "    \"\"\"\n",
    "    print(f\"原始操作數量: {len(operations_list)}\")\n",
    "    print(\"原始操作清單:\")\n",
    "    for i, op in enumerate(operations_list, 1):\n",
    "        print(f\"  {i}. {op}\")\n",
    "    \n",
    "    # Get data summary\n",
    "    data_summary = get_data_summary(dataframe)\n",
    "    data_sample = dataframe.to_string()  # Use only first 5 rows for sample\n",
    "    \n",
    "    print(f\"\\n使用 Gemini LLM 過濾操作 (移除 {removal_percentage*100:.0f}%)...\")\n",
    "    \n",
    "    # Method 1: Use custom filter class with Gemini\n",
    "    try:\n",
    "        print(\"方法1: 使用自定義過濾器 + Gemini...\")\n",
    "        filter_module = OperationFilter(api_key)\n",
    "        dspy_filtered_numbers, dspy_response = filter_module.forward(\n",
    "            operations_list, \n",
    "            operation_details,\n",
    "            data_summary, \n",
    "            removal_percentage\n",
    "        )\n",
    "        print(f\"自定義過濾器方法保留了 {len(dspy_filtered_numbers)} 個操作編號\")\n",
    "        \n",
    "        print(\"\\n自定義過濾器回應:\")\n",
    "        print(\"=\"*30)\n",
    "        print(dspy_response[:500] + \"...\" if len(dspy_response) > 500 else dspy_response)\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"自定義過濾器方法失敗: {e}\")\n",
    "        dspy_filtered_numbers = []\n",
    "    \n",
    "    # Method 2: Direct Gemini API call\n",
    "    try:\n",
    "        print(\"方法2: 直接使用 Gemini API...\")\n",
    "        direct_filtered_numbers, gemini_response = filter_operations_direct_gemini(\n",
    "            api_key, \n",
    "            operations_list, \n",
    "            operation_details,\n",
    "            data_sample, \n",
    "            data_summary, \n",
    "            removal_percentage\n",
    "        )\n",
    "        print(f\"直接 API 方法保留了 {len(direct_filtered_numbers)} 個操作編號\")\n",
    "        \n",
    "        print(\"\\nGemini 回應:\")\n",
    "        print(\"=\"*50)\n",
    "        print(gemini_response)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"直接 API 方法失敗: {e}\")\n",
    "        direct_filtered_numbers = []\n",
    "    \n",
    "    # Combine results (prefer direct method if both work, fallback to custom filter)\n",
    "    if direct_filtered_numbers:\n",
    "        final_operation_numbers = direct_filtered_numbers\n",
    "        print(f\"\\n使用直接 API 方法的結果\")\n",
    "    elif dspy_filtered_numbers:\n",
    "        final_operation_numbers = dspy_filtered_numbers\n",
    "        print(f\"\\n使用自定義過濾器方法的結果\")\n",
    "    else:\n",
    "        # Fallback: keep random subset of operation numbers\n",
    "        target_count = int(len(operations_list) * (1 - removal_percentage))\n",
    "        final_operation_numbers = [detail['number'] for detail in operation_details[:target_count]]\n",
    "        print(f\"\\n兩種方法都失敗，使用前 {target_count} 個操作編號作為備案\")\n",
    "    \n",
    "    print(f\"\\n最終保留的操作編號 ({len(final_operation_numbers)} 個):\")\n",
    "    for i, number in enumerate(final_operation_numbers, 1):\n",
    "        # Find the operation details for display\n",
    "        for detail in operation_details:\n",
    "            if detail['number'] == number:\n",
    "                print(f\"  {i}. 編號 {number}: {detail['name']}\")\n",
    "                break\n",
    "    \n",
    "    return final_operation_numbers\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load operations from JSON file\n",
    "    json_file_path = \"operations.json\"\n",
    "    operation_details, operation_strings = load_operations_from_json(json_file_path)\n",
    "    \n",
    "    if not operation_strings:\n",
    "        print(\"無法載入操作，程式結束\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"\\n載入的操作詳情:\")\n",
    "    for i, detail in enumerate(operation_details[:5], 1):  # Show first 5 as example\n",
    "        print(f\"  {i}. 編號: {detail['number']}, 名稱: {detail['name']}\")\n",
    "        print(f\"      描述: {detail['description']}\")\n",
    "    \n",
    "    if len(operation_details) > 5:\n",
    "        print(f\"  ... 還有 {len(operation_details) - 5} 個操作\")\n",
    "    \n",
    "    # Load badminton data\n",
    "    try:\n",
    "        example_df = pd.read_csv('set1.csv')\n",
    "        print(f\"\\n成功載入資料集: {example_df.shape[0]} 行, {example_df.shape[1]} 列\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"錯誤: 找不到 set1.csv 文件\")\n",
    "        exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"載入資料集時發生錯誤: {e}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Your Gemini API key\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    \n",
    "    # Filter operations and get operation numbers\n",
    "    filtered_operation_numbers = filter_badminton_operations(\n",
    "        operation_strings,  # Use the formatted strings for LLM processing\n",
    "        operation_details,  # Pass the operation details for number extraction\n",
    "        example_df, \n",
    "        api_key, \n",
    "        removal_percentage=0.2\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n操作過濾完成！從 {len(operation_strings)} 個操作減少到 {len(filtered_operation_numbers)} 個操作。\")\n",
    "    print(f\"保留的操作編號清單: {filtered_operation_numbers}\")\n",
    "\n",
    "    # 從 JSON 檔案讀取 \"operations\" 分支\n",
    "    with open(\"operations.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        all_data = json.load(f)\n",
    "        original_operations = all_data[\"operations\"]\n",
    "\n",
    "    # 你想要挑選的 operation 編號（根據實際需求修改這個 list）\n",
    "    selected_numbers = [int(num) for num in filtered_operation_numbers]\n",
    "    print(f\"selected_numbers: {selected_numbers}\")\n",
    "    print(f\"original_operations: {original_operations}\")\n",
    "    # 根據 selected_numbers 選出對應操作，並從 1 開始重新編號\n",
    "    filtered_operations = []\n",
    "    for new_number, original_number in enumerate(selected_numbers, start=1):\n",
    "        for op in original_operations:\n",
    "            if op[\"number\"] == original_number:\n",
    "                filtered_operations.append({\n",
    "                    \"number\": new_number,\n",
    "                    \"name\": op[\"name\"],\n",
    "                    \"description\": op[\"description\"]\n",
    "                })\n",
    "                break\n",
    "    #print(f\"filtered_operations: {filtered_operations}\")\n",
    "    # 新的 JSON 結構\n",
    "    output_json = {\n",
    "        \"description\": \"Selected operations for badminton data analysis.\",\n",
    "        \"requirements\": [\n",
    "            \"The output must be based on the input data ; do not hallucinate.\",\n",
    "            \"Give me the list of numbers.\"\n",
    "        ],\n",
    "        \"operations\": filtered_operations\n",
    "    }\n",
    "\n",
    "    # 寫入 JSON 檔案\n",
    "    with open(\"filtered_operations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"filtered_operations.json has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf4009",
   "metadata": {},
   "source": [
    "# STEP 6\n",
    "\n",
    "根據真實table只保留重要70%操作，保留'write' 'select_col' 'select_row'三個重要操作，到'selected_operations.json'\n",
    "\n",
    "操作提取已完成!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da8caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "從 operations_info.json 成功載入 15 個操作\n",
      "operation_length: 15\n",
      "[1, 2, 4, 5, 3, 6, 7, 9, 10, 8, 13, 12, 14, 15, 11]\n",
      "response: 好的，我將根據您的要求，使用鏈式思考的方式，分析並排序您提供的 15 個分析操作，並輸出一個由操作編號組成的陣列，按照重要性由高到低排列。\n",
      "\n",
      "**鏈式思考分析：**\n",
      "\n",
      "首先，我需要理解作為一個資深羽毛球新聞記者，讀者最想看到什麼樣的資訊，以及哪些分析操作能提供這些資訊。\n",
      "\n",
      "1.  **比賽結果和基本資訊：** 讀者首先關心的是誰贏了，以及比賽的總體情況。\n",
      "\n",
      "2.  **關鍵球員表現和戰術：** 讀者會想知道關鍵球員在比賽中的表現如何，使用了哪些戰術，以及這些戰術是否有效。\n",
      "\n",
      "3.  **失誤分析：** 分析失誤的原因可以幫助讀者了解比賽的轉折點和球員的弱點。\n",
      "\n",
      "4.  **進階分析：** 結合時間、回合得分等因素，分析比賽的節奏、球員的體能變化等。\n",
      "\n",
      "基於以上思考，我將各個操作的重要性排序如下：\n",
      "\n",
      "*   **極高重要性：**\n",
      "\n",
      "    *   **1. write:** 這個操作能將分析結果轉化為新聞報導，是最終呈現給讀者的形式。\n",
      "    *   **2. select_row:** 選擇特定條件的行，例如特定球員的數據，是深入分析的基礎。\n",
      "    *   **4. group_by:** 將數據按照不同的類型分組，例如按照球員、回合等分組，是進行統計分析的前提。\n",
      "    *   **5. aggregate:** 統計不同組別的數據，例如統計每個球員的得分、失誤等，提供關鍵資訊。\n",
      "*   **高重要性：**\n",
      "\n",
      "    *   **3. select_column:** 選擇特定的列，例如選擇球的類型、失誤原因等，是聚焦分析的必要步驟。\n",
      "    *   **6. value_counts:** 統計各種類型的球、失誤原因等的出現次數，提供直觀的數據。\n",
      "    *   **7. crosstab:** 交叉分析不同因素之間的關係，例如球的類型和得分球員之間的關係。\n",
      "*   **中等重要性：**\n",
      "\n",
      "    *   **9. sort:** 按照時間排序，可以分析比賽的進程。\n",
      "    *   **10. calculate:** 計算新的欄位，例如計算回合長度，可以提供更深入的分析。\n",
      "    *   **8. pivot_table:** 創建透視表，可以更靈活地總結數據。\n",
      "*   **低重要性：**\n",
      "\n",
      "    *   **13. normalize:** 正規化球的類型分佈，可以分析戰術的變化，但可能不夠直觀。\n",
      "    *   **12. rolling_window:** 計算時間的滾動平均，可以分析比賽的節奏變化，但可能對一般讀者來說太過技術性。\n",
      "    *   **14. correlation:** 計算欄位之間的相關性，可能發現一些有趣的關係，但可能不夠直接。\n",
      "    *   **15. one_hot_encoding:** 將分類變數轉換為二元矩陣，通常用於機器學習模型，對新聞報導的價值較低。\n",
      "    *   **11. merge:** 合併兩個表格，這個操作在這個資料集中可能不太常用。\n",
      "\n",
      "**排序後的陣列：**\n",
      "\n",
      "```\n",
      "[1, 2, 4, 5, 3, 6, 7, 9, 10, 8, 13, 12, 14, 15, 11]\n",
      "```\n",
      "\n",
      "排序操作重要性編號: [1, 2, 4, 5, 3, 6, 7, 9, 10, 8, 13, 12, 14, 15, 11]\n",
      "operation_details: [{'number': '1', 'name': 'write', 'description': 'If the table is clear or small enough, generates text based on the tables using the LLM.', 'formatted': '1. write: If the table is clear or small enough, generates text based on the tables using the LLM.'}, {'number': '2', 'name': 'select_row', 'description': \"Subsets the table to rows matching a condition. Example: `df[df['getpoint_player'] == 'PlayerA']`.\", 'formatted': \"2. select_row: Subsets the table to rows matching a condition. Example: `df[df['getpoint_player'] == 'PlayerA']`.\"}, {'number': '3', 'name': 'select_column', 'description': \"Selects one or more columns from the table. Example: `df[['type', 'lose_reason']]`.\", 'formatted': \"3. select_column: Selects one or more columns from the table. Example: `df[['type', 'lose_reason']]`.\"}, {'number': '4', 'name': 'group_by', 'description': \"Groups rows based on one or more columns, enabling aggregate calculations. Example: `df.groupby('type')['getpoint_player'].count()`.\", 'formatted': \"4. group_by: Groups rows based on one or more columns, enabling aggregate calculations. Example: `df.groupby('type')['getpoint_player'].count()`.\"}, {'number': '5', 'name': 'aggregate', 'description': \"Calculates summary statistics for each group. Example: `df.groupby('type')['getpoint_player'].agg(['count', 'mean'])`.\", 'formatted': \"5. aggregate: Calculates summary statistics for each group. Example: `df.groupby('type')['getpoint_player'].agg(['count', 'mean'])`.\"}, {'number': '6', 'name': 'value_counts', 'description': \"Counts the occurrences of each unique value in a column. Example: `df['lose_reason'].value_counts()`.\", 'formatted': \"6. value_counts: Counts the occurrences of each unique value in a column. Example: `df['lose_reason'].value_counts()`.\"}, {'number': '7', 'name': 'crosstab', 'description': \"Computes a cross-tabulation of two or more factors. Example: `pd.crosstab(df['type'], df['getpoint_player'])`.\", 'formatted': \"7. crosstab: Computes a cross-tabulation of two or more factors. Example: `pd.crosstab(df['type'], df['getpoint_player'])`.\"}, {'number': '8', 'name': 'pivot_table', 'description': \"Creates a pivot table summarizing data. Example: `pd.pivot_table(df, values='rally', index='type', columns='getpoint_player', aggfunc='mean')`.\", 'formatted': \"8. pivot_table: Creates a pivot table summarizing data. Example: `pd.pivot_table(df, values='rally', index='type', columns='getpoint_player', aggfunc='mean')`.\"}, {'number': '9', 'name': 'sort', 'description': \"Orders the table by one or more columns. Example: `df.sort_values(by='time')`.\", 'formatted': \"9. sort: Orders the table by one or more columns. Example: `df.sort_values(by='time')`.\"}, {'number': '10', 'name': 'calculate', 'description': \"Performs mathematical operations on columns to create new columns. Example: `df['rally_length'] = df['time'].diff()`.\", 'formatted': \"10. calculate: Performs mathematical operations on columns to create new columns. Example: `df['rally_length'] = df['time'].diff()`.\"}, {'number': '11', 'name': 'merge', 'description': 'Joins two tables based on a common column.', 'formatted': '11. merge: Joins two tables based on a common column.'}, {'number': '12', 'name': 'rolling_window', 'description': 'Calculate the rolling mean of the \"time\" column to check the change of the speed.', 'formatted': '12. rolling_window: Calculate the rolling mean of the \"time\" column to check the change of the speed.'}, {'number': '13', 'name': 'normalize', 'description': 'Normalizes the distribution of \"type\" columns based on roundscore to check the change of the shot distribution.', 'formatted': '13. normalize: Normalizes the distribution of \"type\" columns based on roundscore to check the change of the shot distribution.'}, {'number': '14', 'name': 'correlation', 'description': 'Computes the correlation between two columns.', 'formatted': '14. correlation: Computes the correlation between two columns.'}, {'number': '15', 'name': 'one_hot_encoding', 'description': \"Converts categorical variables into a binary matrix representation. Example: `pd.get_dummies(df, columns=['type'])`.\", 'formatted': \"15. one_hot_encoding: Converts categorical variables into a binary matrix representation. Example: `pd.get_dummies(df, columns=['type'])`.\"}]\n",
      "✅ selected_operations.json has been created.\n"
     ]
    }
   ],
   "source": [
    "# 正式版 - 使用 Gemini 過濾羽球比賽分析操作\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dspy\n",
    "import re\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "class Gemini(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model_instance = genai.GenerativeModel(model_name)\n",
    "        super().__init__(model=model_name)\n",
    "\n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "        if isinstance(messages, list):\n",
    "            prompt_text = \"\".join([msg.get('content', '') for msg in messages])\n",
    "        else:\n",
    "            prompt_text = str(messages)\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt_text)\n",
    "            if not response.text:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return [{ 'text': response.text, 'logprobs': None }]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{ 'text': \"⚠️ Gemini API 回應失敗,可能已達限額或出現錯誤。\", 'logprobs': None }]\n",
    "\n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "def setup_gemini_api(api_key):\n",
    "    lm = Gemini(api_key=api_key)\n",
    "    dspy.settings.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "def load_operations_from_json(json_file_path):\n",
    "    try:\n",
    "        with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        operations_data = data if isinstance(data, dict) else {}\n",
    "        operation_details = []\n",
    "        operation_strings = []\n",
    "\n",
    "        for key, op in operations_data.items():\n",
    "            name = op.get('operation', '')\n",
    "            desc = op.get('description', '')\n",
    "            if key and name and desc:\n",
    "                formatted_op = f\"{key}. {name}: {desc}\"\n",
    "                operation_strings.append(formatted_op)\n",
    "                operation_details.append({\n",
    "                    'number': key,\n",
    "                    'name': name,\n",
    "                    'description': desc,\n",
    "                    'formatted': formatted_op\n",
    "                })\n",
    "\n",
    "        print(f\"從 {json_file_path} 成功載入 {len(operation_strings)} 個操作\")\n",
    "        return operation_details, operation_strings\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 載入 operations_info.json 時發生錯誤: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def get_data_summary(dataframe):\n",
    "    summary = f\"資料集概要:\\n- 總行數: {dataframe.shape[0]}\\n- 總列數: {dataframe.shape[1]}\\n- 欄位名稱: {', '.join(dataframe.columns)}\\n\\n各欄位資訊:\\n\"\n",
    "    for col in dataframe.columns:\n",
    "        summary += f\"  - {col}: \"\n",
    "        if dataframe[col].dtype in ['object', 'string']:\n",
    "            summary += f\"類別型資料, 獨特值範例: {', '.join(map(str, dataframe[col].unique()[:10]))}\\n\"\n",
    "        else:\n",
    "            summary += f\"數值型資料, 範圍: {dataframe[col].min()} - {dataframe[col].max()}\\n\"\n",
    "    return summary\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "\n",
    "def extract_operation_numbers_from_response(response):\n",
    "    # 使用正则表达式匹配数组\n",
    "    pattern = r'```\\s*\\[([\\d,\\s]+)\\]\\s*```'\n",
    "    match = re.search(pattern, response)\n",
    "\n",
    "    if match:\n",
    "        # 提取匹配的数组字符串并转换为列表\n",
    "        array_str = match.group(1)\n",
    "        operation_list = [int(num) for num in array_str.replace(' ', '').split(',')]\n",
    "        print(operation_list)\n",
    "        return operation_list\n",
    "    else:\n",
    "        print(\"未找到排序数组\")\n",
    "    \n",
    "def filter_badminton_operations(operation_details, operation_strings, df, api_key, outline_path='outline.txt'):\n",
    "    gemini = Gemini(api_key=api_key)\n",
    "    data_summary = get_data_summary(df)\n",
    "    data_sample = df.to_string()\n",
    "    outline = read_text_file(outline_path)\n",
    "    print(f\"operation_length: {len(operation_strings)}\")\n",
    "    prompt = f\"\"\"\n",
    "    我有一個撰寫新聞的大鋼與比賽的資料集和 {len(operation_strings)} 個分析操作，請依據操作重要性排序(由高到低)。\n",
    "\n",
    "    大綱:\n",
    "    {outline}\n",
    "\n",
    "    資料樣本:\n",
    "    {data_sample}\n",
    "\n",
    "    資料集資訊:\n",
    "    {data_summary}\n",
    "\n",
    "    操作清單:\n",
    "    {'\\n'.join(operation_strings)}\n",
    "\n",
    "    請先根據chain_of_thought分析，將操作編號根據重要性排序，每個編號僅在陣列中出現一次，陣列長度應為{len(operation_strings)}:\n",
    "    [1, 2, 3, ...]\n",
    "    \"\"\"\n",
    "    response = gemini.basic_request(prompt)\n",
    "    #print(response)\n",
    "    return extract_operation_numbers_from_response(response), response\n",
    "\n",
    "def main():\n",
    "    json_file_path = \"operations_info.json\"\n",
    "    operation_details, operation_strings = load_operations_from_json(json_file_path)\n",
    "    if not operation_details:\n",
    "        return\n",
    "    try:\n",
    "        df = pd.read_csv(\"filtered_set1.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 載入資料錯誤: {e}\")\n",
    "        return\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"❌ GOOGLE_API_KEY 未設定\")\n",
    "        return\n",
    "    kept_numbers, response = filter_badminton_operations(operation_details, operation_strings, df, api_key, outline_path = 'main.txt')\n",
    "    print(f\"response: {response}\")\n",
    "    #kept_numbers = list(set(kept_numbers) | {1, 2, 3})\n",
    "    print(\"排序操作重要性編號:\", kept_numbers)\n",
    "    kept_numbers = list(set(kept_numbers[:int(0.7*len(kept_numbers))]) | {1,2,3})\n",
    "    new_operations = []\n",
    "    print(f\"operation_details: {operation_details}\")\n",
    "    for new_id, num in enumerate(kept_numbers, 1):\n",
    "        for detail in operation_details:\n",
    "            if int(detail['number']) == int(num):\n",
    "                new_operations.append({\n",
    "                    'number': new_id,\n",
    "                    'name': detail['name'],\n",
    "                    'description': detail['description']\n",
    "                })\n",
    "                break\n",
    "    output_json = new_operations\n",
    "    \n",
    "    with open(\"selected_operations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_json, f, indent=2, ensure_ascii=False)\n",
    "    print(\"✅ selected_operations.json has been created.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d4081",
   "metadata": {},
   "source": [
    "新增重要operations(select_row, select_col, write) 到'selected_operations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fc64e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 讀取 filtered_operation.json\n",
    "with open('filtered_operations.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 取得目前最大 number\n",
    "existing_numbers = [op['number'] for op in data['operations']]\n",
    "max_number = max(existing_numbers)\n",
    "\n",
    "# 新增的 operations\n",
    "new_operations = [\n",
    "    {\n",
    "        \"number\": max_number + 1,\n",
    "        \"name\": \"select_row\",\n",
    "        \"description\": \"Selects rows based on their row indices.\"\n",
    "    },\n",
    "    {\n",
    "        \"number\": max_number + 2,\n",
    "        \"name\": \"select_col\",\n",
    "        \"description\": \"Selects columns based on their column names.\"\n",
    "    },\n",
    "    {\n",
    "        \"number\": max_number + 3,\n",
    "        \"name\": \"write\",\n",
    "        \"description\": \"If the table is small enough, generates text based on the tables using the LLM; represents the leaf node of the tree.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 將新操作加入原始資料\n",
    "data['operations'].extend(new_operations)\n",
    "\n",
    "# 寫回 JSON 檔\n",
    "with open('selected_operations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 輸出所有操作的 number 列表\n",
    "all_numbers = [op['number'] for op in data['operations']]\n",
    "print(all_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8adeb2",
   "metadata": {},
   "source": [
    "# STEP 7\n",
    "\n",
    "根據Table,得到要執行的操作與參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23802814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Planner for Badminton Game Report\n",
      "==================================================\n",
      "正在載入數據...\n",
      "成功載入CSV: 315 行, 9 列\n",
      "載入表格描述: 494 字符\n",
      "載入操作描述: 10 個項目\n",
      "操作池: ['write', 'select_row', 'select_column', 'group_by', 'aggregate', 'value_counts', 'crosstab', 'pivot_table', 'sort', 'calculate']\n",
      "操作歷史: ['root(None)']\n",
      "\n",
      "開始生成操作和參數...\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "\n",
      "==================================================\n",
      "GEMINI 輸出結果:\n",
      "==================================================\n",
      "[select_column(type, lose_reason, getpoint_player), value_counts(type), value_counts(lose_reason)]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "class ContentPlanner:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        \n",
    "    def generate_operations(self, tables, table_description, operation_description, \n",
    "                          operation_history, operation_pool, max_depth=5, max_degree=3,outline_path='main.txt'):\n",
    "        \"\"\"\n",
    "        使用Gemini生成operations和arguments\n",
    "        \"\"\"\n",
    "        \n",
    "        # 構建完整的提示詞\n",
    "        prompt = f\"\"\"System : You are a content planner for the report. Please follow the outline. Please select candidate Operations and corresponding Arguments from the Operation Pool based on the input Tables and Operation History. These candidate Operations will be the next Operation in the Operation History .\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in English .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The length of Operation History must be less than or equal to {max_depth}.\n",
    "5. The number of Operations must be less than or equal to {max_degree}.\n",
    "6. Only select Opertions from the Operation Pool .\n",
    "7. Arguments must match the format required by the corresponding Operations .\n",
    "8. Operations & Arguments must follow this format : [ operation_1 ( argument_1 , ...) , operation_2 ( argument_2 , ...) , operation_3 ( argument_3 , ...) , ...]\n",
    "9. Only output Operations & Arguments !\n",
    "10. If Table is big or Level is low, it should be more Operations include select_col or select_row not write.\n",
    "11. If the length of Operation History is short, then more operations or more arguments.\n",
    "12. Write operations do not need argument.\n",
    "\n",
    "#outline\n",
    "{read_text_file(outline_path)}\n",
    "\n",
    "# Table Description\n",
    "{table_description}\n",
    "\n",
    "# Operation Description\n",
    "{json.dumps(operation_description, indent=2, ensure_ascii=False)}\n",
    "\n",
    "User : # Test\n",
    "## Tables\n",
    "{tables}\n",
    "\n",
    "## Operation History\n",
    "{operation_history}\n",
    "\n",
    "## Operation Pool\n",
    "{operation_pool}\n",
    "\n",
    "## Operations & Arguments\"\"\"\n",
    "\n",
    "        try:\n",
    "            print(\"正在向Gemini發送請求...\")\n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            if response.text:\n",
    "                print(\"成功獲得Gemini回應\")\n",
    "                return response.text.strip()\n",
    "            else:\n",
    "                print(\"Gemini回應為空\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Gemini API請求失敗: {e}\")\n",
    "            return None\n",
    "        \n",
    "def read_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "    \n",
    "# 設置API密鑰\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(\"Content Planner for Badminton Game Report\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 檢查是否有必要的文件\n",
    "#required_files = ['filtered_set1.csv', 'filtered_data_description.txt', 'filtered_operations.json']\n",
    "\n",
    "print(\"正在載入數據...\")\n",
    "\n",
    "# 讀取CSV檔案\n",
    "TABLES = pd.read_csv('filtered_set1.csv')\n",
    "tables_str = TABLES.to_string()\n",
    "print(f\"成功載入CSV: {TABLES.shape[0]} 行, {TABLES.shape[1]} 列\")\n",
    "\n",
    "# 讀取表格描述\n",
    "TABLE_DESCRIPTION = read_text_file(\"filtered_data_description.txt\")\n",
    "if not TABLE_DESCRIPTION:\n",
    "    TABLE_DESCRIPTION = \"No table description available\"\n",
    "print(f\"載入表格描述: {len(TABLE_DESCRIPTION)} 字符\")\n",
    "\n",
    "# 讀取操作描述\n",
    "OPERATION_DESCRIPTION = read_json_file(\"selected_operations.json\")\n",
    "print(f\"載入操作描述: {len(OPERATION_DESCRIPTION)} 個項目\")\n",
    "\n",
    "# 設置其他變數\n",
    "MAX_DEPTH = 5\n",
    "MAX_DEGREE = 5\n",
    "OPERATION_HISTORY = ['root(None)']\n",
    "Level = 0\n",
    "# 從操作描述中提取操作池\n",
    "#if 'operations' in OPERATION_DESCRIPTION:\n",
    "#    OPERATION_POOL = [op['name'] for op in OPERATION_DESCRIPTION['operations']]\n",
    "#else:\n",
    "#    OPERATION_POOL = list(OPERATION_DESCRIPTION.keys())\n",
    "OPERATION_POOL = [op['name'] for op in OPERATION_DESCRIPTION]\n",
    "\n",
    "print(f\"操作池: {OPERATION_POOL}\")\n",
    "print(f\"操作歷史: {OPERATION_HISTORY}\")\n",
    "    \n",
    "\n",
    "\n",
    "# 初始化內容規劃器\n",
    "planner = ContentPlanner(api_key)\n",
    "\n",
    "# 生成操作和參數\n",
    "print(\"\\n開始生成操作和參數...\")\n",
    "operations_and_arguments = planner.generate_operations(\n",
    "    tables=tables_str,\n",
    "    table_description=TABLE_DESCRIPTION,\n",
    "    operation_description=OPERATION_DESCRIPTION,\n",
    "    operation_history=OPERATION_HISTORY,\n",
    "    operation_pool=OPERATION_POOL,\n",
    "    max_depth=MAX_DEPTH,\n",
    "    max_degree=MAX_DEGREE,\n",
    "    outline_path='analyze_response.txt'\n",
    ")\n",
    "OPERATION_HISTORY = OPERATION_HISTORY.append(operations_and_arguments)\n",
    "Level +=1\n",
    "\n",
    "if operations_and_arguments:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GEMINI 輸出結果:\")\n",
    "    print(\"=\"*50)\n",
    "    print(operations_and_arguments)\n",
    "    print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "243e8c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[select_column(type, lose_reason, getpoint_player), value_counts(type), value_counts(lose_reason)]\n"
     ]
    }
   ],
   "source": [
    "print(operations_and_arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b317faf",
   "metadata": {},
   "source": [
    "解析LLM response內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc1223e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select_column(type, lose_reason, getpoint_player)', 'value_counts(type)', 'value_counts(lose_reason)']\n"
     ]
    }
   ],
   "source": [
    "# 原始字符串\n",
    "test_str = operations_and_arguments\n",
    "\n",
    "# 提取方括号内的内容\n",
    "start = test_str.find('[') + 1\n",
    "end = test_str.rfind(']')\n",
    "content = test_str[start:end].strip()\n",
    "\n",
    "elements = []\n",
    "current = []\n",
    "stack = 0\n",
    "\n",
    "# 遍历字符进行解析\n",
    "for char in content:\n",
    "    if char == '(':\n",
    "        stack += 1\n",
    "        current.append(char)\n",
    "    elif char == ')':\n",
    "        stack -= 1\n",
    "        current.append(char)\n",
    "    elif char == ',' and stack == 0:\n",
    "        elements.append(''.join(current).strip())\n",
    "        current = []\n",
    "    else:\n",
    "        current.append(char)\n",
    "\n",
    "# 添加最后一个元素\n",
    "if current:\n",
    "    elements.append(''.join(current).strip())\n",
    "\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12882b",
   "metadata": {},
   "source": [
    "# STEP 8\n",
    "\n",
    "根據欄位型態與'operation_name' 和 'operation_argument'，請LLM撰寫可以執行的操作程式碼\n",
    "\n",
    "取欄位型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe204f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          int64\n",
      "rally               int64\n",
      "time               object\n",
      "roundscore_A        int64\n",
      "roundscore_B        int64\n",
      "player             object\n",
      "type               object\n",
      "lose_reason        object\n",
      "getpoint_player    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_copy = pd.read_csv(\"filtered_set1.csv\")\n",
    "df = df_copy\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2986094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315 entries, 0 to 314\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       315 non-null    int64 \n",
      " 1   rally            315 non-null    int64 \n",
      " 2   time             315 non-null    object\n",
      " 3   roundscore_A     315 non-null    int64 \n",
      " 4   roundscore_B     315 non-null    int64 \n",
      " 5   player           315 non-null    object\n",
      " 6   type             315 non-null    object\n",
      " 7   lose_reason      36 non-null     object\n",
      " 8   getpoint_player  36 non-null     object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 22.3+ KB\n",
      "生成的程式碼：\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "def select_column(df, type_col, lose_reason_col, getpoint_player_col):\n",
      "  \"\"\"\n",
      "  從 DataFrame 中選擇指定的欄位。\n",
      "\n",
      "  Args:\n",
      "    df: pandas DataFrame.\n",
      "    type_col: 類型欄位的名稱 (字串).\n",
      "    lose_reason_col: 失敗原因欄位的名稱 (字串).\n",
      "    getpoint_player_col: 得分球員欄位的名稱 (字串).\n",
      "\n",
      "  Returns:\n",
      "    一個新的 DataFrame，僅包含指定的欄位。\n",
      "  \"\"\"\n",
      "  return df[[type_col, lose_reason_col, getpoint_player_col]]\n",
      "\n",
      "\n",
      "# 讀取 CSV 數據集\n",
      "try:\n",
      "    df = pd.read_csv(\"filtered_set1.csv\")\n",
      "except FileNotFoundError:\n",
      "    print(\"錯誤：找不到 'filtered_set1.csv' 檔案。請確認檔案路徑是否正確。\")\n",
      "    exit()\n",
      "except pd.errors.EmptyDataError:\n",
      "    print(\"錯誤：'filtered_set1.csv' 檔案為空。\")\n",
      "    exit()\n",
      "except pd.errors.ParserError:\n",
      "    print(\"錯誤：解析 'filtered_set1.csv' 檔案時發生錯誤。請檢查檔案格式是否正確。\")\n",
      "    exit()\n",
      "\n",
      "\n",
      "# 指定欄位名稱\n",
      "type_col = \"type\"  # 替換為實際的欄位名稱\n",
      "lose_reason_col = \"lose_reason\"  # 替換為實際的欄位名稱\n",
      "getpoint_player_col = \"getpoint_player\" # 替換為實際的欄位名稱\n",
      "\n",
      "\n",
      "# 執行 select_column 操作\n",
      "try:\n",
      "    modified_df = select_column(df.copy(), type_col, lose_reason_col, getpoint_player_col)\n",
      "except KeyError as e:\n",
      "    print(f\"錯誤：DataFrame 中找不到欄位 '{e.args[0]}'。請檢查欄位名稱是否正確。\")\n",
      "    exit()\n",
      "\n",
      "\n",
      "# 將修改後的 DataFrame 存入 'tmp.csv'\n",
      "try:\n",
      "    modified_df.to_csv(\"tmp.csv\", index=False)\n",
      "    print(\"已成功將修改後的 DataFrame 儲存到 'tmp.csv'。\")\n",
      "except Exception as e:\n",
      "    print(f\"儲存檔案時發生錯誤：{e}\")\n",
      "```\n",
      "\n",
      "已成功將修改後的 DataFrame 儲存到 'tmp.csv'。\n",
      "\n",
      "處理結果：\n",
      "     type lose_reason getpoint_player\n",
      "0     發長球         NaN             NaN\n",
      "1      切球         NaN             NaN\n",
      "2      挑球         NaN             NaN\n",
      "3      長球         NaN             NaN\n",
      "4      殺球         NaN             NaN\n",
      "..    ...         ...             ...\n",
      "310  未知球種         NaN             NaN\n",
      "311    切球         NaN             NaN\n",
      "312    挑球         NaN             NaN\n",
      "313    長球         NaN             NaN\n",
      "314    長球          出界               A\n",
      "\n",
      "[315 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "elements = ['select_column(type, lose_reason, getpoint_player)', 'value_counts(type)', 'value_counts(lose_reason)']\n",
    "\n",
    "class Gemini(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model_instance = genai.GenerativeModel(model_name)\n",
    "        super().__init__(model=model_name)\n",
    "\n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "        if isinstance(messages, list):\n",
    "            prompt_text = \"\".join([msg.get('content', '') for msg in messages])\n",
    "        else:\n",
    "            prompt_text = str(messages)\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt_text)\n",
    "            if not response.text:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return [{'text': response.text, 'logprobs': None}]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{'text': \"⚠️ Gemini API 回應失敗\", 'logprobs': None}]\n",
    "\n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "def setup_gemini_api(api_key):\n",
    "    lm = Gemini(api_key=api_key)\n",
    "    dspy.settings.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "class DataFrameOperator:\n",
    "    def __init__(self, api_key):\n",
    "        self.lm = setup_gemini_api(api_key)\n",
    "\n",
    "    def generate_code(self, operation, df_info, df_path):\n",
    "        prompt = f\"\"\"\n",
    "        你是一個專業的Python資料分析助手。欄位名稱以資料欄位類型提供為主，根據以下要求生成操作DataFrame的程式碼：\n",
    "\n",
    "        要執行的操作: {operation}\n",
    "\n",
    "        CSV數據集: {df_path}\n",
    "\n",
    "        資料欄位類型:\n",
    "        {df_info}\n",
    "\n",
    "        生成要求：\n",
    "        讀取CSV數據集，並存入DataFrame後，使用要執行的操作後，將修改後的DataFrame存入'tmp.csv'，撰寫完整python code.\n",
    "        切忌每個操作參數都需要使用\n",
    "\n",
    "        輸出格式：\n",
    "        ```python\n",
    "        # 你的程式碼\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return self.lm.basic_request(prompt)\n",
    "\n",
    "    def safe_execute(self, code, df):\n",
    "        try:\n",
    "            code_block = re.search(r'```python\\n(.*?)\\n```', code, re.DOTALL)\n",
    "            if code_block:\n",
    "                code = code_block.group(1)\n",
    "\n",
    "            # 寫入暫存 CSV 檔案作為模擬 df.csv 路徑\n",
    "            df.to_csv(\"input_tmp.csv\", index=False)\n",
    "\n",
    "            # 建立安全執行環境\n",
    "            exec_globals = {'pd': pd}\n",
    "            exec_locals = {}\n",
    "\n",
    "            # 執行生成的程式碼\n",
    "            exec(code, exec_globals, exec_locals)\n",
    "\n",
    "            # 從 tmp.csv 讀取處理後的結果\n",
    "            result_df = pd.read_csv(\"tmp.csv\")\n",
    "            return result_df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"執行錯誤: {str(e)}\")\n",
    "            return df\n",
    "\n",
    "\n",
    "\n",
    "# 初始化\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "operator = DataFrameOperator(API_KEY)\n",
    "\n",
    "# 獲取資料資訊\n",
    "df_info = df.info()\n",
    "df_path = \"filtered_set1.csv\"\n",
    "operation_def = elements[0]\n",
    "#print(operation)\n",
    "\n",
    "generated_code = operator.generate_code(\n",
    "    operation=operation_def,\n",
    "    df_info=df_info,\n",
    "    df_path=df_path\n",
    ")\n",
    "\n",
    "print(\"生成的程式碼：\")\n",
    "print(generated_code)\n",
    "\n",
    "# 執行操作\n",
    "processed_df = operator.safe_execute(generated_code, df)\n",
    "\n",
    "print(\"\\n處理結果：\")\n",
    "print(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e320f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n",
      "1\n",
      "5\n",
      "- Node(1)\n",
      "  - Node(2)\n",
      "    - Node(3)\n",
      "    - Node(4)\n",
      "      - Node(5)\n",
      "      - Node(6)\n",
      "        - Node(7)\n",
      "      - Node(8)\n",
      "      - Node(9)\n",
      "      - Node(10)\n",
      "        - Node(11)\n",
      "        - Node(12)\n",
      "        - Node(13)\n",
      "        - Node(14)\n",
      "        - Node(15)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "        self.level = Level\n",
    "        self.text = text\n",
    "        self.table = table\n",
    "        self.\n",
    "    def __repr__(self):\n",
    "        return f\"TreeNode({self.value})\"\n",
    "\n",
    "def build_random_tree(current_depth=1, max_depth=5, max_degree=5, value_counter=[0]):\n",
    "    value_counter[0] += 1\n",
    "    node = TreeNode(value_counter[0])\n",
    "\n",
    "    if current_depth >= max_depth or random.random() < 0.3:\n",
    "        return node  # 葉節點\n",
    "\n",
    "    degree = random.randint(1, max_degree)\n",
    "    print(degree)\n",
    "    for _ in range(degree):\n",
    "        child = build_random_tree(current_depth + 1, max_depth, max_degree, value_counter)\n",
    "        node.children.append(child)\n",
    "\n",
    "    return node\n",
    "\n",
    "def print_tree(node, level=0):\n",
    "    print(\"  \" * level + f\"- Node({node.value})\")\n",
    "    for child in node.children:\n",
    "        print_tree(child, level + 1)\n",
    "\n",
    "# 建立並印出隨機樹\n",
    "random.seed(42)  # 可重現性\n",
    "root = build_random_tree()\n",
    "print_tree(root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49301e",
   "metadata": {},
   "source": [
    "# STEP final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c0409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree-of-Report for Data Analysis\n",
      "==================================================\n",
      "正在載入數據...\n",
      "成功載入CSV: 315 行, 9 列\n",
      "最大深度: 3\n",
      "最大分支度: 3\n",
      "載入操作池: ['write', 'select_row', 'select_column', 'group_by', 'aggregate', 'value_counts', 'crosstab', 'pivot_table', 'sort', 'calculate']\n",
      "\n",
      "開始建構報告樹...\n",
      "\n",
      "處理節點 - Level: 0, Operation: root(None)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['select_column(roundscore_A, roundscore_B)', 'value_counts(roundscore_A)', 'value_counts(roundscore_B)']\n",
      "創建數據操作節點: select_column(roundscore_A, roundscore_B), 結果形狀: (315, 2)\n",
      "創建數據操作節點: value_counts(roundscore_A), 結果形狀: (315, 9)\n",
      "創建數據操作節點: value_counts(roundscore_B), 結果形狀: (16, 2)\n",
      "\n",
      "處理節點 - Level: 1, Operation: select_column(roundscore_A, roundscore_B)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['value_counts(roundscore_A)', 'value_counts(roundscore_B)']\n",
      "已成功將修改後的 DataFrame 儲存到 'tmp.csv'\n",
      "創建數據操作節點: value_counts(roundscore_A), 結果形狀: (21, 2)\n",
      "成功將 value_counts 結果儲存到 'tmp.csv'\n",
      "創建數據操作節點: value_counts(roundscore_B), 結果形狀: (16, 2)\n",
      "\n",
      "處理節點 - Level: 1, Operation: value_counts(roundscore_A)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['value_counts(roundscore_B)', 'calculate(time)']\n",
      "創建數據操作節點: value_counts(roundscore_B), 結果形狀: (16, 2)\n",
      "創建數據操作節點: calculate(time), 結果形狀: (315, 9)\n",
      "\n",
      "處理節點 - Level: 1, Operation: value_counts(roundscore_B)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['aggregate(count, roundscore_B)', 'sort(count)', 'write()']\n",
      "創建數據操作節點: aggregate(count, roundscore_B), 結果形狀: (16, 2)\n",
      "創建數據操作節點: sort(count), 結果形狀: (16, 2)\n",
      "創建 write 節點: write()\n",
      "\n",
      "處理節點 - Level: 2, Operation: value_counts(roundscore_A)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['value_counts(roundscore_A)', 'write()']\n",
      "創建數據操作節點: value_counts(roundscore_A), 結果形狀: (21, 2)\n",
      "Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 21\n",
      "}\n",
      "]\n",
      "已達配額限制，等待 30 秒後重試 (1/3)...\n",
      "Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 51\n",
      "}\n",
      "]\n",
      "已達配額限制，等待 30 秒後重試 (2/3)...\n",
      "創建 write 節點: write()\n",
      "\n",
      "處理節點 - Level: 2, Operation: value_counts(roundscore_B)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['value_counts(roundscore_B)', 'write()']\n",
      "創建數據操作節點: value_counts(roundscore_B), 結果形狀: (16, 2)\n",
      "創建 write 節點: write()\n",
      "\n",
      "處理節點 - Level: 2, Operation: value_counts(roundscore_B)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['write()']\n",
      "創建 write 節點: write()\n",
      "\n",
      "處理節點 - Level: 2, Operation: calculate(time)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['value_counts(type)', 'value_counts(lose_reason)']\n",
      "創建數據操作節點: value_counts(type), 結果形狀: (18, 2)\n",
      "創建數據操作節點: value_counts(lose_reason), 結果形狀: (4, 2)\n",
      "\n",
      "處理節點 - Level: 2, Operation: aggregate(count, roundscore_B)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: ['write()']\n",
      "創建 write 節點: write()\n",
      "\n",
      "處理節點 - Level: 2, Operation: sort(count)\n",
      "正在向Gemini發送請求...\n",
      "成功獲得Gemini回應\n",
      "生成操作: [\"'write'\"]\n",
      "創建數據操作節點: 'write', 結果形狀: (16, 2)\n",
      "創建 write 節點: write()\n",
      "創建 write 節點: write()\n",
      "創建 write 節點: write()\n",
      "Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 3\n",
      "}\n",
      "]\n",
      "已達配額限制，等待 30 秒後重試 (1/3)...\n",
      "創建 write 節點: write()\n",
      "創建 write 節點: write()\n",
      "Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "已達配額限制，等待 30 秒後重試 (1/3)...\n",
      "\n",
      "生成最終報告...\n",
      "\n",
      "==================================================\n",
      "TREE-OF-REPORT 最終報告\n",
      "==================================================\n",
      "## 賽事數據深度分析：精準洞察，勝負關鍵盡在掌握\n",
      "\n",
      "**起：緒論 - 數據揭示的潛在優勢與隱憂**\n",
      "\n",
      "本次賽事數據分析旨在透過量化選手表現、解析得分模式及失誤原因，從而挖掘潛在的戰術優勢與技術短板。透過對Player A和Player B的得分分布、擊球種類偏好以及失分環節的深入剖析，我們期望能為後續的訓練及戰術制定提供更精準的數據支持，進而提升整體競技水平。本次分析不僅關注表面上的得分，更著重於得分背後的原因，例如不同擊球種類的效率、對手失誤的比重等，力求揭示更深層次的比賽邏輯。\n",
      "\n",
      "**承：Player A與Player B得分模式對比 - 分布差異與穩定性考量**\n",
      "\n",
      "從數據來看，Player A的得分分佈呈現明顯的離散型特徵，其中13分這個分數出現的頻率極高，達52次。這意味著Player A可能在特定的戰術或技術環節上表現突出，能穩定取得13分。然而，其他分數出現的頻率則較低，例如甚至有1分和2分的極低分出現。這種情況暗示Player A在穩定性方面可能存在問題，比賽狀態容易受到波動影響，需要進一步分析造成這種波動的原因，例如是否與對手戰術、自身體能狀態、或特定技術環節的失誤有關。\n",
      "\n",
      "Player B的得分分佈則相對集中，6分、10分、9分是其得分高峰，分別出現了59次、42次和40次。6分的頻率最高，顯示Player B在取得6分方面具有相當的穩定性。這種相對集中的得分分佈可能代表Player B的戰術執行更為穩健，或更擅長在特定的比分範圍內控制節奏。但同時也需要警惕，這種穩定性是否意味著缺乏變化，容易被對手掌握規律。\n",
      "\n",
      "**轉：擊球種類與失分分析 - 戰術偏好與弱點暴露**\n",
      "\n",
      "在擊球種類方面，長球（55次）的使用頻率最高，其次是殺球（36次）和挑球（35次）。這反映了本次比賽中，長球在戰術運用中的重要性，可能是作為控制節奏、尋找進攻機會或防守反擊的手段。殺球和挑球的次數相近，說明選手在進攻和防守之間相對均衡。然而，僅僅統計次數並不能說明效率，需要進一步分析不同擊球種類的成功率，以及它們與得分之間的關聯，例如，殺球的成功率是否高於挑球？長球是否更多用於過渡還是直接得分？\n",
      "\n",
      "失分方面，對手直接得分12次，因球出界失分12次。這兩項數據都需要引起重視。對手直接得分可能源於防守漏洞、反應遲緩或判斷失誤，需要針對性地加強防守訓練，提升反應速度和判斷能力。球出界失分則可能與發力控制、擊球角度或場地適應性有關，需要加強對球的控制力，以及對不同場地的適應能力。\n",
      "\n",
      "**合：總結與建議 - 持續優化，提升競技實力**\n",
      "\n",
      "綜上所述，本次賽事數據分析揭示了Player A和Player B在得分模式、擊球種類及失分環節上的差異。Player A的得分分佈較為分散，穩定性需提升；Player B則更為集中，可能存在戰術變化不足的隱憂。長球在戰術運用中扮演重要角色，而失分主要源於對手直接得分和球出界。\n",
      "\n",
      "基於以上分析，我們提出以下建議：\n",
      "\n",
      "*   **針對Player A：** 加強穩定性訓練，分析13分高頻次出現的原因，並將其成功經驗複製到其他得分環節；同時，分析低分出現的原因，針對性地進行改進。\n",
      "*   **針對Player B：** 在保持穩定性的前提下，增加戰術變化，避免被對手掌握規律；同時，分析6分高頻次出現的原因，並思考如何利用其優勢來創造更多得分機會。\n",
      "*   **針對共同問題：** 加強防守訓練，提升反應速度和判斷能力；強化對球的控制力，降低球出界失分率；分析不同擊球種類的成功率，並據此調整戰術策略。\n",
      "\n",
      "總而言之，數據分析是提升競技實力的重要手段。透過持續的數據收集、分析和反饋，我們可以更全面地了解自身優劣勢，並據此制定更精準的訓練計劃和戰術策略，從而在未來的比賽中取得更好的成績。\n",
      "報告已儲存至 tree_of_report.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import dspy\n",
    "import ast\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional\n",
    "import copy\n",
    "\n",
    "# ===== 基於參考程式碼的函數 =====\n",
    "def read_text_file(file_path):\n",
    "    \"\"\"讀取文本文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"No file available\"\n",
    "    except Exception as e:\n",
    "        print(f\"讀取文件錯誤: {e}\")\n",
    "        return \"Error reading file\"\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"讀取JSON文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # 返回默認操作集合\n",
    "        return [\n",
    "            {\"name\": \"select_column\", \"description\": \"選擇特定欄位\"},\n",
    "            {\"name\": \"value_counts\", \"description\": \"計算值的頻次\"},\n",
    "            {\"name\": \"groupby\", \"description\": \"按欄位分組\"},\n",
    "            {\"name\": \"sort_values\", \"description\": \"排序數據\"},\n",
    "            {\"name\": \"filter_rows\", \"description\": \"過濾行數據\"},\n",
    "            {\"name\": \"write\", \"description\": \"撰寫分析文本\"}\n",
    "        ]\n",
    "\n",
    "# ===== 樹節點類別 =====\n",
    "class TreeNode:\n",
    "    \"\"\"樹節點類別，包含 children, level, text, table 屬性\"\"\"\n",
    "    def __init__(self, level: int = 0, text: str = \"\", table: pd.DataFrame = None, operation: str = None):\n",
    "        self.children: List['TreeNode'] = []\n",
    "        self.level: int = level\n",
    "        self.text: str = text\n",
    "        self.table: pd.DataFrame = table if table is not None else pd.DataFrame()\n",
    "        self.operation: str = operation\n",
    "        self.parent: Optional['TreeNode'] = None\n",
    "        self.operation_history: List[str] = []\n",
    "    \n",
    "    def add_child(self, child: 'TreeNode'):\n",
    "        \"\"\"添加子節點\"\"\"\n",
    "        child.parent = self\n",
    "        self.children.append(child)\n",
    "    \n",
    "    def is_leaf(self) -> bool:\n",
    "        \"\"\"判斷是否為葉節點\"\"\"\n",
    "        return len(self.children) == 0\n",
    "\n",
    "# ===== 基於參考程式碼的 ContentPlanner =====\n",
    "class ContentPlanner:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        \n",
    "    def generate_operations(self, tables, table_description, operation_description, \n",
    "                          operation_history, operation_pool, max_depth=5, max_degree=3, outline_path='main.txt'):\n",
    "        \"\"\"\n",
    "        使用Gemini生成operations和arguments\n",
    "        \"\"\"\n",
    "        \n",
    "        # 構建完整的提示詞\n",
    "        prompt = f\"\"\"System : You are a content planner for the report. Please follow the outline. Please select candidate Operations and corresponding Arguments from the Operation Pool based on the input Tables and Operation History. These candidate Operations will be the next Operation in the Operation History .\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in English .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The length of Operation History must be less than or equal to {max_depth}.\n",
    "5. The number of Operations must be less than or equal to {max_degree}.\n",
    "6. Only select Opertions from the Operation Pool .\n",
    "7. Arguments must match the format required by the corresponding Operations .\n",
    "8. Operations & Arguments must follow this format : [ operation_1 ( argument_1 , ...) , operation_2 ( argument_2 , ...) , operation_3 ( argument_3 , ...) , ...]\n",
    "9. Only output Operations & Arguments !\n",
    "10. If Table is big or Level is low, it should be more Operations include select_col or select_row not write.\n",
    "11. If the length of Operation History is short, then more operations or more arguments.\n",
    "12. Write operations do not need argument.\n",
    "\n",
    "#outline\n",
    "{read_text_file(outline_path) if os.path.exists(outline_path) else \"Generate comprehensive data analysis\"}\n",
    "\n",
    "# Table Description\n",
    "{table_description}\n",
    "\n",
    "# Operation Description\n",
    "{json.dumps(operation_description, indent=2, ensure_ascii=False)}\n",
    "\n",
    "User : # Test\n",
    "## Tables\n",
    "{tables}\n",
    "\n",
    "## Operation History\n",
    "{operation_history}\n",
    "\n",
    "## Operation Pool\n",
    "{operation_pool}\n",
    "\n",
    "## Operations & Arguments\"\"\"\n",
    "\n",
    "        try:\n",
    "            print(\"正在向Gemini發送請求...\")\n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            if response.text:\n",
    "                print(\"成功獲得Gemini回應\")\n",
    "                return self.parse_operations(response.text.strip())\n",
    "            else:\n",
    "                print(\"Gemini回應為空\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Gemini API請求失敗: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def parse_operations(self, response_text):\n",
    "        \"\"\"解析 Gemini 回應的操作列表\"\"\"\n",
    "        try:\n",
    "            # 尋找方括號內的內容\n",
    "            bracket_match = re.search(r'\\[(.*?)\\]', response_text, re.DOTALL)\n",
    "            if bracket_match:\n",
    "                operations_str = bracket_match.group(1)\n",
    "                # 分割操作\n",
    "                operations = []\n",
    "                # 使用正則表達式分割操作\n",
    "                op_pattern = r'([a-zA-Z_]+\\([^)]*\\))'\n",
    "                matches = re.findall(op_pattern, operations_str)\n",
    "                if matches:\n",
    "                    return matches\n",
    "                else:\n",
    "                    # 如果沒有匹配，嘗試簡單分割\n",
    "                    ops = [op.strip().strip(',') for op in operations_str.split(',')]\n",
    "                    return [op for op in ops if op and op != '']\n",
    "            else:\n",
    "                # 如果沒有方括號，按行分割\n",
    "                lines = response_text.split('\\n')\n",
    "                operations = []\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if line and not line.startswith('#') and not line.startswith('System'):\n",
    "                        operations.append(line)\n",
    "                return operations\n",
    "        except Exception as e:\n",
    "            print(f\"解析操作失敗: {e}\")\n",
    "            return []\n",
    "\n",
    "# ===== 基於參考程式碼的 Gemini 和 DataFrameOperator =====\n",
    "class Gemini(dspy.LM):\n",
    "    def __init__(self, api_key, model_name=\"gemini-2.0-flash\"):\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        genai.configure(api_key=api_key)\n",
    "        self._model_instance = genai.GenerativeModel(model_name)\n",
    "        super().__init__(model=model_name)\n",
    "\n",
    "    def __call__(self, messages=None, **kwargs):\n",
    "        if messages is None:\n",
    "            raise ValueError(\"Missing 'messages' argument\")\n",
    "        if isinstance(messages, list):\n",
    "            prompt_text = \"\".join([msg.get('content', '') for msg in messages])\n",
    "        else:\n",
    "            prompt_text = str(messages)\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt_text)\n",
    "            if not response.text:\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return [{'text': response.text, 'logprobs': None}]\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return [{'text': \"⚠️ Gemini API 回應失敗\", 'logprobs': None}]\n",
    "\n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        try:\n",
    "            response = self._model_instance.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error from Gemini model: {e}\")\n",
    "            return \"⚠️ 無法取得 Gemini 回應\"\n",
    "\n",
    "def setup_gemini_api(api_key):\n",
    "    lm = Gemini(api_key=api_key)\n",
    "    dspy.settings.configure(lm=lm)\n",
    "    return lm\n",
    "\n",
    "class DataFrameOperator:\n",
    "    def __init__(self, api_key):\n",
    "        self.lm = setup_gemini_api(api_key)\n",
    "\n",
    "    def generate_code(self, operation, df_info, df_path=\"input_tmp.csv\"):\n",
    "        prompt = f\"\"\"\n",
    "        你是一個專業的Python資料分析助手。欄位名稱以資料欄位類型提供為主，根據以下要求生成操作DataFrame的程式碼：\n",
    "\n",
    "        要執行的操作: {operation}\n",
    "\n",
    "        CSV數據集: {df_path}\n",
    "\n",
    "        資料欄位類型:\n",
    "        {df_info}\n",
    "\n",
    "        生成要求：\n",
    "        讀取CSV數據集，並存入DataFrame後，使用要執行的操作後，將修改後的DataFrame存入'tmp.csv'，撰寫完整python code.\n",
    "        切忌每個操作參數都需要使用\n",
    "\n",
    "        輸出格式：\n",
    "        ```python\n",
    "        # 你的程式碼\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return self.lm.basic_request(prompt)\n",
    "\n",
    "    def safe_execute(self, code, df):\n",
    "        try:\n",
    "            code_block = re.search(r'```python\\n(.*?)\\n```', code, re.DOTALL)\n",
    "            if code_block:\n",
    "                code = code_block.group(1)\n",
    "\n",
    "            # 寫入暫存 CSV 檔案作為模擬 df.csv 路徑\n",
    "            df.to_csv(\"input_tmp.csv\", index=False)\n",
    "\n",
    "            # 建立安全執行環境\n",
    "            exec_globals = {'pd': pd}\n",
    "            exec_locals = {}\n",
    "\n",
    "            # 執行生成的程式碼\n",
    "            exec(code, exec_globals, exec_locals)\n",
    "\n",
    "            # 從 tmp.csv 讀取處理後的結果\n",
    "            if os.path.exists(\"tmp.csv\"):\n",
    "                result_df = pd.read_csv(\"tmp.csv\")\n",
    "                return result_df\n",
    "            else:\n",
    "                return df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"執行錯誤: {str(e)}\")\n",
    "            return df\n",
    "\n",
    "# ===== 文本生成器 =====\n",
    "# 修改 TextGenerator 類別：初始化時接收 table_description\n",
    "import time  # 確保導入 time 模組\n",
    "\n",
    "class TextGenerator:\n",
    "    def __init__(self, api_key, table_description=\"\"):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.table_description = table_description\n",
    "\n",
    "    def _retry_generate(self, prompt, max_retries=3, delay_seconds=30):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(prompt)\n",
    "                if response.text:\n",
    "                    return response.text.strip()\n",
    "            except Exception as e:\n",
    "                err = str(e)\n",
    "                print(f\"Gemini 回應失敗: {err}\")\n",
    "                if \"429\" in err:\n",
    "                    print(f\"已達配額限制，等待 {delay_seconds} 秒後重試 ({attempt+1}/{max_retries})...\")\n",
    "                    time.sleep(delay_seconds)\n",
    "                else:\n",
    "                    break\n",
    "        return \"⚠️ 寫作請求失敗：API 限制或其他錯誤\"\n",
    "\n",
    "    def generate_text_for_write_operation(self, table: pd.DataFrame, operation_history: List[str]) -> str:\n",
    "        table_str = table.head(10).to_string() if len(table) > 10 else table.to_string()\n",
    "        WRITE_TOKENS = 50\n",
    "        TABLE_FORMAT = \"Pandas DataFrame as plain text\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "    System :\n",
    "    You are a content writer for the badminton game report .\n",
    "    Please write the Report based on the input Table .\n",
    "\n",
    "    # Requirements\n",
    "    1. Strictly adhere to the requirements .\n",
    "    2. The output must be in English .\n",
    "    3. The output must be based on the input data ; do not hallucinate .\n",
    "    4. The Table format is {TABLE_FORMAT}.\n",
    "    5. The Report can only describe the content included in the Tables and cannot describe anything not included in the Tables .\n",
    "    6. The Report must consist of only one paragraph .\n",
    "    7. The number of tokens in the Report must be within {WRITE_TOKENS}.\n",
    "\n",
    "    # Table Description\n",
    "    {self.table_description}\n",
    "\n",
    "    User :\n",
    "    # Test\n",
    "    ## Tables\n",
    "    {table_str}\n",
    "    ## Report\n",
    "    \"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "    def merge_child_texts(self, child_texts: List[str], parent_operation: str) -> str:\n",
    "        if not child_texts:\n",
    "            return \"\"\n",
    "\n",
    "        GENERATING_TOKENS = 100\n",
    "        reports_str = \"\\n\".join([f\"- {txt}\" for txt in child_texts])\n",
    "        prompt = f\"\"\"\n",
    "    System :\n",
    "    You are a content generator for the badminton game report .\n",
    "    Please merge and rewrite a New Report based on the input Reports .\n",
    "\n",
    "    # Requirements\n",
    "    1. Strictly adhere to the requirements .\n",
    "    2. The output must be in English .\n",
    "    3. The output must be based on the input data ; do not hallucinate .\n",
    "    4. The New Report must include all the content from the input Reports ; do not omit any information .\n",
    "    5. The New Report must follow the order of the input Reports .\n",
    "    6. The number of tokens in the New Report must be within {GENERATING_TOKENS}.\n",
    "\n",
    "    User :\n",
    "    # Test\n",
    "    ## Reports\n",
    "    {reports_str}\n",
    "    ## New Report\n",
    "    \"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "# 修改 TreeOfReport 類別中 TextGenerator 的初始化邏輯\n",
    "class TreeOfReport:\n",
    "    def __init__(self, api_key: str, max_depth: int = 5, max_degree: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.max_depth = max_depth\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "        # 載入配置檔案\n",
    "        self.load_configurations()\n",
    "\n",
    "        # 初始化組件，注意 TextGenerator 傳入 table_description\n",
    "        self.content_planner = ContentPlanner(api_key)\n",
    "        self.df_operator = DataFrameOperator(api_key)\n",
    "        self.text_generator = TextGenerator(api_key, table_description=self.table_description)\n",
    "\n",
    "    def load_configurations(self):\n",
    "        self.table_description = read_text_file(\"filtered_data_description.txt\")\n",
    "        if not self.table_description or self.table_description == \"No file available\":\n",
    "            self.table_description = \"數據分析表格，包含各種欄位用於分析\"\n",
    "\n",
    "        self.operation_description = read_json_file(\"selected_operations.json\")\n",
    "        if isinstance(self.operation_description, list):\n",
    "            self.operation_pool = [op['name'] for op in self.operation_description]\n",
    "        else:\n",
    "            self.operation_pool = list(self.operation_description.keys())\n",
    "\n",
    "        print(f\"載入操作池: {self.operation_pool}\")\n",
    "\n",
    "    \n",
    "    def build_tree(self, root_table: pd.DataFrame) -> TreeNode:\n",
    "        \"\"\"建構報告樹\"\"\"\n",
    "        root = TreeNode(level=0, text=\"資料分析報告\", table=root_table, operation=\"root(None)\")\n",
    "        root.operation_history = ['root(None)']\n",
    "        queue = [root]\n",
    "\n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "\n",
    "            if current_node.operation.lower().startswith('write'):\n",
    "                continue\n",
    "\n",
    "            if current_node.level >= self.max_depth:\n",
    "                write_node = self.create_child_node(current_node, 'write()')\n",
    "                if write_node:\n",
    "                    current_node.add_child(write_node)\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n處理節點 - Level: {current_node.level}, Operation: {current_node.operation}\")\n",
    "\n",
    "            tables_str = current_node.table.to_string()\n",
    "            operations = self.content_planner.generate_operations(\n",
    "                tables=tables_str,\n",
    "                table_description=self.table_description,\n",
    "                operation_description=self.operation_description,\n",
    "                operation_history=current_node.operation_history,\n",
    "                operation_pool=self.operation_pool,\n",
    "                max_depth=self.max_depth,\n",
    "                max_degree=self.max_degree\n",
    "            )\n",
    "\n",
    "            print(f\"生成操作: {operations}\")\n",
    "\n",
    "            for operation in operations[:self.max_degree]:\n",
    "                if operation.strip():\n",
    "                    child_node = self.create_child_node(current_node, operation)\n",
    "                    if child_node:\n",
    "                        current_node.add_child(child_node)\n",
    "                        queue.append(child_node)\n",
    "\n",
    "        self.generate_all_texts(root)\n",
    "        return root\n",
    "    \n",
    "    def create_child_node(self, parent: TreeNode, operation: str) -> Optional[TreeNode]:\n",
    "        \"\"\"創建子節點\"\"\"\n",
    "        try:\n",
    "            # 建立新的操作歷史\n",
    "            new_operation_history = parent.operation_history + [operation]\n",
    "            \n",
    "            # 檢查是否為 write 操作\n",
    "            if operation.lower().startswith('write'):\n",
    "                # Write 操作：生成文本，表格保持不變\n",
    "                text = self.text_generator.generate_text_for_write_operation(\n",
    "                    parent.table,\n",
    "                    new_operation_history\n",
    "                )\n",
    "                child = TreeNode(\n",
    "                    level=parent.level + 1,\n",
    "                    text=text,\n",
    "                    table=parent.table.copy(),\n",
    "                    operation=operation\n",
    "                )\n",
    "                child.operation_history = new_operation_history\n",
    "                print(f\"創建 write 節點: {operation}\")\n",
    "                return child\n",
    "            else:\n",
    "                # 其他操作：執行數據操作\n",
    "                df_info = f\"Shape: {parent.table.shape}\\nColumns: {list(parent.table.columns)}\\nData types:\\n{parent.table.dtypes.to_string()}\"\n",
    "                code = self.df_operator.generate_code(operation, df_info)\n",
    "                \n",
    "                if code:\n",
    "                    result_df = self.df_operator.safe_execute(code, parent.table)\n",
    "                    child = TreeNode(\n",
    "                        level=parent.level + 1,\n",
    "                        text=\"\",\n",
    "                        table=result_df,\n",
    "                        operation=operation\n",
    "                    )\n",
    "                    child.operation_history = new_operation_history\n",
    "                    print(f\"創建數據操作節點: {operation}, 結果形狀: {result_df.shape}\")\n",
    "                    return child\n",
    "                else:\n",
    "                    print(f\"無法生成操作代碼: {operation}\")\n",
    "                    return None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"創建子節點失敗: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_all_texts(self, node: TreeNode):\n",
    "        \"\"\"遞歸生成所有節點的文本\"\"\"\n",
    "        # 先處理子節點\n",
    "        for child in node.children:\n",
    "            self.generate_all_texts(child)\n",
    "        \n",
    "        # 如果是葉節點且沒有文本（非 write 操作）\n",
    "        if node.is_leaf() and not node.text and node.operation and not node.operation.lower().startswith('write'):\n",
    "            node.text = self.text_generator.generate_text_for_write_operation(\n",
    "                node.table, \n",
    "                node.operation_history\n",
    "            )\n",
    "        # 如果有子節點，合併子節點的文本\n",
    "        elif node.children:\n",
    "            child_texts = [child.text for child in node.children if child.text.strip()]\n",
    "            if child_texts:\n",
    "                merged_text = self.text_generator.merge_child_texts(\n",
    "                    child_texts, \n",
    "                    node.operation or \"root\"\n",
    "                )\n",
    "                if node.text:\n",
    "                    node.text = node.text + \"\\n\\n\" + merged_text\n",
    "                else:\n",
    "                    node.text = merged_text\n",
    "        print(f'節點資訊: {node.text}')\n",
    "        \n",
    "    def generate_report(self, node: TreeNode, level: int = 0) -> str:\n",
    "            if node.level == 0:\n",
    "                prompt = f\"\"\"\n",
    "                根據以下分析總結，請撰寫一篇賽事數據分析報導，包含：起、承、轉、合，提供全面深入的分析。\n",
    "                請用繁體中文撰寫，保持邏輯清晰，資訊準確。\n",
    "\n",
    "                分析總結:\n",
    "                {node.text}\n",
    "                \"\"\"\n",
    "                final_text = self.text_generator._retry_generate(prompt)\n",
    "                with open(\"tree_of_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(final_text)\n",
    "                return final_text\n",
    "            else:\n",
    "                print(f'generate report from not root')\n",
    "                indent = \"  \" * level\n",
    "                report = f\"{indent}{'#' * (level + 1)} {node.operation or 'Root'}\\n\\n\"\n",
    "\n",
    "                if node.text:\n",
    "                    report += f\"{indent}{node.text}\\n\\n\"\n",
    "\n",
    "                if node.table is not None and not node.table.empty and level < 2:\n",
    "                    report += f\"{indent}**資料摘要:** Shape {node.table.shape}\\n\"\n",
    "                    if len(node.table) <= 10:\n",
    "                        report += f\"{indent}```\\n{node.table.to_string()}\\n{indent}```\\n\\n\"\n",
    "                    else:\n",
    "                        report += f\"{indent}```\\n{node.table.head().to_string()}\\n{indent}```\\n\\n\"\n",
    "\n",
    "                for child in node.children:\n",
    "                    report += self.generate_report(child, level + 1)\n",
    "\n",
    "                return report\n",
    "\n",
    "\n",
    "\n",
    "# ===== 主程序 =====\n",
    "def main():\n",
    "    \"\"\"主函數 - 基於參考程式碼結構\"\"\"\n",
    "    \n",
    "    # 設置API密鑰\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"請設置 GOOGLE_API_KEY 環境變數\")\n",
    "        return\n",
    "    \n",
    "    print(\"Tree-of-Report for Data Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"正在載入數據...\")\n",
    "    \n",
    "    # 讀取CSV檔案\n",
    "    try:\n",
    "        TABLES = pd.read_csv('filtered_set1.csv')\n",
    "        print(f\"成功載入CSV: {TABLES.shape[0]} 行, {TABLES.shape[1]} 列\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"找不到 filtered_set1.csv，使用示例數據\")\n",
    "        # 創建示例數據\n",
    "        TABLES = pd.DataFrame({\n",
    "            'type': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B'],\n",
    "            'lose_reason': ['net', 'out', 'net', 'long', 'net', 'out', 'long', 'net'],\n",
    "            'getpoint_player': ['Player1', 'Player2', 'Player1', 'Player2', 'Player1', 'Player2', 'Player1', 'Player2'],\n",
    "            'score': [1, 2, 1, 3, 2, 1, 4, 2]\n",
    "        })\n",
    "    \n",
    "    # 設置參數\n",
    "    MAX_DEPTH = 3  # 降低深度以便測試\n",
    "    MAX_DEGREE = 3  # 降低分支度以便測試\n",
    "    \n",
    "    print(f\"最大深度: {MAX_DEPTH}\")\n",
    "    print(f\"最大分支度: {MAX_DEGREE}\")\n",
    "    \n",
    "    # 初始化 Tree-of-Report\n",
    "    tree_report = TreeOfReport(api_key, max_depth=MAX_DEPTH, max_degree=MAX_DEGREE)\n",
    "    \n",
    "    # 建構報告樹\n",
    "    print(\"\\n開始建構報告樹...\")\n",
    "    root = tree_report.build_tree(TABLES)\n",
    "    \n",
    "    # 生成最終報告\n",
    "    print(\"\\n生成最終報告...\")\n",
    "    final_report = tree_report.generate_report(root)\n",
    "    \n",
    "    # 輸出報告\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TREE-OF-REPORT 最終報告\")\n",
    "    print(\"=\"*50)\n",
    "    print(final_report)\n",
    "    \n",
    "    # 儲存報告\n",
    "    with open('tree_of_report.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# Tree-of-Report 數據分析報告\\n\\n\")\n",
    "        f.write(final_report)\n",
    "    \n",
    "    print(\"報告已儲存至 tree_of_report.md\")\n",
    "    \n",
    "    # 清理暫存檔案\n",
    "    for temp_file in ['input_tmp.csv', 'tmp.csv']:\n",
    "        if os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e90ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:11,808 - INFO - Tree-of-Report for Data Analysis (改進版)\n",
      "2025-06-06 11:24:11,809 - INFO - ==================================================\n",
      "2025-06-06 11:24:11,809 - INFO - 正在載入數據...\n",
      "2025-06-06 11:24:11,812 - INFO - 成功載入CSV: 315 行, 9 列\n",
      "2025-06-06 11:24:11,812 - INFO - 最大深度: 3\n",
      "2025-06-06 11:24:11,812 - INFO - 最大分支度: 4\n",
      "2025-06-06 11:24:11,814 - INFO - 載入操作池: ['write', 'select_row', 'select_column', 'group_by', 'aggregate', 'value_counts', 'crosstab', 'pivot_table', 'sort', 'calculate']\n",
      "2025-06-06 11:24:11,815 - INFO - 開始建構報告樹...\n",
      "2025-06-06 11:24:11,815 - INFO - 處理節點 - Level: 0, Operation: root(None)\n",
      "2025-06-06 11:24:11,822 - INFO - 正在向Gemini發送請求...\n",
      "2025-06-06 11:24:13,400 - INFO - 成功獲得Gemini回應\n",
      "2025-06-06 11:24:13,400 - INFO - 生成操作: ['select_column(player,type,lose_reason,getpoint_player)', 'value_counts(type)', 'value_counts(lose_reason)', 'value_counts(getpoint_player)']\n",
      "2025-06-06 11:24:16,452 - INFO - 操作成功，結果形狀: (315, 4)\n",
      "2025-06-06 11:24:16,453 - INFO - 創建數據操作節點: select_column(player,type,lose_reason,getpoint_player), 結果形狀: (315, 4)\n",
      "2025-06-06 11:24:16,454 - INFO - 添加子節點: 68962585 to a46eb399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame已成功保存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:18,701 - INFO - 操作成功，結果形狀: (18, 2)\n",
      "2025-06-06 11:24:18,702 - INFO - 創建數據操作節點: value_counts(type), 結果形狀: (18, 2)\n",
      "2025-06-06 11:24:18,703 - INFO - 添加子節點: 6766c7a8 to a46eb399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts('type') 操作完成，結果已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:20,505 - INFO - 操作成功，結果形狀: (4, 2)\n",
      "2025-06-06 11:24:20,506 - INFO - 創建數據操作節點: value_counts(lose_reason), 結果形狀: (4, 2)\n",
      "2025-06-06 11:24:20,507 - INFO - 添加子節點: 6b604cfd to a46eb399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts 操作已完成，結果已保存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:22,720 - INFO - 操作成功，結果形狀: (2, 2)\n",
      "2025-06-06 11:24:22,720 - INFO - 創建數據操作節點: value_counts(getpoint_player), 結果形狀: (2, 2)\n",
      "2025-06-06 11:24:22,720 - INFO - 添加子節點: ad3b8632 to a46eb399\n",
      "2025-06-06 11:24:22,721 - INFO - 處理節點 - Level: 1, Operation: select_column(player,type,lose_reason,getpoint_player)\n",
      "2025-06-06 11:24:22,724 - INFO - 正在向Gemini發送請求...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts 操作已成功執行並保存到 'tmp.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:23,745 - INFO - 成功獲得Gemini回應\n",
      "2025-06-06 11:24:23,745 - INFO - 生成操作: ['value_counts(type)', 'value_counts(lose_reason)']\n",
      "2025-06-06 11:24:25,559 - INFO - 操作成功，結果形狀: (18, 2)\n",
      "2025-06-06 11:24:25,561 - INFO - 創建數據操作節點: value_counts(type), 結果形狀: (18, 2)\n",
      "2025-06-06 11:24:25,561 - INFO - 添加子節點: 1a48c3b5 to 68962585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts('type') 操作已完成，结果已保存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:27,829 - INFO - 操作成功，結果形狀: (4, 2)\n",
      "2025-06-06 11:24:27,830 - INFO - 創建數據操作節點: value_counts(lose_reason), 結果形狀: (4, 2)\n",
      "2025-06-06 11:24:27,830 - INFO - 添加子節點: fe370ae8 to 68962585\n",
      "2025-06-06 11:24:27,831 - INFO - 處理節點 - Level: 1, Operation: value_counts(type)\n",
      "2025-06-06 11:24:27,832 - INFO - 正在向Gemini發送請求...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_counts('lose_reason') 操作成功，结果已保存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:28,569 - INFO - 成功獲得Gemini回應\n",
      "2025-06-06 11:24:28,572 - INFO - 生成操作: ['sort(count)']\n",
      "2025-06-06 11:24:30,259 - INFO - 操作成功，結果形狀: (18, 2)\n",
      "2025-06-06 11:24:30,261 - INFO - 創建數據操作節點: sort(count), 結果形狀: (18, 2)\n",
      "2025-06-06 11:24:30,261 - INFO - 添加子節點: d7445d2b to 6766c7a8\n",
      "2025-06-06 11:24:30,261 - INFO - 處理節點 - Level: 1, Operation: value_counts(lose_reason)\n",
      "2025-06-06 11:24:30,263 - INFO - 正在向Gemini發送請求...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame已成功排序並儲存至 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:31,118 - INFO - 成功獲得Gemini回應\n",
      "2025-06-06 11:24:31,118 - INFO - 生成操作: ['select_column(lose_reason, count)', 'sort(count, ascending=False)', 'write()']\n",
      "2025-06-06 11:24:33,906 - INFO - 操作成功，結果形狀: (4, 2)\n",
      "2025-06-06 11:24:33,906 - INFO - 創建數據操作節點: select_column(lose_reason, count), 結果形狀: (4, 2)\n",
      "2025-06-06 11:24:33,908 - INFO - 添加子節點: 496577ff to 6b604cfd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 'input_tmp.csv' and saved the result to 'tmp.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:35,569 - INFO - 操作成功，結果形狀: (4, 2)\n",
      "2025-06-06 11:24:35,569 - INFO - 創建數據操作節點: sort(count, ascending=False), 結果形狀: (4, 2)\n",
      "2025-06-06 11:24:35,570 - INFO - 添加子節點: 50728b8d to 6b604cfd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV檔案已成功讀取、排序並儲存為 'tmp.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:24:36,444 - INFO - 創建 write 節點: write()\n",
      "2025-06-06 11:24:36,445 - INFO - 添加子節點: cdb60d60 to 6b604cfd\n",
      "2025-06-06 11:24:36,446 - INFO - 處理節點 - Level: 1, Operation: value_counts(getpoint_player)\n",
      "2025-06-06 11:24:36,447 - INFO - 正在向Gemini發送請求...\n",
      "2025-06-06 11:24:37,202 - INFO - 成功獲得Gemini回應\n",
      "2025-06-06 11:24:37,204 - INFO - 生成操作: ['write()']\n",
      "2025-06-06 11:24:38,277 - INFO - 創建 write 節點: write()\n",
      "2025-06-06 11:24:38,277 - INFO - 添加子節點: 7711d075 to ad3b8632\n",
      "2025-06-06 11:24:38,278 - INFO - 處理節點 - Level: 2, Operation: value_counts(type)\n",
      "2025-06-06 11:24:38,279 - INFO - 正在向Gemini發送請求...\n",
      "2025-06-06 11:24:38,625 - ERROR - Gemini API請求失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 19\n",
      "}\n",
      "]\n",
      "2025-06-06 11:24:38,625 - INFO - 生成操作: []\n",
      "2025-06-06 11:24:38,625 - INFO - 處理節點 - Level: 2, Operation: value_counts(lose_reason)\n",
      "2025-06-06 11:24:38,627 - INFO - 正在向Gemini發送請求...\n",
      "2025-06-06 11:24:38,896 - ERROR - Gemini API請求失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 19\n",
      "}\n",
      "]\n",
      "2025-06-06 11:24:38,897 - INFO - 生成操作: []\n",
      "2025-06-06 11:24:38,897 - INFO - 處理節點 - Level: 2, Operation: sort(count)\n",
      "2025-06-06 11:24:38,899 - INFO - 正在向Gemini發送請求...\n",
      "2025-06-06 11:24:39,156 - ERROR - Gemini API請求失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "2025-06-06 11:24:39,156 - INFO - 生成操作: []\n",
      "2025-06-06 11:24:39,157 - INFO - 處理節點 - Level: 2, Operation: select_column(lose_reason, count)\n",
      "2025-06-06 11:24:39,158 - INFO - 正在向Gemini發送請求...\n",
      "2025-06-06 11:24:39,669 - ERROR - Gemini API請求失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "2025-06-06 11:24:39,669 - INFO - 生成操作: []\n",
      "2025-06-06 11:24:39,670 - INFO - 處理節點 - Level: 2, Operation: sort(count, ascending=False)\n",
      "2025-06-06 11:24:39,672 - INFO - 正在向Gemini發送請求...\n",
      "2025-06-06 11:24:39,914 - ERROR - Gemini API請求失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "2025-06-06 11:24:39,914 - INFO - 生成操作: []\n",
      "C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\217919585.py:516: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if table[col].nunique() <= 10 or dtype == 'object' or pd.api.types.is_categorical_dtype(table[col]):\n",
      "2025-06-06 11:24:40,188 - ERROR - Gemini 回應失敗: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 17\n",
      "}\n",
      "]\n",
      "2025-06-06 11:24:40,189 - INFO - 已達配額限制，等待 30 秒後重試 (1/3)...\n",
      "2025-06-06 11:25:11,260 - INFO - 節點 1a48c3b5 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node table:      type  count\n",
      "0      長球     55\n",
      "1      殺球     36\n",
      "2      挑球     35\n",
      "3      切球     31\n",
      "4      推球     31\n",
      "5     放小球     28\n",
      "6     擋小球     20\n",
      "7    未知球種     16\n",
      "8      勾球     12\n",
      "9     發長球     10\n",
      "10    發短球     10\n",
      "11  後場抽平球      7\n",
      "12   過度切球      6\n",
      "13   防守回抽      5\n",
      "14     撲球      5\n",
      "15     點扣      4\n",
      "16   防守回挑      2\n",
      "17     平球      2\n",
      "node.table:      type  count\n",
      "0      長球     55\n",
      "1      殺球     36\n",
      "2      挑球     35\n",
      "3      切球     31\n",
      "4      推球     31\n",
      "5     放小球     28\n",
      "6     擋小球     20\n",
      "7    未知球種     16\n",
      "8      勾球     12\n",
      "9     發長球     10\n",
      "10    發短球     10\n",
      "11  後場抽平球      7\n",
      "12   過度切球      6\n",
      "13   防守回抽      5\n",
      "14     撲球      5\n",
      "15     點扣      4\n",
      "16   防守回挑      2\n",
      "17     平球      2\n",
      "節點文本: 場上局勢膠著，雙方你來我往。長球使用次數最多，高達55次，但未知球員得分效率驚人。殺球緊隨其後，有36次，可見進攻端火力十足！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:12,487 - INFO - 節點 fe370ae8 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 比賽中，可見對手落地得分與我方出界是主要失分因素，各佔12分，掛網失誤也不容忽視，丟失10分。減少無謂失誤，是接下來需要重點調整的方向。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:13,750 - INFO - 節點 68962585 文本生成完成\n",
      "C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\217919585.py:516: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if table[col].nunique() <= 10 or dtype == 'object' or pd.api.types.is_categorical_dtype(table[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:     player  type lose_reason getpoint_player\n",
      "0        B   發長球         NaN             NaN\n",
      "1        A    切球         NaN             NaN\n",
      "2        B    挑球         NaN             NaN\n",
      "3        A    長球         NaN             NaN\n",
      "4        B    殺球         NaN             NaN\n",
      "..     ...   ...         ...             ...\n",
      "310      B  未知球種         NaN             NaN\n",
      "311      A    切球         NaN             NaN\n",
      "312      B    挑球         NaN             NaN\n",
      "313      A    長球         NaN             NaN\n",
      "314      B    長球          出界               A\n",
      "\n",
      "[315 rows x 4 columns]\n",
      "節點文本: 球場局勢膠著，雙方互有攻防。長球使用頻率最高，達到55次，未知球員得分效率驚人。殺球次數緊隨其後，共36次，進攻火力強勁。比賽中，對手落地得分與我方出界為主要失分因素，各佔12分，掛網失誤也造成10分丟失。減少不必要的失誤將是未來調整的重點。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:14,787 - INFO - 節點 d7445d2b 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node table:      type  count\n",
      "0      平球      2\n",
      "1    防守回挑      2\n",
      "2      點扣      4\n",
      "3    防守回抽      5\n",
      "4      撲球      5\n",
      "5    過度切球      6\n",
      "6   後場抽平球      7\n",
      "7     發長球     10\n",
      "8     發短球     10\n",
      "9      勾球     12\n",
      "10   未知球種     16\n",
      "11    擋小球     20\n",
      "12    放小球     28\n",
      "13     切球     31\n",
      "14     推球     31\n",
      "15     挑球     35\n",
      "16     殺球     36\n",
      "17     長球     55\n",
      "node.table:      type  count\n",
      "0      平球      2\n",
      "1    防守回挑      2\n",
      "2      點扣      4\n",
      "3    防守回抽      5\n",
      "4      撲球      5\n",
      "5    過度切球      6\n",
      "6   後場抽平球      7\n",
      "7     發長球     10\n",
      "8     發短球     10\n",
      "9      勾球     12\n",
      "10   未知球種     16\n",
      "11    擋小球     20\n",
      "12    放小球     28\n",
      "13     切球     31\n",
      "14     推球     31\n",
      "15     挑球     35\n",
      "16     殺球     36\n",
      "17     長球     55\n",
      "節點文本: 本場比賽雙方在長球的使用上非常頻繁，高達55次，挑球的次數也不少，有35次。另外，切球和推球的次數也旗鼓相當，分別為31次，可見這兩種技術是選手們常用的得分手段。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:15,625 - INFO - 節點 6766c7a8 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:      type  count\n",
      "0      長球     55\n",
      "1      殺球     36\n",
      "2      挑球     35\n",
      "3      切球     31\n",
      "4      推球     31\n",
      "5     放小球     28\n",
      "6     擋小球     20\n",
      "7    未知球種     16\n",
      "8      勾球     12\n",
      "9     發長球     10\n",
      "10    發短球     10\n",
      "11  後場抽平球      7\n",
      "12   過度切球      6\n",
      "13   防守回抽      5\n",
      "14     撲球      5\n",
      "15     點扣      4\n",
      "16   防守回挑      2\n",
      "17     平球      2\n",
      "節點文本: 本場比賽雙方頻繁使用長球，次數高達55次，挑球也有35次。切球和推球的使用次數相當，分別為31次，顯示這兩種技術是選手們常用的得分手段。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:16,534 - INFO - 節點 496577ff 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 比賽中，可見對手落地得分與出界是主要失分點，各有12次，需要重點提防。掛網失誤也有10次，不可忽視。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:17,737 - INFO - 節點 50728b8d 文本生成完成\n",
      "2025-06-06 11:25:17,739 - INFO - 節點 cdb60d60 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 本場比賽雙方在場上爭奪激烈，可見「對手落地致勝」與「出界」是主要失分原因，各有12次之多，而「掛網」失誤也有10次，選手需多加注意。\n",
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 場上局勢膠著，雙方互有攻防。可見「對手落地致勝」與「出界」為主要失分因素，各位球員需要多加留意。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:18,620 - INFO - 節點 6b604cfd 文本生成完成\n",
      "2025-06-06 11:25:18,622 - INFO - 節點 7711d075 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   lose_reason  count\n",
      "0      對手落地致勝     12\n",
      "1          出界     12\n",
      "2          掛網     10\n",
      "3         未過網      2\n",
      "節點文本: 本場比賽雙方爭奪激烈，局勢膠著。主要失分點為對手落地得分與出界，各有12次，需重點提防。掛網失誤亦有10次，不可忽視，球員們需多加留意。\n",
      "node.table:   getpoint_player  count\n",
      "0               A     21\n",
      "1               B     15\n",
      "節點文本: A選手進攻火力全開，拿下全場最高的21分！B選手也不甘示弱，努力追分，取得15分。雖然數據未能顯示具體的失分原因，但A選手的得分能力無疑是本場比賽的一大亮點。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:19,499 - INFO - 節點 ad3b8632 文本生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:   getpoint_player  count\n",
      "0               A     21\n",
      "1               B     15\n",
      "節點文本: A選手進攻火力全開，以全場最高的21分領先！B選手奮力追趕，獲得15分。雖然未明確指出失分原因，但A選手的得分能力是本次比賽的亮點。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:20,804 - INFO - 節點 a46eb399 文本生成完成\n",
      "2025-06-06 11:25:20,807 - INFO - 生成最終報告...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node.table:      Unnamed: 0  rally      time  roundscore_A  roundscore_B player  type  \\\n",
      "0             0      1  00:05:47             1             0      B   發長球   \n",
      "1             1      1  00:05:49             1             0      A    切球   \n",
      "2             2      1  00:05:50             1             0      B    挑球   \n",
      "3             3      1  00:05:51             1             0      A    長球   \n",
      "4             4      1  00:05:52             1             0      B    殺球   \n",
      "..          ...    ...       ...           ...           ...    ...   ...   \n",
      "310         310     36  00:24:44            21            15      B  未知球種   \n",
      "311         311     36  00:24:58            21            15      A    切球   \n",
      "312         312     36  00:25:00            21            15      B    挑球   \n",
      "313         313     36  00:25:01            21            15      A    長球   \n",
      "314         314     36  00:25:02            21            15      B    長球   \n",
      "\n",
      "    lose_reason getpoint_player  \n",
      "0           NaN             NaN  \n",
      "1           NaN             NaN  \n",
      "2           NaN             NaN  \n",
      "3           NaN             NaN  \n",
      "4           NaN             NaN  \n",
      "..          ...             ...  \n",
      "310         NaN             NaN  \n",
      "311         NaN             NaN  \n",
      "312         NaN             NaN  \n",
      "313         NaN             NaN  \n",
      "314          出界               A  \n",
      "\n",
      "[315 rows x 9 columns]\n",
      "節點文本: 資料分析報告\n",
      "\n",
      "本場球賽雙方局勢膠著，互有攻防。長球使用最頻繁，高達55次，挑球35次。切球和推球次數相近，皆為31次。未知球員得分效率驚人，殺球次數為36次，進攻火力強勁。主要失分因素為對手落地得分與我方出界，各佔12分，掛網失誤亦有10分，需減少不必要失誤。A選手進攻火力全開，以21分領先，B選手獲得15分。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 11:25:24,558 - INFO - 樹結構已導出至: tree_structure.json\n",
      "2025-06-06 11:25:24,559 - INFO - \n",
      "==================================================\n",
      "2025-06-06 11:25:24,560 - INFO - TREE-OF-REPORT 最終報告\n",
      "2025-06-06 11:25:24,561 - INFO - ==================================================\n",
      "2025-06-06 11:25:24,563 - INFO - 報告生成完成，耗時: 72.75 秒\n",
      "2025-06-06 11:25:24,563 - INFO - 生成的文件:\n",
      "2025-06-06 11:25:24,565 - INFO - - tree_of_report.md: 最終報告\n",
      "2025-06-06 11:25:24,566 - INFO - - tree_of_report.txt: 純文本報告\n",
      "2025-06-06 11:25:24,567 - INFO - - tree_structure.json: 樹結構數據\n",
      "2025-06-06 11:25:24,568 - INFO - - execution_report.md: 執行過程報告\n",
      "2025-06-06 11:25:24,569 - INFO - - tree_visualization.html: 可視化頁面\n",
      "2025-06-06 11:25:24,570 - INFO - 清理暫存檔案: input_tmp.csv\n",
      "2025-06-06 11:25:24,571 - INFO - 清理暫存檔案: tmp.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generate report\n",
      "## 猛攻奏效！羽球賽事戰況膠著，A選手火力全開險勝\n",
      "\n",
      "羽球賽事現場氣氛緊張，雙方選手你來我往，比分始終無法拉開。整場比賽可謂高來高去，長球戰術頻繁使用，高達55次，展現選手們對場地深度的高度掌握。挑球的運用也相當關鍵，共計35次，試圖擾亂對手節奏。切球與推球則如兩把利刃，各有31次的精準施放，考驗著選手的細膩手感。\n",
      "\n",
      "然而，在這場戰術交鋒中，A選手憑藉其驚人的進攻火力脫穎而出。他猶如一頭猛獸，殺球次數高達36次，讓對手難以招架。反觀B選手，雖奮力抵抗，卻難以抵擋A選手的強勢進攻。\n",
      "\n",
      "儘管如此，比賽並非毫無破綻。雙方選手在比賽中都出現了因對手落地得分、自身出界以及掛網等失誤，其中落地得分與出界各佔12分，掛網失誤亦有10分，突顯了減少非受迫性失誤的重要性。\n",
      "\n",
      "最終，A選手憑藉著更勝一籌的進攻能力，以21分的佳績力壓B選手的15分，險勝對手。這場比賽不僅展現了選手們精湛的球技，也提醒著我們，在追求進攻的同時，穩紮穩打，減少不必要的失誤，才能在激烈的競爭中脫穎而出。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import dspy\n",
    "import ast\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional, Set\n",
    "import copy\n",
    "import hashlib\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import builtins\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===== 基於參考程式碼的函數 =====\n",
    "def read_text_file(file_path):\n",
    "    \"\"\"讀取文本文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"No file available\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"讀取文件錯誤: {e}\")\n",
    "        return \"Error reading file\"\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"讀取JSON文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # 返回默認操作集合\n",
    "        return [\n",
    "            {\"name\": \"select_column\", \"description\": \"選擇特定欄位\"},\n",
    "            {\"name\": \"value_counts\", \"description\": \"計算值的頻次\"},\n",
    "            {\"name\": \"groupby\", \"description\": \"按欄位分組\"},\n",
    "            {\"name\": \"sort_values\", \"description\": \"排序數據\"},\n",
    "            {\"name\": \"filter_rows\", \"description\": \"過濾行數據\"},\n",
    "            {\"name\": \"write\", \"description\": \"撰寫分析文本\"}\n",
    "        ]\n",
    "\n",
    "# ===== 改進的樹節點類別 =====\n",
    "class TreeNode:\n",
    "    \"\"\"改進的樹節點類別，增加語意驗證和追蹤功能\"\"\"\n",
    "    def __init__(self, level: int = 0, text: str = \"\", table: pd.DataFrame = None, operation: str = None):\n",
    "        self.children: List['TreeNode'] = []\n",
    "        self.level: int = level\n",
    "        self.text: str = text\n",
    "        self.table: pd.DataFrame = table if table is not None else pd.DataFrame()\n",
    "        self.operation: str = operation\n",
    "        self.parent: Optional['TreeNode'] = None\n",
    "        self.operation_history: List[str] = []\n",
    "        \n",
    "        # 新增屬性用於改進功能\n",
    "        self.node_id: str = self._generate_node_id()\n",
    "        self.created_at: datetime = datetime.now()\n",
    "        self.validation_errors: List[str] = []\n",
    "        self.table_hash: str = self._calculate_table_hash()\n",
    "        self.semantic_score: float = 0.0\n",
    "        \n",
    "    def _generate_node_id(self) -> str:\n",
    "        \"\"\"生成唯一節點ID\"\"\"\n",
    "        content = f\"{self.level}_{self.operation}_{datetime.now().isoformat()}\"\n",
    "        return hashlib.md5(content.encode()).hexdigest()[:8]\n",
    "        \n",
    "    def _calculate_table_hash(self) -> str:\n",
    "        \"\"\"計算表格內容的哈希值，用於檢測重複\"\"\"\n",
    "        if self.table.empty:\n",
    "            return \"\"\n",
    "        try:\n",
    "            return hashlib.md5(str(self.table.values.tobytes()).encode()).hexdigest()[:8]\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    def add_child(self, child: 'TreeNode'):\n",
    "        \"\"\"添加子節點並進行驗證\"\"\"\n",
    "        if self._validate_child(child):\n",
    "            child.parent = self\n",
    "            self.children.append(child)\n",
    "            logger.info(f\"添加子節點: {child.node_id} to {self.node_id}\")\n",
    "        else:\n",
    "            logger.warning(f\"子節點驗證失敗: {child.validation_errors}\")\n",
    "    \n",
    "    def _validate_child(self, child: 'TreeNode') -> bool:\n",
    "        \"\"\"驗證子節點的合理性\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # 檢查是否有重複的表格狀態\n",
    "        if child.table_hash and child.table_hash == self.table_hash:\n",
    "            if not child.operation.lower().startswith('write'):\n",
    "                errors.append(\"表格內容未發生變化但非寫作操作\")\n",
    "        \n",
    "        # 檢查操作是否邏輯合理\n",
    "        if self._is_redundant_operation(child.operation):\n",
    "            errors.append(f\"檢測到冗餘操作: {child.operation}\")\n",
    "        \n",
    "        child.validation_errors = errors\n",
    "        return len(errors) == 0\n",
    "    \n",
    "    def _is_redundant_operation(self, operation: str) -> bool:\n",
    "        \"\"\"檢查操作是否冗餘\"\"\"\n",
    "        if len(self.operation_history) < 2:\n",
    "            return False\n",
    "            \n",
    "        # 檢查是否有相同操作在近期歷史中\n",
    "        recent_ops = self.operation_history[-3:]  # 檢查最近3個操作\n",
    "        op_name = operation.split('(')[0].lower()\n",
    "        \n",
    "        for hist_op in recent_ops:\n",
    "            if hist_op.split('(')[0].lower() == op_name:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_leaf(self) -> bool:\n",
    "        \"\"\"判斷是否為葉節點\"\"\"\n",
    "        return len(self.children) == 0\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"將節點轉換為字典格式，用於可視化\"\"\"\n",
    "        return {\n",
    "            \"node_id\": self.node_id,\n",
    "            \"level\": self.level,\n",
    "            \"operation\": self.operation,\n",
    "            \"text_preview\": self.text[:100] + \"...\" if len(self.text) > 100 else self.text,\n",
    "            \"table_shape\": list(self.table.shape) if not self.table.empty else [0, 0],\n",
    "            \"table_columns\": list(self.table.columns) if not self.table.empty else [],\n",
    "            \"children_count\": len(self.children),\n",
    "            \"validation_errors\": self.validation_errors,\n",
    "            \"semantic_score\": self.semantic_score,\n",
    "            \"created_at\": self.created_at.isoformat(),\n",
    "            \"table_hash\": self.table_hash\n",
    "        }\n",
    "\n",
    "# ===== 改進的操作解析器 =====\n",
    "class OperationParser:\n",
    "    \"\"\"專門負責解析和驗證操作的類別\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.valid_operations = {\n",
    "            'select_column', 'select_row',  'sort', 'calculate',\n",
    "            'group_by', 'value_counts', 'aggregate', 'crosstab','pivot_table', 'write'\n",
    "        }\n",
    "        \n",
    "    def parse_operations(self, response_text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"改進的操作解析，返回結構化結果\"\"\"\n",
    "        try:\n",
    "            parsed_operations = []\n",
    "            \n",
    "            # 多種解析策略\n",
    "            operations = self._extract_operations_multiple_strategies(response_text)\n",
    "            \n",
    "            for op_str in operations:\n",
    "                parsed_op = self._parse_single_operation(op_str)\n",
    "                if parsed_op and self._validate_operation(parsed_op):\n",
    "                    parsed_operations.append(parsed_op)\n",
    "                else:\n",
    "                    logger.warning(f\"無效操作被忽略: {op_str}\")\n",
    "            \n",
    "            return parsed_operations[:5]  # 限制最多5個操作\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"解析操作失敗: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_operations_multiple_strategies(self, text: str) -> List[str]:\n",
    "        \"\"\"使用多種策略提取操作\"\"\"\n",
    "        operations = []\n",
    "        \n",
    "        # 策略1: 尋找方括號內容\n",
    "        bracket_match = re.search(r'\\[(.*?)\\]', text, re.DOTALL)\n",
    "        if bracket_match:\n",
    "            content = bracket_match.group(1)\n",
    "            # 使用正則提取函數調用格式\n",
    "            pattern = r'([a-zA-Z_]+\\([^)]*\\))'\n",
    "            ops = re.findall(pattern, content)\n",
    "            operations.extend(ops)\n",
    "        \n",
    "        # 策略2: 逐行解析\n",
    "        if not operations:\n",
    "            lines = text.split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#') and '(' in line and ')' in line:\n",
    "                    operations.append(line)\n",
    "        \n",
    "        # 策略3: 逗號分割\n",
    "        if not operations:\n",
    "            parts = text.replace('[', '').replace(']', '').split(',')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                if part and '(' in part:\n",
    "                    operations.append(part)\n",
    "        \n",
    "        return operations\n",
    "    \n",
    "    def _parse_single_operation(self, op_str: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"解析單個操作字符串\"\"\"\n",
    "        try:\n",
    "            # 移除多餘的字符\n",
    "            op_str = op_str.strip().rstrip(',').strip()\n",
    "            \n",
    "            # 提取操作名稱和參數\n",
    "            if '(' not in op_str:\n",
    "                return {\"name\": op_str, \"args\": [], \"raw\": op_str}\n",
    "            \n",
    "            name_part = op_str.split('(')[0].strip()\n",
    "            args_part = op_str[op_str.find('(')+1:op_str.rfind(')')].strip()\n",
    "            \n",
    "            # 解析參數\n",
    "            args = []\n",
    "            if args_part:\n",
    "                # 簡單的參數分割（可以進一步改進）\n",
    "                for arg in args_part.split(','):\n",
    "                    arg = arg.strip().strip('\\'\"')\n",
    "                    if arg:\n",
    "                        args.append(arg)\n",
    "            \n",
    "            return {\n",
    "                \"name\": name_part.lower(),\n",
    "                \"args\": args,\n",
    "                \"raw\": op_str\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"解析操作 '{op_str}' 失敗: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _validate_operation(self, operation: Dict[str, Any]) -> bool:\n",
    "        \"\"\"驗證操作的有效性\"\"\"\n",
    "        name = operation.get(\"name\", \"\").lower()\n",
    "        \n",
    "        # 檢查操作名稱是否有效\n",
    "        if name not in self.valid_operations:\n",
    "            logger.warning(f\"未知操作: {name}\")\n",
    "            return False\n",
    "        \n",
    "        # 檢查特定操作的參數\n",
    "        args = operation.get(\"args\", [])\n",
    "        \n",
    "        if name in ['select_column', 'sort_values'] and not args:\n",
    "            logger.warning(f\"{name} 操作需要參數\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "# ===== 改進的內容規劃器 =====\n",
    "class ContentPlanner:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.parser = OperationParser()\n",
    "        \n",
    "    def generate_operations(self, tables, table_description, operation_description, \n",
    "                          operation_history, operation_pool, max_depth=5, max_degree=3, outline_path='main.txt'):\n",
    "        \"\"\"\n",
    "        改進的操作生成，加入重複檢測和語意驗證\n",
    "        \"\"\"\n",
    "        \n",
    "        # 檢測近期操作，避免重複\n",
    "        recent_operations = self._extract_recent_operations(operation_history)\n",
    "        \n",
    "        # 構建改進的提示詞\n",
    "        prompt = f\"\"\"System : You are a content planner for the report. Please follow the outline. Please select candidate Operations and corresponding Arguments from the Operation Pool based on the input Tables and Operation History. These candidate Operations will be the next Operation in the Operation History .\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in English .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The length of Operation History must be less than or equal to {max_depth}.\n",
    "5. The number of Operations must be less than or equal to {max_degree}  and more than zero.\n",
    "6. Only select Opertions from the Operation Pool .\n",
    "7. Arguments must match the format required by the corresponding Operations .\n",
    "8. Operations & Arguments must follow this format : [ operation_1 ( argument_1 , ...) , operation_2 ( argument_2 , ...) , operation_3 ( argument_3 , ...) , ...]\n",
    "9. Only output Operations & Arguments !\n",
    "10. If Table is big or Level is low, it should be more Operations include select_col or select_row not write.\n",
    "11. If the length of Operation History is short, then more operations or more arguments.\n",
    "12. Write operations do not need argument.\n",
    "13. AVOID repeating recent operations: {recent_operations}\n",
    "14. Prioritize operations that will meaningfully transform the data.\n",
    "15. Avoid give the arguments that not match by the operation.\n",
    "\n",
    "#outline\n",
    "{read_text_file(outline_path) if os.path.exists(outline_path) else \"Generate comprehensive data analysis\"}\n",
    "\n",
    "# Table Description\n",
    "{table_description}\n",
    "\n",
    "# Operation Description\n",
    "{json.dumps(operation_description, indent=2, ensure_ascii=False)}\n",
    "\n",
    "User : # Test\n",
    "## Tables\n",
    "{tables}\n",
    "\n",
    "## Operation History\n",
    "{operation_history}\n",
    "\n",
    "## Operation Pool\n",
    "{operation_pool}\n",
    "\n",
    "## Operations & Arguments\"\"\"\n",
    "\n",
    "        try:\n",
    "            logger.info(\"正在向Gemini發送請求...\")\n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            if response.text:\n",
    "                logger.info(\"成功獲得Gemini回應\")\n",
    "                parsed_ops = self.parser.parse_operations(response.text.strip())\n",
    "                return [op[\"raw\"] for op in parsed_ops]  # 返回原始字符串格式\n",
    "            else:\n",
    "                logger.warning(\"Gemini回應為空\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Gemini API請求失敗: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_recent_operations(self, operation_history: List[str]) -> List[str]:\n",
    "        \"\"\"提取最近的操作名稱\"\"\"\n",
    "        recent = []\n",
    "        for op in operation_history[-3:]:  # 最近3個操作\n",
    "            if '(' in op:\n",
    "                name = op.split('(')[0].strip()\n",
    "                recent.append(name)\n",
    "        return recent\n",
    "\n",
    "# ===== 安全的DataFrame操作器 =====\n",
    "class SafeDataFrameOperator:\n",
    "    \"\"\"安全的DataFrame操作器，使用AST驗證而非直接exec\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.allowed_modules = {'pandas', 'numpy', 're'}\n",
    "        self.allowed_functions = {\n",
    "            'pd.read_csv', 'pd.DataFrame', 'df.head', 'df.tail', 'df.sort_values',\n",
    "            'df.groupby', 'df.filter', 'df.select', 'df.drop', 'df.fillna',\n",
    "            'df.to_csv', 'df.value_counts', 'df.describe', 'df.info'\n",
    "        }\n",
    "\n",
    "    def generate_code(self, operation, df_info, df_path=\"input_tmp.csv\"):\n",
    "        prompt = f\"\"\"\n",
    "        你是一個專業的Python資料分析助手。欄位名稱以資料欄位類型提供為主，根據以下要求生成操作DataFrame的程式碼：\n",
    "\n",
    "        要執行的操作: {operation}\n",
    "\n",
    "        CSV數據集: {df_path}\n",
    "\n",
    "        資料欄位類型:\n",
    "        {df_info}\n",
    "\n",
    "        生成要求：\n",
    "        1. 讀取CSV數據集，並存入DataFrame後，使用要執行的操作後，將修改後的DataFrame存入'tmp.csv'\n",
    "        2. 只使用pandas基本操作，避免複雜的自定義函數\n",
    "        3. 確保代碼安全，不包含文件系統操作（除了指定的CSV讀寫）\n",
    "        4. 撰寫完整python code，包含錯誤處理\n",
    "\n",
    "        輸出格式：\n",
    "        ```python\n",
    "        # 你的程式碼\n",
    "        ```\n",
    "        \"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "    def _retry_generate(self, prompt, max_retries=2):\n",
    "        \"\"\"帶重試的生成請求\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(prompt)\n",
    "                if response.text:\n",
    "                    return response.text.strip()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"生成代碼失敗 (嘗試 {attempt+1}/{max_retries}): {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    import time\n",
    "                    time.sleep(1)\n",
    "        return \"\"\n",
    "\n",
    "    def safe_execute(self, code: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"安全執行生成的代碼\"\"\"\n",
    "        try:\n",
    "            # 提取代碼塊\n",
    "            code_block = re.search(r'```python\\n(.*?)\\n```', code, re.DOTALL)\n",
    "            #print(f'python code: {code_block}')\n",
    "            if code_block:\n",
    "                code = code_block.group(1)\n",
    "\n",
    "            # AST安全驗證\n",
    "            if not self._validate_code_safety(code):\n",
    "                logger.error(\"代碼安全驗證失敗\")\n",
    "                return df\n",
    "\n",
    "            # 寫入暫存 CSV 檔案\n",
    "            df.to_csv(\"input_tmp.csv\", index=False)\n",
    "\n",
    "            allowed_builtin_names = [\n",
    "                'int', 'float', 'str', 'bool', 'list', 'dict', 'set', 'tuple',\n",
    "                'len', 'range', 'enumerate', 'zip', 'min', 'max', 'sum', 'abs',\n",
    "                'print',\n",
    "                'Exception', 'TypeError', 'ValueError', 'KeyError', 'IndexError',\n",
    "                'FileNotFoundError', 'ZeroDivisionError', 'AttributeError', 'ImportError',\n",
    "                '__import__'\n",
    "            ]\n",
    "\n",
    "            safe_globals = {\n",
    "                'pd': pd,\n",
    "                '__name__': '__main__',\n",
    "                '__builtins__': {name: getattr(builtins, name) for name in allowed_builtin_names}\n",
    "            }\n",
    "\n",
    "            safe_locals = {}\n",
    "\n",
    "            # 執行代碼\n",
    "            exec(code, safe_globals, safe_locals)\n",
    "\n",
    "            # 讀取結果\n",
    "            if os.path.exists(\"tmp.csv\"):\n",
    "                result_df = pd.read_csv(\"tmp.csv\")\n",
    "                logger.info(f\"操作成功，結果形狀: {result_df.shape}\")\n",
    "                return result_df\n",
    "            else:\n",
    "                logger.warning(\"未生成結果文件，返回原始DataFrame\")\n",
    "                return df\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"執行錯誤: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            print(\"錯誤代碼如下：\\n\" + \"-\" * 30)\n",
    "            print(code)  # ✅ 輸出造成錯誤的程式碼\n",
    "            print(\"-\" * 30)\n",
    "            logger.error(error_msg)\n",
    "            sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "    def _validate_code_safety(self, code: str) -> bool:\n",
    "        \"\"\"使用AST驗證代碼安全性\"\"\"\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            \n",
    "            for node in ast.walk(tree):\n",
    "                # 檢查危險的函數調用\n",
    "                if isinstance(node, ast.Call):\n",
    "                    if isinstance(node.func, ast.Name):\n",
    "                        func_name = node.func.id\n",
    "                        if func_name in ['exec', 'eval', 'compile', '__import__', 'open']:\n",
    "                            logger.error(f\"檢測到危險函數: {func_name}\")\n",
    "                            return False\n",
    "                \n",
    "                # 檢查文件操作（除了允許的CSV操作）\n",
    "                if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):\n",
    "                    if hasattr(node.func, 'attr'):\n",
    "                        attr_name = node.func.attr\n",
    "                        if attr_name in ['system', 'popen', 'subprocess']:\n",
    "                            logger.error(f\"檢測到系統調用: {attr_name}\")\n",
    "                            return False\n",
    "                \n",
    "                # 檢查導入語句\n",
    "                if isinstance(node, ast.Import):\n",
    "                    for alias in node.names:\n",
    "                        if alias.name not in self.allowed_modules:\n",
    "                            logger.error(f\"檢測到不允許的模組導入: {alias.name}\")\n",
    "                            return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except SyntaxError as e:\n",
    "            logger.error(f\"代碼語法錯誤: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"AST驗證失敗: {e}\")\n",
    "            return False\n",
    "\n",
    "# ===== 文本生成器 =====\n",
    "import time\n",
    "\n",
    "class TextGenerator:\n",
    "    def __init__(self, api_key, table_description=\"\"):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.table_description = table_description\n",
    "\n",
    "    def extract_highlights_from_table(self, table: pd.DataFrame) -> str:\n",
    "        try:\n",
    "            if 'lose_reason' in table.columns:\n",
    "                top_reason = table['lose_reason'].value_counts().idxmax()\n",
    "            else:\n",
    "                top_reason = \"無資料\"\n",
    "            if 'getpoint_player' in table.columns:\n",
    "                top_player = table['getpoint_player'].value_counts().idxmax()\n",
    "            else:\n",
    "                top_player = \"未知球員\"\n",
    "            return f\"最多失分原因為「{top_reason}」，得分最多的是 {top_player}。\"\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "    def extract_table_features(self, table: pd.DataFrame) -> str:\n",
    "        summary = []\n",
    "        for col in table.columns:\n",
    "            dtype = str(table[col].dtype)\n",
    "            line = f\"欄位「{col}」類型：{dtype}\"\n",
    "\n",
    "            # 顯示常見值僅限類別型欄位\n",
    "            if table[col].nunique() <= 10 or dtype == 'object' or pd.api.types.is_categorical_dtype(table[col]):\n",
    "                top_values = table[col].value_counts().head(3).to_dict()\n",
    "                line += f\"，常見值：{list(top_values.keys())}\"\n",
    "            summary.append(line)\n",
    "        return \"\\n\".join(summary)\n",
    "\n",
    "    def _retry_generate(self, prompt, max_retries=3, delay_seconds=30):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(prompt)\n",
    "                if response.text:\n",
    "                    return response.text.strip()\n",
    "            except Exception as e:\n",
    "                err = str(e)\n",
    "                logger.error(f\"Gemini 回應失敗: {err}\")\n",
    "                if \"429\" in err:\n",
    "                    logger.info(f\"已達配額限制，等待 {delay_seconds} 秒後重試 ({attempt+1}/{max_retries})...\")\n",
    "                    time.sleep(delay_seconds)\n",
    "                else:\n",
    "                    break\n",
    "        return \"⚠️ 寫作請求失敗：API 限制或其他錯誤\"\n",
    "\n",
    "    def generate_text_for_write_operation(self, table: pd.DataFrame, operation_history: List[str]) -> str:\n",
    "        table_str = table.to_string()\n",
    "        WRITE_TOKENS = 50\n",
    "        TABLE_FORMAT = \"Pandas DataFrame as plain text\"\n",
    "        highlight_summary = self.extract_highlights_from_table(table)\n",
    "        table_feature_summary = self.extract_table_features(table)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "System :\n",
    "You are a professional content writer for the badminton game report .\n",
    "Please write the Report based on the input Table, just pick one or two lightspots.\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in 中文 .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The Table format is {TABLE_FORMAT}.\n",
    "5. The Report can only describe the content included in the Tables and cannot describe anything not included in the Tables .\n",
    "6. The Report must consist of only one paragraph .\n",
    "7. The number of tokens in the Report must be within {WRITE_TOKENS}.\n",
    "8. 請專注描述得分與失分模式、關鍵欄位趨勢或球員亮點。\n",
    "9. 請模仿比賽轉播員或教練的語氣描述，句式自然、有節奏感。\n",
    "10. 請特別觀察球種之間的連續轉換，例如 放小球 接 殺球 等，找出其中有效得分或不尋常的組合並描述。\n",
    "\n",
    "# Highlights Summary\n",
    "{highlight_summary}\n",
    "\n",
    "# Table Features\n",
    "{table_feature_summary}\n",
    "\n",
    "# Table Description\n",
    "{self.table_description}\n",
    "\n",
    "User :\n",
    "# Test\n",
    "## Tables\n",
    "{table_str}\n",
    "## Report\n",
    "\"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "    def merge_child_texts(self, child_texts: List[str], parent_operation: str) -> str:\n",
    "        if not child_texts:\n",
    "            return \"\"\n",
    "\n",
    "        GENERATING_TOKENS = 100\n",
    "        reports_str = \"\\n\".join([f\"- {txt}\" for txt in child_texts])\n",
    "        prompt = f\"\"\"\n",
    "System :\n",
    "You are a content generator for the badminton game report .\n",
    "Please merge and rewrite a New Report based on the input Reports .\n",
    "\n",
    "# Requirements\n",
    "1. Strictly adhere to the requirements .\n",
    "2. The output must be in 中文 .\n",
    "3. The output must be based on the input data ; do not hallucinate .\n",
    "4. The New Report must include all the content from the input Reports ; do not omit any information .\n",
    "5. The New Report must follow the order of the input Reports .\n",
    "6. The number of tokens in the New Report must be within {GENERATING_TOKENS}.\n",
    "7. 請依序整合每段內容，形成結構清晰的段落，包括亮點、失誤模式與球員貢獻。\n",
    "\n",
    "User :\n",
    "# Test\n",
    "## Reports\n",
    "{reports_str}\n",
    "## New Report\n",
    "\"\"\"\n",
    "        return self._retry_generate(prompt)\n",
    "\n",
    "# ===== OperationParser._validate_operation 強化參數驗證（補入 df 欄位比對） =====\n",
    "def validate_operation_with_columns(operation: Dict[str, Any], df_columns: List[str]) -> bool:\n",
    "    name = operation.get(\"name\", \"\").lower()\n",
    "    args = operation.get(\"args\", [])\n",
    "\n",
    "    # 檢查操作名稱是否有效\n",
    "    if name not in {\n",
    "        'select_column', 'select_row', 'sort', 'calculate',\n",
    "        'group_by', 'value_counts', 'aggregate', 'crosstab', 'pivot_table', 'write'\n",
    "    }:\n",
    "        return False\n",
    "\n",
    "    # 僅針對需參數操作檢查欄位\n",
    "    if name in ['select_column', 'sort', 'group_by']:\n",
    "        for arg in args:\n",
    "            if arg not in df_columns:\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "# ===== 改進的TreeOfReport類別 =====\n",
    "class TreeOfReport:\n",
    "    def __init__(self, api_key: str, max_depth: int = 5, max_degree: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.max_depth = max_depth\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "        # 載入配置檔案\n",
    "        self.load_configurations()\n",
    "\n",
    "        # 初始化改進的組件\n",
    "        self.content_planner = ContentPlanner(api_key)\n",
    "        self.df_operator = SafeDataFrameOperator(api_key)  # 使用安全版本\n",
    "        self.text_generator = TextGenerator(api_key, table_description=self.table_description)\n",
    "        \n",
    "        # 新增追蹤功能\n",
    "        self.execution_log: List[Dict[str, Any]] = []\n",
    "        self.node_registry: Dict[str, TreeNode] = {}\n",
    "\n",
    "    def load_configurations(self):\n",
    "        self.table_description = read_text_file(\"filtered_data _description.txt\")\n",
    "        if not self.table_description or self.table_description == \"No file available\":\n",
    "            self.table_description = \"數據分析表格，包含各種欄位用於分析\"\n",
    "\n",
    "        self.operation_description = read_json_file(\"selected_operations.json\")\n",
    "        if isinstance(self.operation_description, list):\n",
    "            self.operation_pool = [op['name'] for op in self.operation_description]\n",
    "        else:\n",
    "            self.operation_pool = list(self.operation_description.keys())\n",
    "\n",
    "        logger.info(f\"載入操作池: {self.operation_pool}\")\n",
    "\n",
    "    def build_tree(self, root_table: pd.DataFrame) -> TreeNode:\n",
    "        \"\"\"改進的樹構建，加入完整的追蹤和驗證\"\"\"\n",
    "        root = TreeNode(level=0, text=\"資料分析報告\", table=root_table, operation=\"root(None)\")\n",
    "        root.operation_history = ['root(None)']\n",
    "        self.node_registry[root.node_id] = root\n",
    "        \n",
    "        queue = [root]\n",
    "        \n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "            \n",
    "            # 記錄處理日誌\n",
    "            self._log_node_processing(current_node)\n",
    "\n",
    "            if current_node.operation.lower().startswith('write'):\n",
    "                continue\n",
    "\n",
    "            if current_node.level >= self.max_depth:\n",
    "                write_node = self.create_child_node(current_node, 'write()')\n",
    "                if write_node:\n",
    "                    current_node.add_child(write_node)\n",
    "                continue\n",
    "\n",
    "            logger.info(f\"處理節點 - Level: {current_node.level}, Operation: {current_node.operation}\")\n",
    "\n",
    "            tables_str = current_node.table.to_string()\n",
    "            operations = self.content_planner.generate_operations(\n",
    "                tables=tables_str,\n",
    "                table_description=self.table_description,\n",
    "                operation_description=self.operation_description,\n",
    "                operation_history=current_node.operation_history,\n",
    "                operation_pool=self.operation_pool,\n",
    "                max_depth=self.max_depth,\n",
    "                max_degree=self.max_degree\n",
    "            )\n",
    "\n",
    "            logger.info(f\"生成操作: {operations}\")\n",
    "\n",
    "            for operation in operations[:self.max_degree]:\n",
    "                if operation.strip():\n",
    "                    child_node = self.create_child_node(current_node, operation)\n",
    "                    if child_node:\n",
    "                        current_node.add_child(child_node)\n",
    "                        queue.append(child_node)\n",
    "\n",
    "        self.generate_all_texts(root)\n",
    "        return root\n",
    "    \n",
    "    def _log_node_processing(self, node: TreeNode):\n",
    "        \"\"\"記錄節點處理日誌\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"node_id\": node.node_id,\n",
    "            \"level\": node.level,\n",
    "            \"operation\": node.operation,\n",
    "            \"table_shape\": list(node.table.shape) if not node.table.empty else [0, 0],\n",
    "            \"validation_errors\": node.validation_errors\n",
    "        }\n",
    "        self.execution_log.append(log_entry)\n",
    "    \n",
    "    def create_child_node(self, parent: TreeNode, operation: str) -> Optional[TreeNode]:\n",
    "        \"\"\"改進的子節點創建，加入完整驗證\"\"\"\n",
    "        try:\n",
    "            # 建立新的操作歷史\n",
    "            new_operation_history = parent.operation_history + [operation]\n",
    "            \n",
    "            # 檢查是否為 write 操作\n",
    "            if operation.lower().startswith('write'):\n",
    "                text = self.text_generator.generate_text_for_write_operation(\n",
    "                    parent.table,\n",
    "                    new_operation_history\n",
    "                )\n",
    "                child = TreeNode(\n",
    "                    level=parent.level + 1,\n",
    "                    text=text,\n",
    "                    table=parent.table.copy(),\n",
    "                    operation=operation\n",
    "                )\n",
    "                child.operation_history = new_operation_history\n",
    "                self.node_registry[child.node_id] = child\n",
    "                logger.info(f\"創建 write 節點: {operation}\")\n",
    "                return child\n",
    "            else:\n",
    "                # 其他操作：執行數據操作\n",
    "                df_info = f\"Shape: {parent.table.shape}\\nColumns: {list(parent.table.columns)}\\nData types:\\n{parent.table.dtypes.to_string()}\"\n",
    "                code = self.df_operator.generate_code(operation, df_info)\n",
    "                \n",
    "                if code:\n",
    "                    result_df = self.df_operator.safe_execute(code, parent.table)\n",
    "                    child = TreeNode(\n",
    "                        level=parent.level + 1,\n",
    "                        text=\"\",\n",
    "                        table=result_df,\n",
    "                        operation=operation\n",
    "                    )\n",
    "                    child.operation_history = new_operation_history\n",
    "                    self.node_registry[child.node_id] = child\n",
    "                    logger.info(f\"創建數據操作節點: {operation}, 結果形狀: {result_df.shape}\")\n",
    "                    return child\n",
    "                else:\n",
    "                    logger.warning(f\"無法生成操作代碼: {operation}\")\n",
    "                    return None\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"創建子節點失敗: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_all_texts(self, node: TreeNode):\n",
    "        \"\"\"遞歸生成所有節點的文本\"\"\"\n",
    "        for child in node.children:\n",
    "            self.generate_all_texts(child)\n",
    "        \n",
    "        if node.is_leaf() and not node.text and node.operation and not node.operation.lower().startswith('write'):\n",
    "            node.text = self.text_generator.generate_text_for_write_operation(\n",
    "                node.table, \n",
    "                node.operation_history\n",
    "            )\n",
    "            print(f'node table: {node.table}')\n",
    "        elif node.children:\n",
    "            child_texts = [child.text for child in node.children if child.text.strip()]\n",
    "            if child_texts:\n",
    "                merged_text = self.text_generator.merge_child_texts(\n",
    "                    child_texts, \n",
    "                    node.operation or \"root\"\n",
    "                )\n",
    "                if node.text:\n",
    "                    node.text = node.text + \"\\n\\n\" + merged_text\n",
    "                else:\n",
    "                    node.text = merged_text\n",
    "        logger.info(f'節點 {node.node_id} 文本生成完成')\n",
    "        print(f'node.table: {node.table}')\n",
    "        print(f'節點文本: {node.text}')\n",
    "        \n",
    "    def export_tree_structure(self, root: TreeNode, output_path: str = \"tree_structure.json\"):\n",
    "        \"\"\"導出樹結構為JSON格式，用於可視化和分析\"\"\"\n",
    "        def node_to_dict(node: TreeNode) -> Dict[str, Any]:\n",
    "            result = node.to_dict()\n",
    "            result[\"children\"] = [node_to_dict(child) for child in node.children]\n",
    "            return result\n",
    "        \n",
    "        tree_data = {\n",
    "            \"metadata\": {\n",
    "                \"export_time\": datetime.now().isoformat(),\n",
    "                \"total_nodes\": len(self.node_registry),\n",
    "                \"max_depth\": self.max_depth,\n",
    "                \"max_degree\": self.max_degree\n",
    "            },\n",
    "            \"execution_log\": self.execution_log,\n",
    "            \"tree\": node_to_dict(root)\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(tree_data, f, indent=2, ensure_ascii=False)\n",
    "            logger.info(f\"樹結構已導出至: {output_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"導出樹結構失敗: {e}\")\n",
    "    \n",
    "    def generate_execution_report(self) -> str:\n",
    "        \"\"\"生成執行過程報告\"\"\"\n",
    "        total_nodes = len(self.node_registry)\n",
    "        error_nodes = sum(1 for node in self.node_registry.values() if node.validation_errors)\n",
    "        \n",
    "        report = f\"\"\"\n",
    "# Tree-of-Report 執行報告\n",
    "\n",
    "## 統計信息\n",
    "- 總節點數: {total_nodes}\n",
    "- 錯誤節點數: {error_nodes}\n",
    "- 樹最大深度: {self.max_depth}\n",
    "- 最大分支度: {self.max_degree}\n",
    "\n",
    "## 節點分布\n",
    "\"\"\"\n",
    "        \n",
    "        # 按層級統計節點\n",
    "        level_counts = {}\n",
    "        for node in self.node_registry.values():\n",
    "            level = node.level\n",
    "            level_counts[level] = level_counts.get(level, 0) + 1\n",
    "        \n",
    "        for level, count in sorted(level_counts.items()):\n",
    "            report += f\"- Level {level}: {count} 個節點\\n\"\n",
    "        \n",
    "        # 錯誤摘要\n",
    "        if error_nodes > 0:\n",
    "            report += \"\\n## 驗證錯誤摘要\\n\"\n",
    "            for node in self.node_registry.values():\n",
    "                if node.validation_errors:\n",
    "                    report += f\"- 節點 {node.node_id} ({node.operation}): {'; '.join(node.validation_errors)}\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "    def generate_report(self, node: TreeNode, level: int = 0) -> str:\n",
    "        \"\"\"改進的報告生成\"\"\"\n",
    "        if node.level == 0:\n",
    "            prompt = f\"\"\"\n",
    "            你是一位新聞記者，根據以下分析總結，請撰寫一篇賽事新聞報導，提供全面深入的分析，統整成新聞報導，文辭中過多直接使用欄位名稱與直接次數統計，用player_A與player_B表示兩球員，用生動的文句描述，勿出現累贅的句子，請從分析總結中提取轉換，禁止出現幻覺。\n",
    "            請用繁體中文撰寫，保持邏輯清晰，資訊準確。\n",
    "\n",
    "            分析總結:\n",
    "            {node.text}\n",
    "            \"\"\"\n",
    "            final_text = self.text_generator._retry_generate(prompt)\n",
    "            \n",
    "            # 保存多種格式的報告\n",
    "            with open(\"tree_of_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(final_text)\n",
    "            \n",
    "            # 導出樹結構\n",
    "            self.export_tree_structure(node)\n",
    "            \n",
    "            # 生成執行報告\n",
    "            exec_report = self.generate_execution_report()\n",
    "            with open(\"execution_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(exec_report)\n",
    "                print(\"finish generate report\")\n",
    "            \n",
    "            return final_text\n",
    "        else:\n",
    "            logger.info(f'generate report from not root')\n",
    "            indent = \"  \" * level\n",
    "            report = f\"{indent}{'#' * (level + 1)} {node.operation or 'Root'}\\n\\n\"\n",
    "\n",
    "            if node.text:\n",
    "                report += f\"{indent}{node.text}\\n\\n\"\n",
    "\n",
    "            if node.table is not None and not node.table.empty and level < 2:\n",
    "                report += f\"{indent}**資料摘要:** Shape {node.table.shape}\\n\"\n",
    "                if len(node.table) <= 10:\n",
    "                    report += f\"{indent}```\\n{node.table.to_string()}\\n{indent}```\\n\\n\"\n",
    "                else:\n",
    "                    report += f\"{indent}```\\n{node.table.head().to_string()}\\n{indent}```\\n\\n\"\n",
    "\n",
    "            for child in node.children:\n",
    "                report += self.generate_report(child, level + 1)\n",
    "\n",
    "            return report\n",
    "\n",
    "\n",
    "# ===== 主程序 =====\n",
    "def main():\n",
    "    \"\"\"改進的主函數\"\"\"\n",
    "    \n",
    "    # 設置API密鑰\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        logger.error(\"請設置 GOOGLE_API_KEY 環境變數\")\n",
    "        return\n",
    "    \n",
    "    logger.info(\"Tree-of-Report for Data Analysis (改進版)\")\n",
    "    logger.info(\"=\"*50)\n",
    "    \n",
    "    logger.info(\"正在載入數據...\")\n",
    "    \n",
    "    # 讀取CSV檔案\n",
    "    try:\n",
    "        TABLES = pd.read_csv('filtered_set1.csv')\n",
    "        logger.info(f\"成功載入CSV: {TABLES.shape[0]} 行, {TABLES.shape[1]} 列\")\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(\"找不到 filtered_set1.csv，使用示例數據\")\n",
    "        # 創建示例數據\n",
    "        TABLES = pd.DataFrame({\n",
    "            'type': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B'],\n",
    "            'lose_reason': ['net', 'out', 'net', 'long', 'net', 'out', 'long', 'net'],\n",
    "            'getpoint_player': ['Player1', 'Player2', 'Player1', 'Player2', 'Player1', 'Player2', 'Player1', 'Player2'],\n",
    "            'score': [1, 2, 1, 3, 2, 1, 4, 2]\n",
    "        })\n",
    "    \n",
    "    # 設置參數\n",
    "    MAX_DEPTH = 3\n",
    "    MAX_DEGREE = 4\n",
    "    \n",
    "    logger.info(f\"最大深度: {MAX_DEPTH}\")\n",
    "    logger.info(f\"最大分支度: {MAX_DEGREE}\")\n",
    "    \n",
    "    # 初始化改進的 Tree-of-Report\n",
    "    tree_report = TreeOfReport(api_key, max_depth=MAX_DEPTH, max_degree=MAX_DEGREE)\n",
    "    \n",
    "    # 建構報告樹\n",
    "    logger.info(\"開始建構報告樹...\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        root = tree_report.build_tree(TABLES)\n",
    "        \n",
    "        # 生成最終報告\n",
    "        logger.info(\"生成最終報告...\")\n",
    "        final_report = tree_report.generate_report(root)\n",
    "        \n",
    "        # 輸出報告\n",
    "        logger.info(\"\\n\" + \"=\"*50)\n",
    "        logger.info(\"TREE-OF-REPORT 最終報告\")\n",
    "        logger.info(\"=\"*50)\n",
    "        print(final_report)\n",
    "        \n",
    "        # 儲存報告\n",
    "        with open('tree_of_report.md', 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# Tree-of-Report 數據分析報告 (改進版)\\n\\n\")\n",
    "            f.write(final_report)\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        logger.info(f\"報告生成完成，耗時: {duration:.2f} 秒\")\n",
    "        logger.info(\"生成的文件:\")\n",
    "        logger.info(\"- tree_of_report.md: 最終報告\")\n",
    "        logger.info(\"- tree_of_report.txt: 純文本報告\")\n",
    "        logger.info(\"- tree_structure.json: 樹結構數據\")\n",
    "        logger.info(\"- execution_report.md: 執行過程報告\")\n",
    "        logger.info(\"- tree_visualization.html: 可視化頁面\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"程序執行失敗: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    finally:\n",
    "        # 清理暫存檔案\n",
    "        for temp_file in ['input_tmp.csv', 'tmp.csv']:\n",
    "            if os.path.exists(temp_file):\n",
    "                try:\n",
    "                    os.remove(temp_file)\n",
    "                    logger.info(f\"清理暫存檔案: {temp_file}\")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:17:50,505 - INFO - Enhanced Tree-of-Report for Sports News Generation\n",
      "2025-06-06 12:17:50,507 - INFO - ============================================================\n",
      "2025-06-06 12:17:50,507 - INFO - 正在載入數據...\n",
      "2025-06-06 12:17:50,509 - INFO - 成功載入CSV: 315 行, 9 列\n",
      "2025-06-06 12:17:50,510 - INFO - 載入操作池: ['write', 'select_row', 'select_column', 'group_by', 'aggregate', 'value_counts', 'crosstab', 'pivot_table', 'sort', 'calculate']\n",
      "2025-06-06 12:17:50,510 - INFO - 開始建構增強版報告樹...\n",
      "2025-06-06 12:17:50,520 - ERROR - 創建子節點失敗: Object of type int64 is not JSON serializable\n",
      "2025-06-06 12:17:52,337 - INFO - 操作成功，結果形狀: (315, 9)\n",
      "2025-06-06 12:17:52,338 - INFO - 創建數據操作節點: select_row, 結果形狀: (315, 9)\n",
      "2025-06-06 12:17:52,345 - ERROR - 創建子節點失敗: Object of type int64 is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully read, processed, and saved to tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:17:54,946 - INFO - 操作成功，結果形狀: (258, 9)\n",
      "2025-06-06 12:17:54,946 - INFO - 創建數據操作節點: select_row, 結果形狀: (258, 9)\n",
      "2025-06-06 12:17:54,954 - ERROR - 創建子節點失敗: Object of type int64 is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 已成功儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:17:56,504 - INFO - 操作成功，結果形狀: (258, 9)\n",
      "2025-06-06 12:17:56,505 - INFO - 創建數據操作節點: select_row, 結果形狀: (258, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame操作成功並已保存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:17:58,560 - INFO - 操作成功，結果形狀: (258, 8)\n",
      "2025-06-06 12:17:58,561 - INFO - 創建數據操作節點: select_column, 結果形狀: (258, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame處理完成並已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:00,665 - INFO - 操作成功，結果形狀: (31, 3)\n",
      "2025-06-06 12:18:00,665 - INFO - 創建數據操作節點: group_by, 結果形狀: (31, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_by 操作完成，結果已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:02,589 - INFO - 操作成功，結果形狀: (315, 3)\n",
      "2025-06-06 12:18:02,589 - INFO - 創建數據操作節點: select_column, 結果形狀: (315, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully processed and saved to tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:04,308 - INFO - 創建 write 節點: write (品質分數: 0.80)\n",
      "2025-06-06 12:18:07,124 - INFO - 操作成功，結果形狀: (0, 3)\n",
      "2025-06-06 12:18:07,124 - INFO - 創建數據操作節點: select_row, 結果形狀: (0, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功保存修改後的DataFrame到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:08,541 - INFO - 操作成功，結果形狀: (315, 2)\n",
      "2025-06-06 12:18:08,542 - INFO - 創建數據操作節點: select_column, 結果形狀: (315, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file processed and saved to tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:10,514 - INFO - 操作成功，結果形狀: (315, 2)\n",
      "2025-06-06 12:18:10,514 - INFO - 創建數據操作節點: group_by, 結果形狀: (315, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "發生錯誤：name 'all' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:12,328 - INFO - 操作成功，結果形狀: (31, 3)\n",
      "2025-06-06 12:18:12,329 - INFO - 創建數據操作節點: group_by, 結果形狀: (31, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_by 操作完成，結果已儲存至 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:13,772 - INFO - 創建 write 節點: write (品質分數: 0.85)\n",
      "2025-06-06 12:18:16,380 - INFO - 操作成功，結果形狀: (0, 3)\n",
      "2025-06-06 12:18:16,380 - INFO - 創建數據操作節點: select_row, 結果形狀: (0, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully processed and saved to tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:18,196 - INFO - 操作成功，結果形狀: (31, 2)\n",
      "2025-06-06 12:18:18,197 - INFO - 創建數據操作節點: select_column, 結果形狀: (31, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欄位選擇完成並已儲存至 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:20,219 - INFO - 操作成功，結果形狀: (31, 3)\n",
      "2025-06-06 12:18:20,219 - INFO - 創建數據操作節點: group_by, 結果形狀: (31, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_by操作完成，結果已儲存到 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:21,917 - INFO - 操作成功，結果形狀: (315, 2)\n",
      "2025-06-06 12:18:21,918 - INFO - 創建數據操作節點: select_column, 結果形狀: (315, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "選取欄位完成，並已儲存至 tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:18:22,185 - ERROR - 生成失敗 (嘗試 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 35\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:24,431 - ERROR - 生成失敗 (嘗試 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:26,658 - ERROR - 生成失敗 (嘗試 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:26,659 - INFO - 創建 write 節點: write (品質分數: 0.40)\n",
      "2025-06-06 12:18:26,920 - ERROR - 生成失敗 (嘗試 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 31\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:29,169 - ERROR - 生成失敗 (嘗試 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:31,418 - ERROR - 生成失敗 (嘗試 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:31,419 - INFO - 創建 write 節點: write (品質分數: 0.40)\n",
      "2025-06-06 12:18:32,194 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:33,420 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:33,420 - WARNING - 無法生成操作代碼: select_row\n",
      "2025-06-06 12:18:33,646 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:34,877 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:34,878 - WARNING - 無法生成操作代碼: select_column\n",
      "2025-06-06 12:18:35,700 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:36,929 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 21\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:36,930 - WARNING - 無法生成操作代碼: group_by\n",
      "2025-06-06 12:18:37,750 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:38,986 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 19\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:38,987 - WARNING - 無法生成操作代碼: select_row\n",
      "2025-06-06 12:18:39,778 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:40,998 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 17\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:40,998 - WARNING - 無法生成操作代碼: select_column\n",
      "2025-06-06 12:18:41,884 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:43,123 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:43,124 - WARNING - 無法生成操作代碼: group_by\n",
      "2025-06-06 12:18:43,354 - WARNING - 生成代碼失敗 (嘗試 1/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:44,587 - WARNING - 生成代碼失敗 (嘗試 2/2): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 13\n",
      "}\n",
      "]\n",
      "2025-06-06 12:18:44,588 - WARNING - 無法生成操作代碼: group_by\n",
      "2025-06-06 12:18:44,604 - ERROR - 程序執行失敗: Object of type int64 is not JSON serializable\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\1641214403.py\", line 584, in <module>\n",
      "    enhanced_tree_report.generate_all_texts_enhanced(root)\n",
      "  File \"C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\1641214403.py\", line 424, in generate_all_texts_enhanced\n",
      "    self.generate_all_texts_enhanced(child)\n",
      "  File \"C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\1641214403.py\", line 424, in generate_all_texts_enhanced\n",
      "    self.generate_all_texts_enhanced(child)\n",
      "  File \"C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\1641214403.py\", line 424, in generate_all_texts_enhanced\n",
      "    self.generate_all_texts_enhanced(child)\n",
      "  File \"C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\1641214403.py\", line 428, in generate_all_texts_enhanced\n",
      "    node.text = self.text_generator.generate_enhanced_write_content(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Danie\\AppData\\Local\\Temp\\ipykernel_15944\\1641214403.py\", line 191, in generate_enhanced_write_content\n",
      "    {json.dumps(insights, ensure_ascii=False, indent=2)}\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\encoder.py\", line 202, in encode\n",
      "    chunks = list(chunks)\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\encoder.py\", line 432, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\encoder.py\", line 406, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\encoder.py\", line 439, in _iterencode\n",
      "    o = _default(o)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Danie\\.conda\\envs\\badminton\\Lib\\json\\encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type int64 is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import dspy\n",
    "import ast\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional, Set\n",
    "import copy\n",
    "import hashlib\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import builtins\n",
    "import time\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===== 新增：新聞寫作風格配置 =====\n",
    "class NewsStyleConfig:\n",
    "    \"\"\"新聞寫作風格配置類\"\"\"\n",
    "    \n",
    "    # 羽球專業術語對照表\n",
    "    BADMINTON_TERMS = {\n",
    "        'net': '網前失誤',\n",
    "        'out': '出界',\n",
    "        'long': '過底線',\n",
    "        'smash': '殺球',\n",
    "        'clear': '高遠球',\n",
    "        'drop': '切球',\n",
    "        'drive': '平抽球',\n",
    "        'serve': '發球',\n",
    "        'return': '回球'\n",
    "    }\n",
    "    \n",
    "    # 新聞常用動詞\n",
    "    ACTION_VERBS = [\n",
    "        '展現', '發揮', '掌握', '運用', '施展', '控制', '主導', '壓制',\n",
    "        '突破', '創造', '締造', '奠定', '確立', '鞏固', '扭轉', '逆轉'\n",
    "    ]\n",
    "    \n",
    "    # 新聞形容詞\n",
    "    DESCRIPTIVE_ADJECTIVES = [\n",
    "        '精彩', '激烈', '關鍵', '致命', '精準', '穩健', '霸氣', '靈活',\n",
    "        '果決', '冷靜', '強勢', '驚艷', '出色', '卓越', '完美', '絕佳'\n",
    "    ]\n",
    "    \n",
    "    # 新聞句式模板\n",
    "    SENTENCE_TEMPLATES = [\n",
    "        \"{player}在{situation}中{action}，{result}\",\n",
    "        \"憑藉{skill}，{player}{achievement}\",\n",
    "        \"{player}以{score_pattern}{victory_method}，{final_result}\",\n",
    "        \"比賽中{player}{performance}，{impact}\",\n",
    "        \"關鍵時刻{player}{key_action}，{outcome}\"\n",
    "    ]\n",
    "\n",
    "# ===== 改進的文本生成器 =====\n",
    "class EnhancedTextGenerator:\n",
    "    def __init__(self, api_key, table_description=\"\"):\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "        self.table_description = table_description\n",
    "        self.style_config = NewsStyleConfig()\n",
    "        \n",
    "        # 新增：比賽上下文記憶\n",
    "        self.match_context = {\n",
    "            'player_names': ['Player_A', 'Player_B'],\n",
    "            'match_type': '羽球賽事',\n",
    "            'key_moments': [],\n",
    "            'performance_trends': {}\n",
    "        }\n",
    "\n",
    "    def _convert_to_json_serializable(self, obj):\n",
    "        \"\"\"將numpy/pandas類型轉換為JSON可序列化的Python基本類型\"\"\"\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        \n",
    "        if isinstance(obj, (np.integer, np.int64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (pd.Series, pd.Index)):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, pd.DataFrame):\n",
    "            return obj.to_dict(orient='records')\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: self._convert_to_json_serializable(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self._convert_to_json_serializable(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "        \n",
    "    def extract_detailed_insights(self, table: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"提取更詳細的比賽洞察\"\"\"\n",
    "        insights = {\n",
    "            'basic_stats': {},\n",
    "            'patterns': {},\n",
    "            'key_moments': [],\n",
    "            'player_performance': {},\n",
    "            'tactical_analysis': {}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # 基本統計\n",
    "            if 'lose_reason' in table.columns:\n",
    "                lose_reasons = table['lose_reason'].value_counts()\n",
    "                insights['basic_stats']['top_lose_reason'] = {\n",
    "                    'reason': lose_reasons.index[0] if len(lose_reasons) > 0 else '未知',\n",
    "                    'count': lose_reasons.iloc[0] if len(lose_reasons) > 0 else 0,\n",
    "                    'percentage': round((lose_reasons.iloc[0] / len(table)) * 100, 1) if len(lose_reasons) > 0 else 0\n",
    "                }\n",
    "                \n",
    "            if 'getpoint_player' in table.columns:\n",
    "                point_winners = table['getpoint_player'].value_counts()\n",
    "                insights['basic_stats']['leading_player'] = {\n",
    "                    'player': point_winners.index[0] if len(point_winners) > 0 else '未知',\n",
    "                    'points': point_winners.iloc[0] if len(point_winners) > 0 else 0,\n",
    "                    'advantage': point_winners.iloc[0] - point_winners.iloc[1] if len(point_winners) > 1 else 0\n",
    "                }\n",
    "            \n",
    "            # 模式分析\n",
    "            if 'type' in table.columns and 'lose_reason' in table.columns:\n",
    "                pattern_analysis = table.groupby('type')['lose_reason'].value_counts()\n",
    "                insights['patterns']['shot_error_correlation'] = pattern_analysis.to_dict()\n",
    "            \n",
    "            # 關鍵時刻識別（基於分數變化）\n",
    "            if 'score' in table.columns:\n",
    "                score_changes = table['score'].diff().abs()\n",
    "                critical_moments = table[score_changes > score_changes.quantile(0.8)]\n",
    "                insights['key_moments'] = critical_moments.to_dict('records')[:3]  # 前3個關鍵時刻\n",
    "            \n",
    "            # 球員表現分析\n",
    "            if 'getpoint_player' in table.columns:\n",
    "                for player in table['getpoint_player'].unique():\n",
    "                    player_data = table[table['getpoint_player'] == player]\n",
    "                    insights['player_performance'][player] = {\n",
    "                        'total_points': len(player_data),\n",
    "                        'winning_shots': player_data['type'].value_counts().to_dict() if 'type' in table.columns else {},\n",
    "                        'consistency': self._calculate_consistency(player_data)\n",
    "                    }\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"提取洞察失敗: {e}\")\n",
    "            \n",
    "        return self._convert_to_json_serializable(insights)\n",
    "\n",
    "    def _calculate_consistency(self, player_data: pd.DataFrame) -> float:\n",
    "        \"\"\"計算球員一致性指標\"\"\"\n",
    "        try:\n",
    "            if 'score' in player_data.columns and len(player_data) > 1:\n",
    "                score_variance = player_data['score'].var()\n",
    "                return max(0, 1 - (score_variance / 10))  # 標準化一致性分數\n",
    "            return 0.5  # 預設值\n",
    "        except:\n",
    "            return 0.5\n",
    "\n",
    "    def generate_contextual_narrative(self, insights: Dict[str, Any], operation_history: List[str]) -> str:\n",
    "        \"\"\"根據洞察生成有上下文的敘述\"\"\"\n",
    "        narratives = []\n",
    "        insights = self._convert_to_json_serializable(insights)\n",
    "        # 開場敘述\n",
    "        if insights.get('basic_stats', {}).get('leading_player'):\n",
    "            leader_info = insights['basic_stats']['leading_player']\n",
    "            if leader_info['advantage'] > 2:\n",
    "                narratives.append(f\"{leader_info['player']}在本局展現強勢表現，以{leader_info['points']}分領先對手{leader_info['advantage']}分\")\n",
    "            else:\n",
    "                narratives.append(f\"雙方戰況膠著，{leader_info['player']}僅以{leader_info['advantage']}分的微幅優勢領先\")\n",
    "        \n",
    "        # 失誤分析敘述\n",
    "        if insights.get('basic_stats', {}).get('top_lose_reason'):\n",
    "            error_info = insights['basic_stats']['top_lose_reason']\n",
    "            error_desc = self.style_config.BADMINTON_TERMS.get(error_info['reason'], error_info['reason'])\n",
    "            narratives.append(f\"比賽中{error_desc}成為主要失分因素，佔總失誤的{error_info['percentage']}%\")\n",
    "        \n",
    "        # 關鍵時刻敘述\n",
    "        if insights.get('key_moments'):\n",
    "            narratives.append(\"關鍵分數轉折點出現激烈攻防，雙方你來我往不相上下\")\n",
    "        \n",
    "        return \"，\".join(narratives) + \"。\"\n",
    "\n",
    "    def generate_enhanced_write_content(self, table: pd.DataFrame, operation_history: List[str]) -> str:\n",
    "        \"\"\"生成增強版的寫作內容\"\"\"\n",
    "        \n",
    "        # 提取詳細洞察\n",
    "        insights = self.extract_detailed_insights(table)\n",
    "        \n",
    "        # 生成上下文敘述\n",
    "        contextual_narrative = self.generate_contextual_narrative(insights, operation_history)\n",
    "        \n",
    "        table_str = table.to_string()\n",
    "        WRITE_TOKENS = 80  # 增加token數量以支援更豐富內容\n",
    "        \n",
    "        enhanced_prompt = f\"\"\"\n",
    "System: 你是專業的體育新聞記者，專精羽球賽事報導。請根據數據分析撰寫一段精彩的比賽片段描述。\n",
    "\n",
    "# 寫作要求\n",
    "1. 使用繁體中文，文筆生動活潑\n",
    "2. 採用體育新聞的專業語調，避免過於技術性的用詞\n",
    "3. 重點描述比賽節奏、球員表現和戰術運用\n",
    "4. 字數控制在{WRITE_TOKENS}字以內\n",
    "5. 避免直接引用欄位名稱，使用自然的描述方式\n",
    "6. 突出比賽的戲劇性和觀賞性\n",
    "\n",
    "# 專業術語對照\n",
    "{json.dumps(self.style_config.BADMINTON_TERMS, ensure_ascii=False, indent=2)}\n",
    "\n",
    "# 比賽數據洞察\n",
    "{json.dumps(insights, ensure_ascii=False, indent=2)}\n",
    "\n",
    "# 上下文敘述參考\n",
    "{contextual_narrative}\n",
    "\n",
    "# 原始數據表格\n",
    "{table_str}\n",
    "\n",
    "請撰寫一段引人入勝的比賽描述：\n",
    "\"\"\"\n",
    "        \n",
    "        return self._retry_generate_with_quality_check(enhanced_prompt)\n",
    "\n",
    "    def _retry_generate_with_quality_check(self, prompt: str, max_retries=3) -> str:\n",
    "        \"\"\"帶配額管理和指數退避的重試生成\"\"\"\n",
    "        import random\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # 添加隨機延遲以避免突發請求\n",
    "                delay = random.uniform(0.5, 2.0) * (2 ** attempt)\n",
    "                time.sleep(delay)\n",
    "                \n",
    "                response = self.model.generate_content(prompt)\n",
    "                \n",
    "                if response.text:\n",
    "                    text = response.text.strip()\n",
    "                    quality_score = self._assess_text_quality(text)\n",
    "                    \n",
    "                    if quality_score >= 0.7:\n",
    "                        return text\n",
    "                    elif attempt < max_retries - 1:\n",
    "                        logger.info(f\"文本品質不達標 (分數: {quality_score:.2f})，重新生成...\")\n",
    "                        time.sleep(1)\n",
    "                    else:\n",
    "                        return text\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if \"429\" in str(e):  # 配額錯誤\n",
    "                    wait_time = 30 + random.randint(0, 10)  # 隨機等待30-40秒\n",
    "                    logger.warning(f\"API配額不足，等待 {wait_time} 秒後重試...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    logger.error(f\"生成失敗 (嘗試 {attempt+1}/{max_retries}): {e}\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        time.sleep(2)\n",
    "                    \n",
    "        return \"⚠️ 內容生成暫時失敗，請稍後重試\"\n",
    "\n",
    "    def _assess_text_quality(self, text: str) -> float:\n",
    "        \"\"\"評估文本品質\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # 長度檢查 (20%)\n",
    "        if 30 <= len(text) <= 120:\n",
    "            score += 0.2\n",
    "        \n",
    "        # 專業術語使用 (20%)\n",
    "        term_usage = sum(1 for term in self.style_config.BADMINTON_TERMS.values() if term in text)\n",
    "        if term_usage > 0:\n",
    "            score += min(0.2, term_usage * 0.1)\n",
    "        \n",
    "        # 動詞活躍度 (20%)\n",
    "        verb_usage = sum(1 for verb in self.style_config.ACTION_VERBS if verb in text)\n",
    "        if verb_usage > 0:\n",
    "            score += min(0.2, verb_usage * 0.05)\n",
    "        \n",
    "        # 避免技術欄位名稱 (20%)\n",
    "        tech_terms = ['lose_reason', 'getpoint_player', 'type', 'column', 'row']\n",
    "        if not any(term in text for term in tech_terms):\n",
    "            score += 0.2\n",
    "        \n",
    "        # 語句流暢度 (20%) - 簡單檢查標點符號\n",
    "        if '，' in text or '。' in text:\n",
    "            score += 0.2\n",
    "        \n",
    "        return min(1.0, score)\n",
    "\n",
    "    def generate_comprehensive_final_report(self, child_texts: List[str], match_metadata: Dict[str, Any]) -> str:\n",
    "        \"\"\"生成綜合性最終報告\"\"\"\n",
    "        \n",
    "        if not child_texts:\n",
    "            return \"比賽數據分析完成，詳細內容請參考各階段分析。\"\n",
    "        \n",
    "        # 整合所有子文本\n",
    "        consolidated_content = \"\\n\".join([f\"• {text.strip()}\" for text in child_texts if text.strip()])\n",
    "        \n",
    "        final_prompt = f\"\"\"\n",
    "System: 你是資深體育記者，負責撰寫羽球賽事的深度報導。請根據以下分析內容，撰寫一篇完整的賽事新聞稿。\n",
    "\n",
    "# 撰寫要求\n",
    "1. 採用新聞稿格式，包含導言、內文和結語\n",
    "2. 語言生動，突出比賽亮點和戲劇性\n",
    "3. 避免使用技術性術語，改用讀者易懂的描述\n",
    "4. 字數控制在150-200字\n",
    "5. 結構清晰，邏輯順暢\n",
    "6. 使用「選手A」和「選手B」稱呼球員\n",
    "\n",
    "# 新聞寫作範例風格\n",
    "\"在今日的精彩對決中，選手A展現出色的網前技巧，多次運用精準的切球製造得分機會。然而選手B並未示弱，憑藉強勁的後場攻擊力，在關鍵時刻連續得分扳回劣勢。整場比賽高潮迭起，兩位選手的精彩表現讓現場觀眾大飽眼福。\"\n",
    "\n",
    "# 分析內容摘要\n",
    "{consolidated_content}\n",
    "\n",
    "請撰寫完整的賽事新聞報導：\n",
    "\"\"\"\n",
    "        \n",
    "        return self._retry_generate_with_quality_check(final_prompt, max_retries=2)\n",
    "\n",
    "    def merge_child_texts_enhanced(self, child_texts: List[str], parent_operation: str) -> str:\n",
    "        \"\"\"增強版文本合併\"\"\"\n",
    "        if not child_texts:\n",
    "            return \"\"\n",
    "\n",
    "        # 過濾和清理文本\n",
    "        clean_texts = []\n",
    "        for text in child_texts:\n",
    "            cleaned = text.strip()\n",
    "            if cleaned and len(cleaned) > 10:  # 過濾過短的文本\n",
    "                clean_texts.append(cleaned)\n",
    "        \n",
    "        if not clean_texts:\n",
    "            return \"\"\n",
    "\n",
    "        # 智能合併邏輯\n",
    "        if len(clean_texts) == 1:\n",
    "            return clean_texts[0]\n",
    "        \n",
    "        # 多段落合併\n",
    "        merge_prompt = f\"\"\"\n",
    "請將以下羽球比賽分析片段整合成一段連貫的描述：\n",
    "\n",
    "{chr(10).join([f\"{i+1}. {text}\" for i, text in enumerate(clean_texts)])}\n",
    "\n",
    "整合要求：\n",
    "1. 保持所有關鍵信息\n",
    "2. 確保邏輯順序合理\n",
    "3. 語言自然流暢\n",
    "4. 避免重複內容\n",
    "5. 字數控制在100字以內\n",
    "\n",
    "整合結果：\n",
    "\"\"\"\n",
    "        \n",
    "        return self._retry_generate_with_quality_check(merge_prompt)\n",
    "\n",
    "# ===== 改進的TreeOfReport類別 =====\n",
    "class EnhancedTreeOfReport:\n",
    "    def __init__(self, api_key: str, max_depth: int = 5, max_degree: int = 5):\n",
    "        self.api_key = api_key\n",
    "        self.max_depth = max_depth\n",
    "        self.max_degree = max_degree\n",
    "\n",
    "        # 載入配置檔案\n",
    "        self.load_configurations()\n",
    "\n",
    "        # 使用增強版文本生成器\n",
    "        self.content_planner = ContentPlanner(api_key)\n",
    "        self.df_operator = SafeDataFrameOperator(api_key)\n",
    "        self.text_generator = EnhancedTextGenerator(api_key, table_description=self.table_description)\n",
    "        \n",
    "        # 新增：比賽元數據追蹤\n",
    "        self.match_metadata = {\n",
    "            'total_points': 0,\n",
    "            'analysis_depth': 0,\n",
    "            'key_insights': [],\n",
    "            'generation_quality': []\n",
    "        }\n",
    "        \n",
    "        # 追蹤功能\n",
    "        self.execution_log: List[Dict[str, Any]] = []\n",
    "        self.node_registry: Dict[str, TreeNode] = {}\n",
    "\n",
    "    def load_configurations(self):\n",
    "        \"\"\"載入配置，與原版相同\"\"\"\n",
    "        self.table_description = read_text_file(\"filtered_data _description.txt\")\n",
    "        if not self.table_description or self.table_description == \"No file available\":\n",
    "            self.table_description = \"羽球比賽數據分析表格，包含得分模式、失誤類型和球員表現等關鍵指標\"\n",
    "\n",
    "        self.operation_description = read_json_file(\"selected_operations.json\")\n",
    "        if isinstance(self.operation_description, list):\n",
    "            self.operation_pool = [op['name'] for op in self.operation_description]\n",
    "        else:\n",
    "            self.operation_pool = list(self.operation_description.keys())\n",
    "\n",
    "        logger.info(f\"載入操作池: {self.operation_pool}\")\n",
    "\n",
    "    def create_child_node_enhanced(self, parent: TreeNode, operation: str) -> Optional[TreeNode]:\n",
    "        \"\"\"增強版子節點創建\"\"\"\n",
    "        try:\n",
    "            new_operation_history = parent.operation_history + [operation]\n",
    "            \n",
    "            if operation.lower().startswith('write'):\n",
    "                # 使用增強版文本生成\n",
    "                text = self.text_generator.generate_enhanced_write_content(\n",
    "                    parent.table,\n",
    "                    new_operation_history\n",
    "                )\n",
    "                \n",
    "                child = TreeNode(\n",
    "                    level=parent.level + 1,\n",
    "                    text=text,\n",
    "                    table=parent.table.copy(),\n",
    "                    operation=operation\n",
    "                )\n",
    "                child.operation_history = new_operation_history\n",
    "                self.node_registry[child.node_id] = child\n",
    "                \n",
    "                # 評估生成質量\n",
    "                quality_score = self.text_generator._assess_text_quality(text)\n",
    "                self.match_metadata['generation_quality'].append(quality_score)\n",
    "                \n",
    "                logger.info(f\"創建 write 節點: {operation} (品質分數: {quality_score:.2f})\")\n",
    "                return child\n",
    "            else:\n",
    "                # 數據操作節點（與原版相同邏輯）\n",
    "                df_info = f\"Shape: {parent.table.shape}\\nColumns: {list(parent.table.columns)}\\nData types:\\n{parent.table.dtypes.to_string()}\"\n",
    "                code = self.df_operator.generate_code(operation, df_info)\n",
    "                \n",
    "                if code:\n",
    "                    result_df = self.df_operator.safe_execute(code, parent.table)\n",
    "                    child = TreeNode(\n",
    "                        level=parent.level + 1,\n",
    "                        text=\"\",\n",
    "                        table=result_df,\n",
    "                        operation=operation\n",
    "                    )\n",
    "                    child.operation_history = new_operation_history\n",
    "                    self.node_registry[child.node_id] = child\n",
    "                    logger.info(f\"創建數據操作節點: {operation}, 結果形狀: {result_df.shape}\")\n",
    "                    return child\n",
    "                else:\n",
    "                    logger.warning(f\"無法生成操作代碼: {operation}\")\n",
    "                    return None\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"創建子節點失敗: {e}\")\n",
    "            return None\n",
    "\n",
    "    def generate_all_texts_enhanced(self, node: TreeNode):\n",
    "        \"\"\"增強版文本生成\"\"\"\n",
    "        # 遞歸處理子節點\n",
    "        for child in node.children:\n",
    "            self.generate_all_texts_enhanced(child)\n",
    "        \n",
    "        # 葉節點處理\n",
    "        if node.is_leaf() and not node.text and node.operation and not node.operation.lower().startswith('write'):\n",
    "            node.text = self.text_generator.generate_enhanced_write_content(\n",
    "                node.table, \n",
    "                node.operation_history\n",
    "            )\n",
    "        # 非葉節點合併\n",
    "        elif node.children:\n",
    "            child_texts = [child.text for child in node.children if child.text.strip()]\n",
    "            if child_texts:\n",
    "                merged_text = self.text_generator.merge_child_texts_enhanced(\n",
    "                    child_texts, \n",
    "                    node.operation or \"root\"\n",
    "                )\n",
    "                if node.text:\n",
    "                    node.text = node.text + \"\\n\\n\" + merged_text\n",
    "                else:\n",
    "                    node.text = merged_text\n",
    "        \n",
    "        logger.info(f'節點 {node.node_id} 增強文本生成完成')\n",
    "\n",
    "    def generate_final_report_enhanced(self, node: TreeNode) -> str:\n",
    "        \"\"\"生成增強版最終報告\"\"\"\n",
    "        if node.level == 0:\n",
    "            # 計算整體品質指標\n",
    "            avg_quality = sum(self.match_metadata['generation_quality']) / len(self.match_metadata['generation_quality']) if self.match_metadata['generation_quality'] else 0\n",
    "            \n",
    "            # 使用增強版最終報告生成\n",
    "            final_text = self.text_generator.generate_comprehensive_final_report(\n",
    "                [node.text] if node.text else [],\n",
    "                {**self.match_metadata, 'average_quality': avg_quality}\n",
    "            )\n",
    "            \n",
    "            # 保存報告和元數據\n",
    "            with open(\"enhanced_tree_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(final_text)\n",
    "            \n",
    "            with open(\"generation_quality_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                quality_report = {\n",
    "                    \"average_quality\": avg_quality,\n",
    "                    \"total_generations\": len(self.match_metadata['generation_quality']),\n",
    "                    \"quality_scores\": self.match_metadata['generation_quality'],\n",
    "                    \"metadata\": self.match_metadata\n",
    "                }\n",
    "                json.dump(quality_report, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            logger.info(f\"最終報告生成完成，平均品質分數: {avg_quality:.2f}\")\n",
    "            return final_text\n",
    "        else:\n",
    "            # 子節點報告（與原版相同）\n",
    "            return self._generate_hierarchical_report(node, 0)\n",
    "\n",
    "    def _generate_hierarchical_report(self, node: TreeNode, level: int) -> str:\n",
    "        \"\"\"生成階層式報告\"\"\"\n",
    "        indent = \"  \" * level\n",
    "        report = f\"{indent}{'#' * (level + 1)} {node.operation or 'Root'}\\n\\n\"\n",
    "\n",
    "        if node.text:\n",
    "            report += f\"{indent}{node.text}\\n\\n\"\n",
    "\n",
    "        if node.table is not None and not node.table.empty and level < 2:\n",
    "            report += f\"{indent}**資料摘要:** Shape {node.table.shape}\\n\"\n",
    "            if len(node.table) <= 10:\n",
    "                report += f\"{indent}```\\n{node.table.to_string()}\\n{indent}```\\n\\n\"\n",
    "            else:\n",
    "                report += f\"{indent}```\\n{node.table.head().to_string()}\\n{indent}```\\n\\n\"\n",
    "\n",
    "        for child in node.children:\n",
    "            report += self._generate_hierarchical_report(child, level + 1)\n",
    "\n",
    "        return report\n",
    "    \n",
    "    def build_tree(self, table: pd.DataFrame) -> 'TreeNode':\n",
    "        \"\"\"構建報告樹的根節點\"\"\"\n",
    "        root = TreeNode(level=0, text=\"\", table=table.copy(), operation=\"root\")\n",
    "        self.node_registry[root.node_id] = root\n",
    "\n",
    "        def expand(node: TreeNode, depth: int):\n",
    "            if depth >= self.max_depth:\n",
    "                return\n",
    "            for operation in self.operation_pool[:self.max_degree]:\n",
    "                child = self.create_child_node_enhanced(node, operation)\n",
    "                if child:\n",
    "                    node.children.append(child)\n",
    "                    expand(child, depth + 1)\n",
    "\n",
    "        expand(root, 0)\n",
    "        return root\n",
    "\n",
    "# ===== 主要函數保持不變，僅修改類別調用 =====\n",
    "def read_text_file(file_path):\n",
    "    \"\"\"讀取文本文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"No file available\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"讀取文件錯誤: {e}\")\n",
    "        return \"Error reading file\"\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"讀取JSON文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    except UnicodeDecodeError:\n",
    "        with open(file_path, 'r', encoding='latin1') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        return [\n",
    "            {\"name\": \"select_column\", \"description\": \"選擇特定欄位\"},\n",
    "            {\"name\": \"value_counts\", \"description\": \"計算值的頻次\"},\n",
    "            {\"name\": \"groupby\", \"description\": \"按欄位分組\"},\n",
    "            {\"name\": \"sort_values\", \"description\": \"排序數據\"},\n",
    "            {\"name\": \"filter_rows\", \"description\": \"過濾行數據\"},\n",
    "            {\"name\": \"write\", \"description\": \"撰寫分析文本\"}\n",
    "        ]\n",
    "\n",
    "# 此處應包含原有的其他類別定義 (TreeNode, OperationParser, ContentPlanner, SafeDataFrameOperator)\n",
    "# 為節省空間，這裡只展示主要的修改部分\n",
    "\n",
    "\n",
    "    \n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n",
    "logger.info(\"Enhanced Tree-of-Report for Sports News Generation\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "logger.info(\"正在載入數據...\")\n",
    "\n",
    "try:\n",
    "    TABLES = pd.read_csv('filtered_set1.csv')\n",
    "    logger.info(f\"成功載入CSV: {TABLES.shape[0]} 行, {TABLES.shape[1]} 列\")\n",
    "except FileNotFoundError:\n",
    "    logger.warning(\"找不到 filtered_set1.csv，使用示例數據\")\n",
    "    TABLES = pd.DataFrame({\n",
    "        'type': ['smash', 'clear', 'drop', 'net', 'smash', 'clear', 'drop', 'drive'],\n",
    "        'lose_reason': ['net', 'out', 'net', 'long', 'net', 'out', 'long', 'net'],\n",
    "        'getpoint_player': ['Player_A', 'Player_B', 'Player_A', 'Player_B', 'Player_A', 'Player_B', 'Player_A', 'Player_B'],\n",
    "        'score': [1, 2, 1, 3, 2, 1, 4, 2]\n",
    "    })\n",
    "\n",
    "# 使用增強版系統\n",
    "MAX_DEPTH = 3\n",
    "MAX_DEGREE = 3\n",
    "\n",
    "enhanced_tree_report = EnhancedTreeOfReport(api_key, max_depth=MAX_DEPTH, max_degree=MAX_DEGREE)\n",
    "\n",
    "logger.info(\"開始建構增強版報告樹...\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    # 建構樹（使用原有的build_tree邏輯，但替換關鍵方法）\n",
    "    root = enhanced_tree_report.build_tree(TABLES)\n",
    "    \n",
    "    # 生成增強版文本\n",
    "    enhanced_tree_report.generate_all_texts_enhanced(root)\n",
    "    \n",
    "    # 生成最終報告\n",
    "    final_report = enhanced_tree_report.generate_final_report_enhanced(root)\n",
    "    \n",
    "    logger.info(\"\\n\" + \"=\"*60)\n",
    "    logger.info(\"ENHANCED TREE-OF-REPORT 最終報告\")\n",
    "    logger.info(\"=\"*60)\n",
    "    print(final_report)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (start_time - end_time).total_seconds()\n",
    "    \n",
    "    logger.info(f\"增強版報告生成完成，耗時: {duration:.2f} 秒\")\n",
    "    logger.info(\"生成的文件:\")\n",
    "    logger.info(\"- enhanced_tree_report.txt: 增強版最終報告\")\n",
    "    logger.info(\"- generation_quality_report.json: 生成品質分析\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"程序執行失敗: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6b0632c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 第 1/3 次生成...\n",
      "⏳ 第 2/3 次生成...\n",
      "⏳ 第 3/3 次生成...\n",
      "\n",
      "✅ 所有版本已生成\n",
      "[1] 分數: 0.7 → 這場羽球對決可謂高潮迭起，雙方選手你來我往，互不相讓。從一開始的試探性發球與輕巧過網球，到隨後逐漸加劇的攻防轉換，長球與短球的交錯使用，展現了兩位選手全面的技術能力。\n",
      "\n",
      "第一分就經歷了多拍來回，雙方在網前短球與後場高遠球之間不斷轉換，最終A選手把握機會，一記精準的落點讓對手措手不及，先下一城。\n",
      "\n",
      "隨後，雙方比分交替上升。A選手擅長利用落點刁鑽的切球來調動對手，而B選手則以強勁的扣殺作為回應。比賽中，多次出現多拍相持，雙方選手都展現了極佳的體能與控制能力。精采的攻防轉換讓觀眾目不暇給。\n",
      "\n",
      "比賽過程中，雙方也出現了一些失誤，包括回球出界、觸網等，但整體而言，兩人表現出的競技水準仍然相當高。特別是後段，雙方體力消耗巨大，但依然堅持快速的攻防轉換，比分也因此呈現膠著狀態。最終，A選手以21:15的比分艱難勝出，贏得了這場激烈的比賽。\n",
      "[2] 分數: 0.7 → 這場羽球賽可謂高潮迭起，雙方選手你來我往，毫不相讓。比賽伊始，雙方就展開了激烈的攻防，多次出現多拍來回的精彩場面。一方選手擅長運用多樣化的球路，包括輕巧的網前小球和角度刁鑽的斜線進攻，試圖調動對手；另一方則以強勁的後場扣殺和穩健的防守反擊見長。\n",
      "\n",
      "比賽過程中，雙方比分交替上升，互不相讓。領先優勢多次易手，每一次得分都伴隨著場邊觀眾的歡呼和掌聲。選手們在場上奮力奔跑，每一次擊球都凝聚著力量和技巧，力求將球打到對方難以觸及的位置。\n",
      "\n",
      "在關鍵分上，雙方都展現出了極高的心理素質。一方選手利用一次精準的判斷，迫使對手回球出界，成功拿下關鍵一分。然而，另一方選手也毫不示弱，隨後利用一記勢大力沉的扣殺，直接得分，將比分追平。\n",
      "\n",
      "比賽最後階段，雙方體能都已接近極限，但依舊堅持著。最終，在一連串的精彩攻防後，一方選手抓住機會，利用對手的一個失誤，成功拿下制勝分，贏得了這場艱苦的比賽。整場比賽節奏緊湊，雙方實力接近，為觀眾奉獻了一場精彩絕倫的羽球盛宴。\n",
      "[3] 分數: 0.75 → 這場羽球賽事可謂高潮迭起，雙方你來我往，攻防轉換迅速。從一開始的比分膠著，到後面的逐漸拉鋸，每一球都充滿了競爭。\n",
      "\n",
      "首局開始，雙方都相當謹慎，試圖通過發球和過渡球來控制節奏。A選手率先取得領先，但B選手緊追不捨，多次通過積極的進攻將比分扳平。比賽過程中，多次出現多拍來回，雙方在網前小球和後場高遠球的處理上都展現了高超的技巧。A選手的突擊和B選手的頑強防守，形成了鮮明的對比。\n",
      "\n",
      "中段，A選手利用一連串的攻勢，包括巧妙的吊球和兇猛的扣殺，逐漸將比分拉開。然而，B選手並沒有因此氣餒，而是穩紮穩打，通過精準的落點控制和積極的跑動來尋找反擊的機會。在一次多拍的僵持中，B選手巧妙運用小球，迫使A選手回球掛網，贏得寶貴一分。\n",
      "\n",
      "比賽末段，雙方體力消耗巨大，失誤也開始增多。A選手的進攻雖然依舊犀利，但穩定性有所下降，多次出現回球出界或下網的情況。而B選手則抓住機會，加強了網前的控制，頻頻利用小球得分。最終，A選手頂住壓力，在一次關鍵的對攻中，成功迫使對手回球出界，艱難地贏下了這一局。\n",
      "\n",
      "整場比賽節奏緊湊，充滿了懸念，雙方選手都展現了極高的競技水平和頑強的鬥志。無論是精準的網前小球，還是勢大力沉的後場扣殺，都給觀眾留下了深刻的印象。\n",
      "\n",
      "🏆 最佳版本是第 3 次：這場羽球賽事可謂高潮迭起，雙方你來我往，攻防轉換迅速。從一開始的比分膠著，到後面的逐漸拉鋸，每一球都充滿了競爭。\n",
      "\n",
      "首局開始，雙方都相當謹慎，試圖通過發球和過渡球來控制節奏。A選手率先取得領先，但B選手緊追不捨，多次通過積極的進攻將比分扳平。比賽過程中，多次出現多拍來回，雙方在網前小球和後場高遠球的處理上都展現了高超的技巧。A選手的突擊和B選手的頑強防守，形成了鮮明的對比。\n",
      "\n",
      "中段，A選手利用一連串的攻勢，包括巧妙的吊球和兇猛的扣殺，逐漸將比分拉開。然而，B選手並沒有因此氣餒，而是穩紮穩打，通過精準的落點控制和積極的跑動來尋找反擊的機會。在一次多拍的僵持中，B選手巧妙運用小球，迫使A選手回球掛網，贏得寶貴一分。\n",
      "\n",
      "比賽末段，雙方體力消耗巨大，失誤也開始增多。A選手的進攻雖然依舊犀利，但穩定性有所下降，多次出現回球出界或下網的情況。而B選手則抓住機會，加強了網前的控制，頻頻利用小球得分。最終，A選手頂住壓力，在一次關鍵的對攻中，成功迫使對手回球出界，艱難地贏下了這一局。\n",
      "\n",
      "整場比賽節奏緊湊，充滿了懸念，雙方選手都展現了極高的競技水平和頑強的鬥志。無論是精準的網前小球，還是勢大力沉的後場扣殺，都給觀眾留下了深刻的印象。\n",
      "✔️ 已儲存至：best_of_three_report_20250606_123050.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# === 寫作風格詞彙 ===\n",
    "BADMINTON_TERMS = {\n",
    "    'net': '網前失誤', 'out': '出界', 'long': '過底線', 'smash': '殺球',\n",
    "    'clear': '高遠球', 'drop': '切球', 'drive': '平抽球', 'serve': '發球', 'return': '回球'\n",
    "}\n",
    "ACTION_VERBS = ['展現', '發揮', '掌握', '運用', '施展', '控制', '主導', '壓制', '突破', '創造', '締造', '奠定', '確立', '鞏固', '扭轉', '逆轉']\n",
    "TECHNICAL_TERMS = ['lose_reason', 'getpoint_player', 'type', 'column', 'row']\n",
    "\n",
    "# === Gemini 模型初始化 ===\n",
    "def init_model(api_key: str):\n",
    "    genai.configure(api_key=api_key)\n",
    "    return genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# === 品質評估 ===\n",
    "def assess_text_quality(text: str) -> float:\n",
    "    score = 0.0\n",
    "    if 30 <= len(text) <= 120:\n",
    "        score += 0.2\n",
    "    score += min(0.2, sum(1 for t in BADMINTON_TERMS.values() if t in text) * 0.1)\n",
    "    score += min(0.2, sum(1 for v in ACTION_VERBS if v in text) * 0.05)\n",
    "    if not any(t in text for t in TECHNICAL_TERMS):\n",
    "        score += 0.2\n",
    "    if '，' in text or '。' in text:\n",
    "        score += 0.2\n",
    "    return round(min(score, 1.0), 2)\n",
    "\n",
    "# === 主流程：重複3次生成並評估 ===\n",
    "def generate_best_of_three(df: pd.DataFrame, api_key: str):\n",
    "    model = init_model(api_key)\n",
    "    table_str = df.to_string(index=False)\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "你是一位專業體育新聞記者，擅長撰寫羽球比賽報導。\n",
    "請根據以下數據表格撰寫賽事描述，使用繁體中文，避免出現技術欄位名稱。\n",
    "\n",
    "# 賽事數據表格：\n",
    "{table_str}\n",
    "\n",
    "請撰寫描述：\n",
    "\"\"\"\n",
    "\n",
    "    results = []\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            print(f\"⏳ 第 {i+1}/3 次生成...\")\n",
    "            response = model.generate_content(prompt_template)\n",
    "            time.sleep(1)\n",
    "            text = response.text.strip() if response.text else \"⚠️ 無內容\"\n",
    "        except Exception as e:\n",
    "            text = f\"⚠️ 生成錯誤: {e}\"\n",
    "        score = assess_text_quality(text)\n",
    "        results.append({'index': i+1, 'text': text, 'score': score})\n",
    "\n",
    "    # 選出最佳結果\n",
    "    best = max(results, key=lambda x: x['score'])\n",
    "\n",
    "    # 輸出到檔案\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"best_of_three_report_{timestamp}.txt\"\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in results:\n",
    "            f.write(f\"[版本 {r['index']}] 品質分數: {r['score']}\\n{r['text']}\\n\\n\")\n",
    "        f.write(f\"🏆 最佳版本為第 {best['index']} 次，分數: {best['score']}\\n\")\n",
    "        f.write(best['text'])\n",
    "\n",
    "    print(\"\\n✅ 所有版本已生成\")\n",
    "    for r in results:\n",
    "        print(f\"[{r['index']}] 分數: {r['score']} → {r['text']}\")\n",
    "    print(f\"\\n🏆 最佳版本是第 {best['index']} 次：{best['text']}\")\n",
    "    print(f\"✔️ 已儲存至：{file_name}\")\n",
    "    return best\n",
    "\n",
    "# === 測試入口 ===\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"請設置 GOOGLE_API_KEY 環境變數\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(\"filtered_set1.csv\")\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame({\n",
    "            'type': ['smash', 'clear', 'drop', 'net', 'smash', 'clear', 'drop', 'drive'],\n",
    "            'lose_reason': ['net', 'out', 'net', 'long', 'net', 'out', 'long', 'net'],\n",
    "            'getpoint_player': ['Player_A', 'Player_B', 'Player_A', 'Player_B', 'Player_A', 'Player_B', 'Player_A', 'Player_B'],\n",
    "            'score': [1, 2, 1, 3, 2, 1, 4, 2]\n",
    "        })\n",
    "\n",
    "    generate_best_of_three(df, api_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "badminton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
